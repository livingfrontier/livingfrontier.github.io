<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>钟鼓楼</title>
  
  <subtitle>钟楼瘦，鼓楼胖</subtitle>
  <link href="https://thysrael.github.io/atom.xml" rel="self"/>
  
  <link href="https://thysrael.github.io/"/>
  <updated>2025-02-14T16:01:18.861Z</updated>
  <id>https://thysrael.github.io/</id>
  
  <author>
    <name>Thysrael</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>海边拾贝-FuseMax</title>
    <link href="https://thysrael.github.io/posts/ce241189/"/>
    <id>https://thysrael.github.io/posts/ce241189/</id>
    <published>2025-02-13T13:32:06.000Z</published>
    <updated>2025-02-14T16:01:18.861Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>这篇工作比较缝合，它引用了 3 个 idea：</p><ul><li><a href="https://arxiv.org/abs/2205.14135">Flash Attention</a> 和 pass 抽象</li><li><a href="https://dl.acm.org/doi/10.1145/3613424.3623791">TeAAL</a> 和它使用的 Einsum 规范</li><li><a href="https://arxiv.org/abs/2404.11591">Extended Einsum</a></li></ul><p>TeAAL 提出用 Einsum 的形式去描述算子，并指导加速器的设计。但是 Einsum 只能描述仅包含加法和乘法的算子，对于 Flash-Attension 这种包含指数运算（softmax）和迭代运算的算子无法描述，于是作者借用了 Extended Einsum 的形式描述了 Flash Attension 算子并实现了 FuseMax 加速器，同时论证了 pass 抽象的合理性。</p><p>而实际上，TeAAL 提出的用 Einsum 指导加速器设计的思路并没有因为使用了 Extended Einsum 而被拓展；FuseMax 所展现的性能优势，大部分来自于 Flash-Attension 算法本身，而不是其硬件实现。</p></blockquote><h2 id="一、Background"><a href="#一、Background" class="headerlink" title="一、Background"></a>一、Background</h2><h3 id="1-1-Flash-Attention-Pass"><a href="#1-1-Flash-Attention-Pass" class="headerlink" title="1.1 Flash Attention, Pass"></a>1.1 Flash Attention, Pass</h3><p>Flash-Attention 是一种 Attention 算子的实现，相比于传统的实现，它可以降低内存带宽的需求，并且使用更少的片上内存，更适合当前加速器存在的 memory bound。为了达到这个目的，我们需要：</p><ul><li>尽可能少的从内存中读取数据 -&gt; 算法设计的 pass 数要少</li><li>尽可能少使用片上内存 -&gt; tile 后 reduce</li></ul><p>而这两个需求都被 softmax 的传统实现阻止了，softmax 的表达式如下：</p><p><img src="/posts/ce241189/-17394538526611.png" alt="img"></p><p>传统的 softmax 实现是一种 3-pass 的实现：</p><p><img src="/posts/ce241189/-17394538576465.png" alt="img"></p><p>所谓的 pass，就是需要访问输入的次数：</p><blockquote><p>the number of times a given element of an input must be revisited after visiting every other element of the input. </p></blockquote><p>因为 softmax 需要先遍历所有元素计算出 max 值，然后根据 max 值遍历所有元素计算分母，再根据分母计算分子。</p><p>在 flash-attention 之前，有 2018 online-softmax 工作，将算法优化成了 2-pass 的。他将第 1，2 轮进行了合并：</p><p><img src="/posts/ce241189/-17394538620357.png" alt="img"></p><p>最终结果如图：</p><p><img src="/posts/ce241189/-173945386674411.png" alt="img"></p><p>如果仅在 softmax 层，那么 2-pass 就是极限了，不过如果考虑整个 Attention，那么是可以继续优化成 1-pass 的算法，这就是 Flash-Attention，2-pass 的 Attention 表示如下：</p><p><img src="/posts/ce241189/-173945387091113.png" alt="img"></p><p>然后我们注意到（直观上说，是利用了 a 这个数组并不是最终结果，而是会被 reduce 的性质）：</p><p><img src="/posts/ce241189/-173945387591215.png" alt="img"></p><p>整理后得到：</p><p><img src="/posts/ce241189/-173945387855817.png" alt="img"></p><p>这就是一个 1-pass 的 Flash-Attention 算法。在此基础上，如果增加了 tile 操作，那么就会获得完全体的 Flash-Attention，但这本文的重点是对于 pass 的优化。</p><p><img src="/posts/ce241189/-173945388095219.png" alt="img"></p><h3 id="1-2-Einsum-Notation"><a href="#1-2-Einsum-Notation" class="headerlink" title="1.2 Einsum Notation"></a>1.2 Einsum Notation</h3><p>爱因斯坦求和标记（Einstein summation notation）是一种标记的约定，用于描述张量运算。比如说二维矩阵乘法就可以被描述为：</p><p><img src="/posts/ce241189/-173945388316621.png" alt="img"></p><p>而矩阵与向量的乘法可以被描述为：</p><p><img src="/posts/ce241189/-173945388498323.png" alt="img"></p><p>Einsum 的输入包括张量，如<script type="math/tex">A, B</script>和其对应的坐标，如<script type="math/tex">m,k</script>和<script type="math/tex">k,n</script>，还有输出矩阵对应的坐标，如<script type="math/tex">m,</script>，比如在 numpy 中，$$$$和$$$$的矩阵乘法写作：</p><pre class="line-numbers language-Python" data-language="Python"><code class="language-Python">np.einsum('mk,kn-&gt;mn', A, B)<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>Einsum 的特点在于，它将 compute 和 reduce 阶段完全区分开了，而不是混在一起，更加清晰了。</p><p>具体而言，在 compute 阶段，我们会根据输入坐标，构建一个迭代空间，然后遍历空间中的每一个点进行计算，得到一个相同维度的张量。以矩阵乘法为例，输入坐标是<script type="math/tex">m,k</script>和<script type="math/tex">k,n</script>，我们构建的迭代空间是<script type="math/tex">[1,M] \times [1,K] \times [1,N]</script>。经过计算得到的张量是<script type="math/tex">z'_{m,k, n} = [a_{m,k} \times b_{k,n}]</script>。</p><p>在 reduce 阶段，我们需要将我们得到的张量 <script type="math/tex">z_{m,k,n}</script>与输出坐标<script type="math/tex">m,n</script>进行比对，发现多了一个<script type="math/tex">$$维度。所以我们会沿着多出的维度进行规约，然后就可以得到</script>z<em>{m,n}=[\sum^{K}</em>{k=1}[a<em>{m,k} \times b</em>{k,n}]$$。</p><p>对比我平时用的矩阵乘法，可以看到 compute 和 reduce 是混合在一起的。</p><pre class="line-numbers language-C" data-language="C"><code class="language-C"> for (int i = 0; i &lt; M; i++) {     for (int j = 0; j &lt; N; j++) {        for (int k = 0; k &lt; K; k++) {            Z[i][j] += A[i][k] * B[k][j];         }    }}<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="1-3-TeAAL"><a href="#1-3-TeAAL" class="headerlink" title="1.3 TeAAL"></a>1.3 TeAAL</h3><p>TeAAL 是一个加速器模型 generator，可以根据不同算子生成不同的加速器模型。在它的设计中，算子需要使用 Einsum Cascade 来进行描述，也就是一系列的 Einsum 。</p><p>使用 Einsum 好处在于，引入了迭代空间，使得许多<strong>加速器**</strong>设计**中的优化和 tradeoff 都非常清晰。TeAAL 提出了 3 个维度的优化：</p><ul><li><strong>Loop Order</strong>：迭代空间“是<script type="math/tex">[1,M] \times [1,K] \times [1,N]</script>还是<script type="math/tex">[1,K] \times [1,M] \times [1,N]</script>”？这会影响数据是 stationary 的，还是 stream 的。</li><li><strong>Splitting</strong>：运算中我们常常将输入分块计算，也可以视为在对迭代空间分块。</li><li><strong>Work scheduling</strong>：根据迭代空间计算出的张量，是如何摆放的？包括空间和时间维度。</li></ul><p>总之 Einsum 是一个非常适合数学化表述加速器设计的标记。</p><h3 id="1-4-Extended-Einsum"><a href="#1-4-Extended-Einsum" class="headerlink" title="1.4 Extended Einsum"></a>1.4 Extended Einsum</h3><p>传统的 Einsum 是不能指定运算符的，比如说在 Numpy 中，Compute 阶段只能使用乘法，Reduce 阶段只能是加法：</p><pre class="line-numbers language-Python" data-language="Python"><code class="language-Python">np.einsum('mk,kn-&gt;mn', A, B)<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p> 而 Extended Einsum 则允许自定义 Compute 和 Reduce 阶段的运算符，例如：</p><p><img src="/posts/ce241189/-173945389006225.png" alt="img"></p><p><script type="math/tex">\bigwedg</script> 是 Compute 阶段使用的运算符，<script type="math/tex">\bigve</script>是 Reduce 阶段使用的运算符。</p><p>除此之外，Extended Einsum 还可以表达循环，比如说前缀和计算：</p><p><img src="/posts/ce241189/-173945389210827.png" alt="img"></p><p>还可以表达递推式，同样是前缀和计算：</p><p><img src="/posts/ce241189/-173945389430429.png" alt="img"></p><p>有了 Extended Einsum，我们就可以描述 Flash-Attention 这种包含许多复杂运算和递推式的算法。</p><hr><h2 id="二、Contribution"><a href="#二、Contribution" class="headerlink" title="二、Contribution"></a>二、Contribution</h2><h3 id="2-1-Einsum-与-Pass"><a href="#2-1-Einsum-与-Pass" class="headerlink" title="2.1 Einsum 与 Pass"></a>2.1 Einsum 与 Pass</h3><p>本文认为，如果将算子写成 Einsum 的形式，那么是有助于确定算子的 Pass 数的，比如说这个算子，就是 2-Pass：</p><p><img src="/posts/ce241189/-173945389672931.png" alt="img"></p><p>而相同功能的另一个算子，就是 1-Pass：</p><p><img src="/posts/ce241189/-173945389876733.png" alt="img"></p><p>本文认为，迭代空间也可以被表示成一个 fibertree，而根据这些 fibertree 就可以判断 pass。首先，我不知道为什么原本适用于稀疏矩阵表示的 fibertree 要用来表示一个非常稠密的迭代空间（它可能是想说 fibertree 用于表示根据迭代空间生成的那个向量），其次，我不知道为什么表示成了 fibertree，就可以看出来是多少个 Pass。</p><p>它原文中对迭代空间的 fibertree 定义如下，非常的简略：</p><blockquote><p>The is-fibertree is a special tree where each fiber belongs to a rank in the iteration space of the Einsum.</p></blockquote><p>而他介绍的根据 fibertree 识别 Pass 的方法，则依赖于非常主观的“Dependency”，其定义基本上和 Flash-Attention 中的定义一样：</p><blockquote><p>Now, in a scenario where fibers for a particular rank exist in multiple is-fibertrees; in each, they project to the same tensor; and <strong>there is a dependency such that all of the elements of the earlier is-fibertree’s fiber must be read before any element can be read again by the later is-fibertree (for all mappings of the</strong> <strong>cascade**</strong>)**, we refer to that read-read sequence as creating an additional pass.</p></blockquote><p>这种冗余和主观定义的方式，指示它无法编写成一个程序来自动优化 Pass 数目：</p><blockquote><p>We leave a full analysis of the space of pass-reduction approaches to future work.</p></blockquote><h3 id="2-2-用-Einsum-表示-Flash-Attention"><a href="#2-2-用-Einsum-表示-Flash-Attention" class="headerlink" title="2.2 用 Einsum 表示 Flash-Attention"></a>2.2 用 Einsum 表示 Flash-Attention</h3><p>用 Extended Einsum 表示 Flash-Attention，结果如图：</p><p><img src="/posts/ce241189/-173945390147135.png" alt="img"></p><p>文章只是将 Flash-Attention 换了一种标记形式（从伪代码到 Einsum Cascade），其算法的实质并没有发生改变。</p><h3 id="2-3-将-Flash-Attention-Map-到硬件上"><a href="#2-3-将-Flash-Attention-Map-到硬件上" class="headerlink" title="2.3 将 Flash-Attention Map 到硬件上"></a>2.3 将 Flash-Attention Map 到硬件上</h3><p>本文将 Flash-Attention 实现到了 Timeloop and Accelergy 模拟的 spatial 架构上：</p><p><img src="/posts/ce241189/-173945390429437.png" alt="img"></p><p>传统的 Attention 加速器，使用 2D Array 来计算矩阵乘法，使用 1D Array 来计算 softmax，这种安排的缺点在于，1D Array 计算 softmax 非常吃力，进而导致 2D Array 需要等待 1D Array 的计算，造成了低计算利用率。</p><p>但是 Flash-Attention 算法本身就融合 softmax 到前面的计算中，所以有一部分的 softmax 的计算任务，是可以放到 2D Array 中计算的，这样两个部分的计算任务就更加均衡了。</p><p>此外，2D Array 的 fill 和 drain 的开销很大，所以需要使用流水线的方法摊还（amortize）开销。</p><hr><h2 id="三、Evaluation"><a href="#三、Evaluation" class="headerlink" title="三、Evaluation"></a>三、Evaluation</h2><h3 id="3-1-Setup"><a href="#3-1-Setup" class="headerlink" title="3.1 Setup"></a>3.1 Setup</h3><p>实验在 TimeLoop 模拟器上进行（全是 Python 代码），BaseLine 分别是一个未经优化的 Attention 加速器，和 FLAT（经过 Fusion 等优化，但是依然使用普通 Attention 算法的加速器）。</p><p>WorkLoad 有 BERT，TrXL，T5，XLM。</p><h3 id="3-2-Compute-Utilization"><a href="#3-2-Compute-Utilization" class="headerlink" title="3.2 Compute Utilization"></a>3.2 Compute Utilization</h3><p>在真实负载情况下，计算单元利用率的比值：</p><p><img src="/posts/ce241189/-173945390670239.png" alt="img"></p><p>正如前文分析的，Baseline 的 2D Array 受到 1D Array 的拖累，导致利用率极低。</p><p>而在序列长度过长时，传统 Attention 算法会导致 global buffer 溢出，进而计算率下降，而 Flash-Attention 则没有这个问题。</p><h3 id="3-3-SpeedUp"><a href="#3-3-SpeedUp" class="headerlink" title="3.3 SpeedUp"></a>3.3 SpeedUp</h3><p>在 attention 时的加速比：</p><p><img src="/posts/ce241189/-173945390896841.png" alt="img"></p><p>在 inference 时的加速比：</p><p><img src="https://ipads.feishu.cn/space/api/box/stream/download/asynccode/?code=YjAzY2VjN2ZjMjZjYzZhYTlmMTNjY2MyNTg3ZDFiNThfTnRMM0RvUzBHYzVEeVU1djMyakdvdFAzWHlLUUp0TXZfVG9rZW46TFJhcGI1MGZBb0ZhWlh4TnhoNGNBQ2FtbmhpXzE3Mzk0NTM3MDU6MTczOTQ1NzMwNV9WNA" alt="img"></p><p>因为计算单元利用率提高，所以加速比也显著提高。</p><h3 id="3-4-Energy"><a href="#3-4-Energy" class="headerlink" title="3.4 Energy"></a>3.4 Energy</h3><p>在 attention 时的能耗：</p><p><img src="/posts/ce241189/-173945391102343.png" alt="img"></p><p>在 inference 时的能耗：</p><p><img src="https://ipads.feishu.cn/space/api/box/stream/download/asynccode/?code=NjllZGU4M2M4NjM2YTY2ZGJhNjUwOGVhYzBlYWUxNmFfYkdGUm9IZUJnOW9OeTBHS1RZb3hxYVpsMmdLeXZVeE1fVG9rZW46SzliTGJZaXYyb3FVN054SGdWYWNmTDJkbjNjXzE3Mzk0NTM3MDU6MTczOTQ1NzMwNV9WNA" alt="img"></p><p>Flash-Attention 节约了 DRAM 的访存开销。</p><hr><h2 id="四、计算密度"><a href="#四、计算密度" class="headerlink" title="四、计算密度"></a>四、计算密度</h2><p>这篇工作主要结合了前人的工作，许多成果本质上是算法（Flash-Attention）或者开发框架（TeAAL，Timeloop）的成果，而非这篇工作自己的成果。</p><p>随着计算单元数目的增多，Roofline 模型中的硬件的 <script type="math/tex">I_{max}</script>越来越往右移动，这就导致越来越多的算法成为 memory bound 的：</p><p><img src="/posts/ce241189/-173945391334345.png" alt="img"></p><p>有一种解决问题的方式是减少内存读取的次数，比如说 Kernel Fusion：</p><p><img src="/posts/ce241189/-173945391528647.png" alt="img"></p><p>直白的 Fusion 并不会修改算子的实现，它只是将计算的中间结果存在了 On-chip Memory 中，但是 On-chip Memory 空间有限，这就导致一旦存不下来，依然会溢出到 Off-chip Memory 中，最终效果并不好（从上文的 Evaluation 中也可以看出）。</p><p>为了解决溢出问题（或者单纯为了减少访存次数），有一种思路是增加 On-chip Memory 的容量，比如说 IPU，相比于 CPU 和 GPU，就增加了更多的片上 SRAM：</p><p><img src="/posts/ce241189/-173945391724649.png" alt="img"></p><p>但是这种方式存在问题，就是片上 SRAM 的面积过大，IPU 很少去和 GPU 对比单位芯片面积（iso-area）下的性能。</p><p>Flash-Attention 和 FuseMax 我认为是另一种思路的代表，就是“以算代存”，计算的中间结果并存储后供后续使用，而是当需要使用的时候，再次计算一遍，是一种更加“数据流”的方法。通过构造额外的计算，来避免存储（Flash Attention 引入了更多的冗余的计算，但是减少了冗余的存储）：</p><p><img src="/posts/ce241189/-173945392031051.png" alt="img"><img src="/posts/ce241189/-173945392212853.png" alt="img"></p><p>我个人隐隐约约感觉，计算单元和存储单元有某种统一性，如果能把握它并提出一种更好的抽象，或许可以做出一个更本质的 tradeoff。</p>]]></content>
    
    
    <summary type="html">&lt;blockquote&gt;
&lt;p&gt;这篇工作比较缝合，它引用了 3 个 idea：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;https://arxiv.org/abs/2205.14135&quot;&gt;Flash Attention&lt;/a&gt; 和 pass 抽象&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://dl.acm.org/doi/10.1145/3613424.3623791&quot;&gt;TeAAL&lt;/a&gt; 和它使用的 Einsum 规范&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://arxiv.org/abs/2404.11591&quot;&gt;Extended Einsum&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;TeAAL 提出用 Einsum 的形式去描述算子，并指导加速器的设计。但是 Einsum 只能描述仅包含加法和乘法的算子，对于 Flash-Attension 这种包含指数运算（softmax）和迭代运算的算子无法描述，于是作者借用了 Extended Einsum 的形式描述了 Flash Attension 算子并实现了 FuseMax 加速器，同时论证了 pass 抽象的合理性。&lt;/p&gt;
&lt;p&gt;而实际上，TeAAL 提出的用 Einsum 指导加速器设计的思路并没有因为使用了 Extended Einsum 而被拓展；FuseMax 所展现的性能优势，大部分来自于 Flash-Attension 算法本身，而不是其硬件实现。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&quot;一、Background&quot;&gt;&lt;a href=&quot;#一、Background&quot; class=&quot;headerlink&quot; title=&quot;一、Background&quot;&gt;&lt;/a&gt;一、Background&lt;/h2&gt;&lt;h3 id=&quot;1-1-Flash-Attention-Pass&quot;&gt;&lt;a href=&quot;#1-1-Flash-Attention-Pass&quot; class=&quot;headerlink&quot; title=&quot;1.1 Flash Attention, Pass&quot;&gt;&lt;/a&gt;1.1 Flash Attention, Pass&lt;/h3&gt;&lt;p&gt;Flash-Attention 是一种 Attention 算子的实现，相比于传统的实现，它可以降低内存带宽的需求，并且使用更少的片上内存，更适合当前加速器存在的 memory bound。为了达到这个目的，我们需要：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;尽可能少的从内存中读取数据 -&amp;gt; 算法设计的 pass 数要少&lt;/li&gt;
&lt;li&gt;尽可能少使用片上内存 -&amp;gt; tile 后 reduce&lt;/li&gt;
&lt;/ul&gt;</summary>
    
    
    
    <category term="海边拾贝" scheme="https://thysrael.github.io/categories/%E6%B5%B7%E8%BE%B9%E6%8B%BE%E8%B4%9D/"/>
    
    
    <category term="S9课上" scheme="https://thysrael.github.io/tags/S9%E8%AF%BE%E4%B8%8A/"/>
    
    <category term="海边拾贝" scheme="https://thysrael.github.io/tags/%E6%B5%B7%E8%BE%B9%E6%8B%BE%E8%B4%9D/"/>
    
    <category term="直观总结" scheme="https://thysrael.github.io/tags/%E7%9B%B4%E8%A7%82%E6%80%BB%E7%BB%93/"/>
    
  </entry>
  
  <entry>
    <title>Sys4AI-LLM</title>
    <link href="https://thysrael.github.io/posts/7dc4ea13/"/>
    <id>https://thysrael.github.io/posts/7dc4ea13/</id>
    <published>2025-01-30T14:24:19.000Z</published>
    <updated>2025-02-14T16:01:18.844Z</updated>
    
    <content type="html"><![CDATA[<h2 id="一、总论"><a href="#一、总论" class="headerlink" title="一、总论"></a>一、总论</h2><p>当我们提到大模型 LLM 的时候，总是和 Transformer 这种架构联系在一起，似乎只有使用了 Transformer 架构的深度学习模型才配叫作大模型。</p><p>不过以我目前浅薄的认知，我倒觉得 Transformer 并不是 LLM 的核心特征，因为 LLM 的算法变化很快，Transformer 从 2017 年到现在有了多种变体，也有完全不采用 Transformer 架构的 AI。我个人感觉 LLM 的核心有两点：</p><ul><li>模型参数极大：我们认为模型参数越多，模型就越智能。这是“涌现”的一种具体体现。</li><li>采用“预训练-微调-推理”范式：这种范式使得模型的通用性得到了增强，划分了不同的生态位。</li></ul><p>我希望在下文中记录一下关于 LLM 或者 Foundation Model 的基础知识，以避免被这个时代抛下太久。</p><hr><h2 id="二、数学基础"><a href="#二、数学基础" class="headerlink" title="二、数学基础"></a>二、数学基础</h2><h3 id="2-1-张量求导"><a href="#2-1-张量求导" class="headerlink" title="2.1 张量求导"></a>2.1 张量求导</h3><h4 id="2-1-1-规律"><a href="#2-1-1-规律" class="headerlink" title="2.1.1 规律"></a>2.1.1 规律</h4><p>之前我多次学习张量求导的数学定义，但是总感觉非常生硬和无厘头，因为我不清楚到底要求多少次偏导，导数矩阵的形状是什么（甚至有些都不是矩阵了，而是 3 维张量了），还有如何跟我之前学过的数学分析、线性代数知识联系在一起。</p><p>经过又一次的学习，我总结出如下规律：</p><ul><li>导数矩阵分量的个数，是因变量的分量个数与自变量的分量个数的乘积。这个细想下来非常显然，在求导的时候，当然应该对影响每个因变量的每个自变量求偏导，这样的每个结果就是导数矩阵中的一个分量。我们以最经典的雅各比矩阵举例，一个 $M$ 维的向量函数对于 $N$ 维的自变量向量求导，它的雅各比矩阵形状是 $M \times N$ ，也就是有 $MN$ 个分量。</li><li>导数矩阵的形状是出于适配链式求导法则等制定的，在梯度下降法中导数矩阵的形状需要与自变量形状相同。由上一条可知，我们已经可以确定导数矩阵中分量具体是什么了，但是如何排列这些分量组成导数矩阵依然不确定。经过我的学习，我觉得形状没有简单的规律可以总结。其核心在于一定要适用于链式法则，也就是要考虑到所有中间变量并求和（下文会有详述）。我又注意到，为了使梯度下降法生效，那么导数矩阵（也就是梯度矩阵），必须和自变量矩阵形状相同，要不然就无法实现矩阵减法了（对应元素相减）。顺便吐槽一下，梯度下降法并不是那么合理，用自变量减去导数，并没有实际意义，它只是在自变量处于极值点时，达到不动点。</li><li>在 ML 中，张量只是一种表示形式，高维度张量一定最终会被转化成矩阵运算。高维度导数张量是由于因变量是向量或者矩阵导致的，在 ML 中广泛存在向量值函数（比如 $softmax$）或者矩阵值函数（比如 $Attenction \space Score$）。但是不用担心，我们的最终目的是求解损失值函数对各个参数的导数矩阵，因为损失值函数是一个标量函数，所以导数矩阵一定是低维张量（后面有介绍）。</li></ul><h4 id="2-1-2-链式法则"><a href="#2-1-2-链式法则" class="headerlink" title="2.1.2 链式法则"></a>2.1.2 链式法则</h4><p>在标量世界中，对于 $z = g(y), y = f(x)$ ，链式法则通常写做：</p><script type="math/tex; mode=display">\frac{\partial z}{\partial x} = \frac{\partial z}{\partial y} \frac{\partial y}{\partial x}</script><p>那么如果 $x$ 不再是标量，而是一个向量 $X$ 怎么办，那么我们依然可以列出来 $X$ 的任意分量 $x_i$ ，有：</p><script type="math/tex; mode=display">\frac{\partial z}{\partial x_i} = \frac{\partial z}{\partial y} \frac{\partial y}{\partial x_i}</script><p>显然如果 $X$ 是一个矩阵，那么情形也是类似的，对于任意分量 $x_{ij}$ ，有：</p><script type="math/tex; mode=display">\frac{\partial z}{\partial x_{ij}} = \frac{\partial z}{\partial y} \frac{\partial y}{\partial x_{ij}}</script><p>上面的都很简单且显然，那么我们可以思考一下如果 $y$ 不再是标量，而是一个 $N$ 维向量 $Y$ 怎么办？那么 $X$ 的某个分量 $x_i$ 就可以通过影响 $Y$ 的所有分量 $y_1, y_2, \dots, y_n$ 来影响 $z$ ，所以当我们求 $z$ 对 $x_i$ 的偏导的时候，要考虑到所有的 $y_k$ ，所以其形式如下：</p><script type="math/tex; mode=display">\frac{\partial z}{\partial x_{i}} = \sum_{k = 1} ^ N \frac{\partial z}{\partial y_k} \frac{\partial y_k}{\partial x_{i}}</script><p>这个分量形式也可以被整理成更加规整的矩阵乘法形式（毕竟上面就是乘加运算），也就是如下所示：</p><script type="math/tex; mode=display">\frac{\partial z}{\partial \mathbf{X}} = \frac{\partial z}{\partial \mathbf{Y}} \frac{\partial Y}{\partial \mathbf{X}}\\= \begin{bmatrix}\frac{\partial z}{\partial y_1} \frac{\partial z}{\partial y_2} \cdots \frac{\partial z}{\partial y_n}\end{bmatrix}\begin{bmatrix}\frac{\partial y_1}{\partial x_{1}} & \frac{\partial y_1}{\partial x_{2}} & \cdots & \frac{\partial y_1}{\partial x_{m}} \\\frac{\partial y_2}{\partial x_{1}} & \frac{\partial y_2}{\partial x_{2}} & \cdots & \frac{\partial y_2}{\partial x_{m}} \\\vdots & \vdots & \ddots & \vdots \\\frac{\partial y_n}{\partial x_{1}} & \frac{\partial y_n}{\partial x_{2}} & \cdots & \frac{\partial y_n}{\partial x_{m}}\end{bmatrix}</script><p>右边的那个方阵，就是传说中的雅各比矩阵。</p><p>我们在“规律”这一节探讨的求导矩阵的形状问题，其实核心就在于求导矩阵的形状，可以在链式法则中直接应用，而不需要经过大量的 reshape。</p><p>那如果 $X$ 和 $Y$ 有任一方是一个矩阵怎么办？可以想见，此时的雅各比矩阵就不再是二维的了，而是三维张量或者四维张量了。此时就很难整理成矩阵乘法的形式了，但是分量求和公式依然成立。</p><p>而在 ML 实践中，常常因为有些 $\frac{\partial z}{\partial y_k}\frac{\partial y_k}{\partial x_i}$ 项为零，进而可以简化高维张量运算。</p><p>我们来举个例子，以 ML 中常见的全连接层 $Y = WX$ 为例（省略了偏置量 $B$），其中 $X$ 是 $N$ 维向量，$Y$ 是 $M$ 维向量，$W$ 是 $M \times N$ 维矩阵。那么在反向传播中，就有：</p><script type="math/tex; mode=display">\frac{\partial Y}{\partial W} = \begin{bmatrix}\begin{bmatrix}\frac{\partial y_1}{\partial w_{11}} & \frac{\partial y_1}{\partial w_{12}} & \cdots & \frac{\partial y_1}{\partial w_{1n}} \\\frac{\partial y_1}{\partial w_{21}} & \frac{\partial y_1}{\partial w_{22}} & \cdots & \frac{\partial y_1}{\partial w_{2n}} \\\vdots & \vdots & \ddots & \vdots \\\frac{\partial y_1}{\partial w_{m1}} & \frac{\partial y_1}{\partial w_{m2}} & \cdots & \frac{\partial y_1}{\partial w_{mn}}\end{bmatrix} \\\begin{bmatrix}\frac{\partial y_2}{\partial w_{11}} & \frac{\partial y_2}{\partial w_{12}} & \cdots & \frac{\partial y_2}{\partial w_{1n}} \\\frac{\partial y_2}{\partial w_{21}} & \frac{\partial y_2}{\partial w_{22}} & \cdots & \frac{\partial y_2}{\partial w_{2n}} \\\vdots & \vdots & \ddots & \vdots \\\frac{\partial y_2}{\partial w_{m1}} & \frac{\partial y_2}{\partial w_{m2}} & \cdots & \frac{\partial y_2}{\partial w_{mn}}\end{bmatrix}\\\vdots\\\begin{bmatrix}\frac{\partial y_n}{\partial w_{11}} & \frac{\partial y_n}{\partial w_{12}} & \cdots & \frac{\partial y_n}{\partial w_{1n}} \\\frac{\partial y_n}{\partial w_{21}} & \frac{\partial y_n}{\partial w_{22}} & \cdots & \frac{\partial y_n}{\partial w_{2n}} \\\vdots & \vdots & \ddots & \vdots \\\frac{\partial y_n}{\partial w_{m1}} & \frac{\partial y_n}{\partial w_{m2}} & \cdots & \frac{\partial y_n}{\partial w_{mn}}\end{bmatrix}\end{bmatrix}</script><p>这个式子看着就非常恐怖，再进行矩阵运算不得活活难死（其实还好），但是我们注意到对于任意分量 $y_i$ ，它等于：</p><script type="math/tex; mode=display">y_i = \sum_{j = 0}^N w_{ij} x_j</script><p>也就是说，对于特定的 $i$， $y_i$ 不和 $W$ 的所有分量有关，而是只跟 $W$ 第 $i$ 行分量有关，也就是：</p><script type="math/tex; mode=display">\frac{\partial Y}{\partial W} = \begin{bmatrix}\begin{bmatrix}\frac{\partial y_1}{\partial w_{11}} & \frac{\partial y_1}{\partial w_{12}} & \cdots & \frac{\partial y_1}{\partial w_{1n}} \\0 & 0 & \cdots & 0 \\\vdots & \vdots & \ddots & \vdots \\0 & 0 & \cdots & 0 \\\end{bmatrix} \\\begin{bmatrix}0 & 0 & \cdots & 0 \\\frac{\partial y_2}{\partial w_{21}} & \frac{\partial y_2}{\partial w_{22}} & \cdots & \frac{\partial y_2}{\partial w_{2n}} \\\vdots & \vdots & \ddots & \vdots \\0 & 0 & \cdots & 0 \\\end{bmatrix}\\\vdots\\\begin{bmatrix}0 & 0 & \cdots & 0 \\0 & 0 & \cdots & 0 \\\vdots & \vdots & \ddots & \vdots \\\frac{\partial y_n}{\partial w_{m1}} & \frac{\partial y_n}{\partial w_{m2}} & \cdots & \frac{\partial y_n}{\partial w_{mn}}\end{bmatrix}\end{bmatrix}=\begin{bmatrix}\begin{bmatrix}x_1 & x_2 & \cdots & x_n \\0 & 0 & \cdots & 0 \\\vdots & \vdots & \ddots & \vdots \\0 & 0 & \cdots & 0 \\\end{bmatrix} \\\begin{bmatrix}0 & 0 & \cdots & 0 \\x_1 & x_2 & \cdots & x_n \\\vdots & \vdots & \ddots & \vdots \\0 & 0 & \cdots & 0 \\\end{bmatrix}\\\vdots\\\begin{bmatrix}0 & 0 & \cdots & 0 \\0 & 0 & \cdots & 0 \\\vdots & \vdots & \ddots & \vdots \\x_1 & x_2 & \cdots & x_n \\\end{bmatrix}\end{bmatrix}</script><p>其实我们都没有必要再关注这个复杂的 $\frac{\partial Y}{\partial W}$ 的稀疏性质了，我们直接回归本源，我们的核心目的是求解损失函数 $l$ 对 $W$ 的导数，那么按照原本来说，有：</p><script type="math/tex; mode=display">\frac{\partial l}{\partial w_{ij}} = \sum_{k = 0}^M \frac{\partial l}{\partial y_k} \frac{\partial y_k}{\partial w_{ij}}</script><p>又因为在 $i,j$ 确定的情况下， $w_{ij}$ 只会影响 $Y$ 的 $y_i$ 分量，所以上面这个式子就会变化成：</p><script type="math/tex; mode=display">\frac{\partial l}{\partial w_{ij}} = \sum_{k = 0}^M \frac{\partial l}{\partial y_k} \frac{\partial y_k}{\partial w_{ij}} = \frac{\partial l}{\partial y_i}\frac{\partial y_i}{\partial w_{ij}} = \frac{\partial l}{\partial y_i}x_j</script><p>有了这样的化简后，就可以被整理成新的向量乘法，如下所示：</p><script type="math/tex; mode=display">\frac{\partial l}{\partial W} = \frac{\partial l}{\partial Y} X^T</script><p>再次变得简洁优雅。</p><p>这件事情很启发我，我之前学习反向传播时，太关注复杂的神经网络的梯度的张量表示了，动不动就会出现三维或者四维的张量，然后陷入停滞。而实际上，就算在数学上产生了这些拦路虎，我们也并不在意，因为这些高维张量本来就不是我们的目的，它只是链式求和公式的一种形式。我们会重新回到链式求和公式，来构建更加简单的矩阵乘法，而不是固守高维张量。</p><h4 id="2-1-3-标量-张量"><a href="#2-1-3-标量-张量" class="headerlink" title="2.1.3 标量-张量"></a>2.1.3 标量-张量</h4><p>标量对张量进行求导时，生成的导数矩阵和张量（无论张量是标量、向量还是矩阵）的形状完全相同。比如说对于一个 $N$ 维列向量 $X$ ，其导数矩阵如下所示：</p><script type="math/tex; mode=display">\frac{\partial y}{\partial \mathbf{X}} = \begin{bmatrix}\frac{\partial y}{\partial x_1} \\\frac{\partial y}{\partial x_2} \\\vdots \\\frac{\partial y}{\partial x_n}\end{bmatrix}</script><p>而对于 $M \times N$ 维的矩阵求导，其形式也是类似的：</p><script type="math/tex; mode=display">\frac{\partial y}{\partial \mathbf{X}} = \begin{bmatrix}\frac{\partial y}{\partial x_{11}} & \frac{\partial y}{\partial x_{12}} & \cdots & \frac{\partial y}{\partial x_{1n}} \\\frac{\partial y}{\partial x_{21}} & \frac{\partial y}{\partial x_{22}} & \cdots & \frac{\partial y}{\partial x_{2n}} \\\vdots & \vdots & \ddots & \vdots \\\frac{\partial y}{\partial x_{m1}} & \frac{\partial y}{\partial x_{m2}} & \cdots & \frac{\partial y}{\partial x_{mn}}\end{bmatrix}</script><h4 id="2-1-4-张量-张量"><a href="#2-1-4-张量-张量" class="headerlink" title="2.1.4 张量-张量"></a>2.1.4 张量-张量</h4><p>当因变量是张量的时候，就是对于因变量张量的每一个分量都应用一遍上文介绍的“标量-张量”方法。因变量分量会组成导数张量的外层维度，每个元素都是一个“标量-张量”导数矩阵。我们举个例子，有 $2 \times 3$ 维的向量 $X$ 和 $3 \times 2$ 维的 $Y$ 相乘得到 $2 \times 2$ 维的 $Z$ ，对于 $\frac{\partial Z}{\partial X}$ 有：</p><script type="math/tex; mode=display">\frac{\partial Z}{\partial X} =\begin{bmatrix}\frac{\partial z_{11}}{\partial X} & \frac{\partial z_{12}}{\partial X} \\\frac{\partial z_{21}}{\partial X} & \frac{\partial z_{22}}{\partial X} \\\end{bmatrix}=\begin{bmatrix}\begin{bmatrix}\frac{\partial z_{11}}{\partial x_{11}} & \frac{\partial z_{11}}{\partial x_{12}} & \frac{\partial z_{11}}{\partial x_{13}} \\\frac{\partial z_{11}}{\partial x_{21}} & \frac{\partial z_{11}}{\partial x_{22}} & \frac{\partial z_{11}}{\partial x_{23}} \\\end{bmatrix}& \begin{bmatrix}\frac{\partial z_{12}}{\partial x_{11}} & \frac{\partial z_{12}}{\partial x_{12}} & \frac{\partial z_{12}}{\partial x_{13}} \\\frac{\partial z_{12}}{\partial x_{21}} & \frac{\partial z_{21}}{\partial x_{22}} & \frac{\partial z_{21}}{\partial x_{23}} \\\end{bmatrix}\\\begin{bmatrix}\frac{\partial z_{21}}{\partial x_{11}} & \frac{\partial z_{21}}{\partial x_{12}} & \frac{\partial z_{21}}{\partial x_{13}} \\\frac{\partial z_{21}}{\partial x_{21}} & \frac{\partial z_{21}}{\partial x_{22}} & \frac{\partial z_{21}}{\partial x_{23}} \\\end{bmatrix}& \begin{bmatrix}\frac{\partial z_{22}}{\partial x_{11}} & \frac{\partial z_{22}}{\partial x_{12}} & \frac{\partial z_{22}}{\partial x_{13}} \\\frac{\partial z_{22}}{\partial x_{21}} & \frac{\partial z_{22}}{\partial x_{22}} & \frac{\partial z_{22}}{\partial x_{23}} \\\end{bmatrix}\end{bmatrix}</script><p>可以看到最后形成了四维 $2 \times 2 \times 2 \times 3$ 的导数矩阵。</p><p>如果我们考虑“向量-向量”这种特殊形式的求导，就会生成著名的雅可比矩阵（Jacobian Matrix）。考虑 $M$ 维 $Y$ 向量对 $N$ 维 $X$ 向量求导，有：</p><script type="math/tex; mode=display">J = \frac{\partial \mathbf{Y}}{\partial \mathbf{X}} =\begin{bmatrix}\frac{\partial y_1}{\partial x_1} & \frac{\partial y_1}{\partial x_2} & \cdots & \frac{\partial y_1}{\partial x_n} \\\frac{\partial y_2}{\partial x_1} & \frac{\partial y_2}{\partial x_2} & \cdots & \frac{\partial y_2}{\partial x_n} \\\vdots & \vdots & \ddots & \vdots \\\frac{\partial y_m}{\partial x_1} & \frac{\partial y_m}{\partial x_2} & \cdots & \frac{\partial y_m}{\partial x_n}\end{bmatrix}</script><p>这里列出的方阵，横轴是 $x$ 分量，而纵轴是 $y$ 分量。我个人觉得只要保证链式法则的基本要求，似乎转置一下也没有大关系，矩阵形状和矩阵乘法，只不过是一种简写的方式。</p><p>在 ML 中因为向量值函数很常见，所以经常可能会出现高维度张量，它们似乎就无法被擅长矩阵这种低维张量计算的 GPU 或者加速器中处理了，而实际上，正如“链式法则”这一章节中提到的，我们很少真正计算高维度张量。</p><h3 id="2-2-FLOPS"><a href="#2-2-FLOPS" class="headerlink" title="2.2 FLOPS"></a>2.2 FLOPS</h3><h4 id="2-2-1-GEMM"><a href="#2-2-1-GEMM" class="headerlink" title="2.2.1 GEMM"></a>2.2.1 GEMM</h4><p>GEMM 即 General Matrix Multiply ，就是最为常见的矩阵乘法操作。</p><p>对于一个 $M \times K$ 的矩阵与一个 $K \times N$ 的矩阵进行 GEMM 运算，FLOPS 是 $2 MNK$ 。</p><p>这是因为结果矩阵中有 $MN$ 个元素，而每个元素都是一个 $K$ 维行向量和一个 $K$ 维列向量的点积结果。而点积需要进行 $K$ 次乘法操作和 $K - 1$ 次加法操作，故总共需要约 $2K$ 次操作（其实我觉得这里存疑，因为如果是 MAC，Multi-Add 的话，其实点积只需要 $K$ 次操作）。进而 GEMM 需要 $2MNK$ 次操作。 </p><p>总之在 GEMM 中，FLOPS 分别是 3 个维度的一次函数。</p><h4 id="2-2-2-损失函数"><a href="#2-2-2-损失函数" class="headerlink" title="2.2.2 损失函数"></a>2.2.2 损失函数</h4><p>在神经网络中的最后一层，往往输出一个 $N$ 维向量 $Z$ ，我们需要根据向量 $Z$ 来计算损失函数 $l$ ，我们考虑一种最常见的损失函数：</p><script type="math/tex; mode=display">l = \sum^{N}_{i = 1} (z_i - t)^2</script><p>其中 $t$ 是目标期望值，那么就有：</p><script type="math/tex; mode=display">\frac{\partial l}{\partial Z} = 2(Z - T)</script><p>其中 $T$ 是一个每个分量均为 $t$ 的 $N$ 维向量。因为要进行 $N$ 次元素操作，此时的 FLOPS 就是 $N$ 。</p><h4 id="2-2-3-隐藏层"><a href="#2-2-3-隐藏层" class="headerlink" title="2.2.3 隐藏层"></a>2.2.3 隐藏层</h4><p>我们首先定义一下隐藏层，首先我们有一个 $N$ 维的输入向量 $I$ ，他会先经过线性变换变成一个 $M$ 维向量 $Y$ ，如下所示：</p><script type="math/tex; mode=display">Y = WI + B</script><p> 然后经过激活函数 $\sigma(Y)$ 的元素变化进行激活，有：</p><script type="math/tex; mode=display">\sigma(y_i) = \frac{1}{1 + e^{-x}}</script><p>我们记录 $M$ 维向量 $O$ 为激活后的值，即：</p><script type="math/tex; mode=display">O = \sigma(Y)</script><p>我们首先计算正向传播一个向量的 FLOPS。在计算 $Y$ 这个步骤的 FLOPS 是 $2NM$ ，计算 $O$ 这个步骤是 $M$ ，所以总体的 FLOPS 就是 $2NM + M$  （常数凑活看吧，领会精神）。</p><p>然后我们计算反向传播一个向量的 FLOPS。我们还需要定义一些其他辅助计算的符号。反向传播是遵循链式法则的，所以我们在计算当前层时，一定已经有了后面一个隐藏层输入的梯度，而后一个隐藏层的输入就是当前隐藏层的输出，也就是说，我们已知 $\frac{\partial l}{\partial O}$ 的值了。</p><p>在这个反向传播的过程中，我们希望求解参数的梯度 $\frac{\partial l}{\partial W}, \frac{\partial l}{\partial B}$ ，此外，我们还需要求解 $\frac{\partial l}{\partial I}$ ，虽然这个值和当前层的参数更新没有关系，但是上一层的反向传播的参数梯度，需要 $\frac{\partial l}{\partial I}$ ，正如我们需要  $\frac{\partial l}{\partial O}$ 一样。</p><p>首先我们计算激活值的梯度，有</p><script type="math/tex; mode=display">\frac{\partial l}{\partial Y} = \frac{\partial l}{\partial O} \frac{\partial O}{\partial Y}</script><p>又因为有：</p><script type="math/tex; mode=display">\sigma'(x) = \sigma(x) \cdot (1 - \sigma(x))</script><p>所以有：</p><script type="math/tex; mode=display">\frac{\partial O}{\partial Y} = \begin{bmatrix}o_1 (1 - o_1) \\o_2 (1 - o_2) \\\cdots \\o_m (1 - o_m)\end{bmatrix}</script><p>计算 $\frac{\partial l}{\partial Y}$ 的过程总 FLOPS 是 $2M$ ，先计算出 $\frac{\partial O}{\partial Y}$ 的 FLOPS 是 $M$ ，然后 $\frac{\partial l}{\partial O}$ 和 $\frac{\partial O}{\partial Y}$ 对应元素相乘，FLOPS 是 $M$ 。</p><p>然后我们计算权重矩阵的梯度，有：</p><script type="math/tex; mode=display">\frac{\partial l}{\partial W} = \frac{\partial l}{\partial Y} \frac{\partial Y}{\partial W}</script><p>按理说 $\frac{\partial Y}{\partial W}$ 是一个三维张量，比较难处理，但是又因为线性变换的特性（在“链式规则”处证明），有：</p><script type="math/tex; mode=display">\frac{\partial l}{\partial W} = \frac{\partial l}{\partial Y} I^T</script><p>因为 $\frac{\partial l}{\partial Y}$ 是 $M$ 维， $I$ 是 $N$ 维，所以总 FLOPS 是 $MN$ （没有加法过程，所以没有常数 $2$）。但是如果还要考虑用 $\frac{\partial l}{\partial W}$ 来修正 $W$ ，那么总 FLOPS 就是 $2MN$ 。</p><p>然后我们计算偏置量的梯度，有：</p><script type="math/tex; mode=display">\frac{\partial l}{\partial B} = \frac{\partial l}{\partial Y} \frac{\partial Y}{\partial B}</script><p>又因为：</p><script type="math/tex; mode=display">\frac{\partial Y}{\partial B} =\begin{bmatrix}1 \\1 \\\cdots \\1\end{bmatrix}</script><p>所以：</p><script type="math/tex; mode=display">\frac{\partial l}{\partial B} = \frac{\partial l}{\partial Y}</script><p>FLOPS 直接可忽略，如果算上更新 $B$ ，那么 FLOPS 是 $N$ 。</p><p>最后我们还需要计算 $\frac{\partial l}{\partial I}$ ，有：</p><script type="math/tex; mode=display">\frac{\partial l}{\partial I} = \frac{\partial l}{\partial Y} \frac{\partial Y}{\partial I}</script><p>又因为：</p><script type="math/tex; mode=display">\frac{\partial Y}{\partial I} = W^T</script><p>所以总的 FLOPS 是一次 $M$ 维向量与 $M \times N$ 维矩阵乘法的 FLOPS，也就是 $2MN$ 。</p><p>所以总得来看，反向传播的 FLOPS 是 $4MN$ 左右，但是这个值很没有意义，只是说，它的量值依然是正比于输入维度 $N$ 和输出维度 $M$ 。</p><h4 id="2-2-4-Attention"><a href="#2-2-4-Attention" class="headerlink" title="2.2.4 Attention"></a>2.2.4 Attention</h4><p>Softmax 是一个独特的元素映射函数，这里记录一下它的梯度函数。设 softmax 的输入是一个 $N$ 维向量 $Z$ ，输出是一个 $N$ 维向量 $P$ ，有：</p><script type="math/tex; mode=display">\frac{\partial l}{\partial Z} = \frac{\partial l}{\partial P} \frac{\partial P}{\partial Z}</script><p>其中 $\frac{\partial P}{\partial Z}$ 是一个 $N \times N$ 维的雅克比矩阵。有如下定理，当 $i = j$ 时：</p><script type="math/tex; mode=display">\frac{\partial p_{i}}{\partial z_j} = p_i(1 - p_i)</script><p>当 $i \ne j$ 时：</p><script type="math/tex; mode=display">\frac{\partial p_{i}}{\partial z_j} = -p_ip_j</script><p>那么这里的反向传播的本质也是一个矩阵与向量乘法，FLOPS 大约是 $N^2$ 。</p><p>而 Attention 的其他部分用到了在隐藏层中没有出现过的矩阵乘法，比如说 $QK^T$ 计算，看似会产生四维张量，实际上和线性变换类似，非常直观，设：</p><script type="math/tex; mode=display">S = \frac{QK^T}{\sqrt{d_k}}</script><p>有：</p><script type="math/tex; mode=display">\frac{\partial l}{\partial Q} = \frac{\partial l}{\partial S} \frac{\partial S}{\partial Q} = \frac{1}{\sqrt{d_k}} \frac{\partial l}{\partial S} K \\\frac{\partial l}{\partial K} = \frac{\partial l}{\partial S} \frac{\partial S}{\partial K} = \frac{1}{\sqrt{d_k}} \frac{\partial l}{\partial S} Q</script><p>因此依然是矩阵与向量乘法的 FLOPS，FLOPS 是 $Q,K$ 维度的乘积，也就是 $seq_len \times d_{k}$ 。</p><h3 id="2-3-Im2Col"><a href="#2-3-Im2Col" class="headerlink" title="2.3 Im2Col"></a>2.3 Im2Col</h3><p>IM2Col 的意思是 Image To Column，本质是将卷积计算转换成矩阵乘法，然后因为矩阵乘法已经被优化得很好了，所以可以加速计算。如下所示：</p><p><img src="/posts/7dc4ea13/image-20250202175313184.png" alt="image-20250202175313184"></p><p>但是这种方式并不从理论上减少计算的复杂度，只是比较简单实现，并且效果较好。此外 FFT 也可以用于加速卷积计算，并且是理论上加速。</p><hr><h2 id="三、Transformer"><a href="#三、Transformer" class="headerlink" title="三、Transformer"></a>三、Transformer</h2><h3 id="3-1-Embedding"><a href="#3-1-Embedding" class="headerlink" title="3.1 Embedding"></a>3.1 Embedding</h3><p>我们都知道人工神经网络中每一层的神经网络都可以对前一层输入进行一次矩阵运算（如果刨除激活不算的话），从线性代数的知识可知，这其实是在做一次空间映射，如果矩阵是 $M \times N$ 的，那么每经过一层，就是将一个原本在 $M$ 维空间向量映射到一个 $N$ 维的空间中。</p><p>人工神经网络的原理是将一段数据先 tokenize ，也就是将原本的字符串之类（比如我们和 chatgpt 说的话）的东西转换成一组一维的向量，每个标量被称为一个 token ，然后将他们映射到一个向量空间中，这个过程叫做“嵌入”（embedding），然后就是对于这个向量的一次次映射。</p><p>那么我们这样做的直观理解是什么，我觉得是这样的，人工神经网络是在描述语义。说白了，就是通过构建一个语义空间的方式去掌握各个 token 的语义，语义空间就是一个多维向量空间。那么为什么一个多维向量空间就可以描述语义呢？因为多维向量空间中存在距离，我们可以用距离的方式来描述两个 token 的相似性，而这就构成了语义。比如在一个空间中，当我们观测到“苹果，梨，香蕉”的距离很近，那么可能就是因为她们都具有水果的语义。</p><p>语义空间的设计有两个极端，一个是一维标量，另一个是独热码。如果用一维标量的话，有些复杂的语义没有办法表示，比如说“苹果”，它既有“水果”的意思，又有“电子品牌”的意思，那么它应该既和“香蕉”离得近，又和“三星”离得近，但是“香蕉”和“三星”不应该离那么近。而独热码则是尽可能的扩大自己的维度，并只使用一个维度，那么我们很难表示出相近的含义，因为独热码的所有点的距离都是相同的。</p><p>Embedding 的维度通常被称为 $d_{model}$ 。</p><p>此外，为了将位置信息（Position），也就是当前 token 在序列中的位置考虑在内，我们还要经过一个位置编码（Position Encoding）的过程，说白了就是将位置编码进去，非常显然。</p><h3 id="3-2-Attention"><a href="#3-2-Attention" class="headerlink" title="3.2 Attention"></a>3.2 Attention</h3><p>Transformer 最初开发出来被用于进行机器翻译，其中最有特色的点就在于使用了 Attention 机制。为了理解 Attention 机制，有必要了解一下在 Transformer 提出之前，人们是怎样进行机器翻译的。</p><p>我最初的理解是，机器翻译就是存着一个字典，然后一个词一个词的翻译就够了（也就是只进行依次 embedding 和逆向 embedding 的过程）。但是仔细一想就不太可能，这是因为不同语言之间并不是只需要逐词翻译，因为语法的不同，导致不同语言的上下文顺序也是不同的。所以人们最先设计出的机器翻译机制，是让每个句子对应一个向量，被称作 Context Vector，在翻译的时候，先用神经网络将句子编码成 Context Vector，然后再用神经网络解码成另一门语言的句子，如下图所示：</p><p><img src="/posts/7dc4ea13/image-20250202211138372.png" alt="image-20250202211138372"></p><p>至于为什么要使用 RNN，将 token 一个个喂入神经网络，而不是一股脑将整个句子当作输入一口气喂进去。是因为翻译的难点在于理解上下文，RNN 可以更好的发现序列之间的关系。</p><p>但是这种方式也存在缺点，那就是 context vector 的维度是有限的，而句子的量级显然不是 context vector 所能容纳的，所以这种方法的效果并不好，而如果我们减小句子的范围，那么就又不利于长上下文的理解。此外，这个方法的并行度也非常差，是串行输入每一个 token 。</p><p>Attention 机制就是解决这个问题的。它的最本质思想是，上下文关系如果存储在隐藏层或者 context vector 中，很容易受到维度的限制，那么我们就专门用一个方阵 $A$ ，用 $a_{ij}$ 记录第 $i$ 个 token 和第 $j$ 个 token 之间的联系，根据这个方阵再结合每个 token 的语义，来确定输出。</p><p>那么 Attention 具体是怎样的呢？首先我们需要先介绍 Attention 的输入。经过 Embedding 过程，每个 token 都是一个 $1 \times d_{model}$ 维的行向量。</p><p>我们设序列长度为 $t$ ，那么输入可以被整理成一个 $t \times d_{model}$ 的矩阵 $X$。</p><p>那么我们如何获得 $A$ 呢（学名叫作 $Attention \space Score$）？很简单，我们可以用向量内积的思想，如果两个向量的内积很大，就说明两个向量离得很近，因为如果二者夹角很小的话，那么内积就会增大。虽然这并不严谨，但是这基本上就是它的思想了。于是我们有了：</p><script type="math/tex; mode=display">A = XX^T</script><p>也就是说有：</p><script type="math/tex; mode=display">a_{ij} = x_i x_j^T</script><p>所以 $a_{ij}$ 就可以表示第 $i$ 个 token 和第 $j$ 个 token 之间的相似度。$A$ 是一个 $t \times t$ 的方阵。</p><p>当然在有了 $A$ 并不够，我们只是获得了不同 token 之间的联系，但是我们并没有考虑原本 token 的语义，所以我们再将 $A$ 与 $X$ 相乘，那么就可以得到一个新的 $t \times d_{model}$ 的矩阵 $Y$ ，如下所示：</p><script type="math/tex; mode=display">Y = AX = XX^TX</script><p>我们将 $Y$ 视为多个 token 的集合，那么对于第 $i$ 个 token，也就是第 $i$ 行的行向量，有：</p><script type="math/tex; mode=display">Y_i = \sum^t_{j = 0} a_{ij} X_j</script><p>现在让我们重新回顾这个模型，我们的输入是一个含有 $t$ 个 token 的集合 $X$ ，输出依然是含有 $t$ 个 token 的集合 $Y$ 。此时 $Y$ 中的每个 token，都是 $X$ 中所有 token 的语义的加权和，权重是 $X$ 中对应的 token 与其他剩余 token 的相关性。在 $X$ 中每个 token 的语义都是独立的（每个 token 单独进入网络层），经过 Attention 机制后，具有相似语义的 token 会互相影响，此时 $Y$ 中的每个 token 都是携带上下文信息的。</p><p>下面举个例子，有 $d_{model} = 4, t = 6$ ，如下所示： </p><p><img src="/posts/7dc4ea13/attention1.drawio.png" alt=""></p><p>这里我有一个有趣的思考，就是并不是所有的模型都可以随着规模增大而性能更好。比如说 RNN 相比于传统的多层感知机，就可以有更多的层数，这是因为 RNN 削弱因层数增多而导致的“梯度消失”现象。但是正如前所述，虽然 RNN 避免了“梯度消失”，但是过于串行化的算法和较低的状态维度（我觉得这点可能可以改进），导致我们无法进一步扩大模型规模。而基于 Attention 机制的 Transformer 模型则有更好的可拓展性，并行化程度高，所以才能在更大规模时有更加智能的表现。</p><h3 id="3-3-Cross-Attention"><a href="#3-3-Cross-Attention" class="headerlink" title="3.3 Cross-Attention"></a>3.3 Cross-Attention</h3><p>上文介绍的 Attention 机制和”Attention is All you Need“这篇论文中的并不太一样，这是因为我在上面只是介绍了最为基础的 Attention 原理，在下文中我会进一步拓展这个机制。</p><p>首先我们注意到，上文中计算 $Y$ 的公式，只有一个输入 $X$ ，如下所示：</p><script type="math/tex; mode=display">Y = XX^TX</script><p>那么这里面的 $X$ 的含义都一样吗？其实并不应该一样，还是以机器翻译来举例，如果输入只有一个 $X$ ，那么谈什么翻译呢？如果希望将中文翻译成英语，怎么也得有 3 个输入，也就是：</p><ul><li>待翻译的中文</li><li>中译英字典（语料库）的索引</li><li>中译英字典（语料库）的内容</li></ul><p>Attention 机制是可以满足这 3 种输入的，正好 $Y$ 的表达式中有 3 个 $X$ ，他们可以被差异化成如下公式：</p><script type="math/tex; mode=display">Y = AV = QK^TV</script><p>此时各个字符的含义如下：</p><ul><li><p>$Q$：Query，即要翻译的中文语句，它的形状是 $t_{sen} \times d_{in}$ 。</p><ul><li>$t_{sen}$ 被理解成语句的长度。</li><li>$d_{in}$ 是表示一个中文 token 语义所需的分量个数。</li></ul></li><li><p>$K$：Key，即中译英字典（语料库）的索引，它的形状是 $t_{all} \times d_{in}$ 。</p><ul><li>$t_{all}$ 可以被理解成所有中文语料的个数。</li></ul></li><li><p>$A$：Attention Score，依然是相关性分数，它的形状是 $t_{sen} \times t_{all}$ 。</p><ul><li>分量 $a_{ij}$ 表示待翻译的中文语句中的第 $i$ 个 token 和语料库中的第 $j$ 个语料的相关性。这很合理，我们查字典的过程，不就是根据待翻译的中文语句中的字，来查询对应的英文吗？</li><li>Attention 对应的就是”查字典“这个过程，只不过”查字典“可以查到准确的单词，而在复杂的翻译过程中，只能查询到与 token 语义相近的语料。</li></ul></li><li><p>$V$：Value，即中译英字典（语料库）的内容，它的形状是 $t_{all} \times d_{out}$ 。</p><ul><li>$d_{out}$ 是表示一个英文 token 语义所需的分量个数。</li></ul></li><li><p>$Y$：Output，即翻译好的英文语句，它的形状是 $t_{sen} \times d_{out}$ 。</p><ul><li>它的每个行向量都是一个英文的 token。</li><li>它是 $A$ 和 $V$ 的乘积，也就是每个英文的 token，都是中译英语料库中以相关性为权重形成的加权和。</li></ul></li></ul><p>上面这个中译英的例子可能还不是那么直观，具体的例子很难举，因为语言和数字的对应还是有些难度的。我们举另一个例子，我们进行一个”成绩-能力“的翻译。也就是我们有上一届同学的考试成绩，还有他们的学习能力，我们希望根据当前这届同学的成绩，来推测他们的学习能力是怎样的，完成一个从”成绩“到”能力“的翻译。</p><p>考试一共有”数学“和”语文“ 2 个科目，成绩是 5 分制。学习能力一共有”记忆“、”创新“和”勤奋“ 3 种。数据都是我瞎编的，勿杠。</p><p>当前这届同学的成绩就构成了 $K$ 矩阵，其中：</p><ul><li>$t_{sen}$ 为 2，表示这届两名同学 s1 和 s2</li><li>$d_{in}$ 为 2，表示 2 门考试科目。</li></ul><p>$K$ 如下所示：</p><div class="table-container"><table><thead><tr><th></th><th>数学</th><th>语文</th></tr></thead><tbody><tr><td>s1</td><td>5</td><td>2</td></tr><tr><td>s2</td><td>1</td><td>5</td></tr></tbody></table></div><p>往届同学的成绩构成了 $Q$ 矩阵，其中 $t_{all}$ 为 3，表示前一届的 3 名同学 s3, s4 和 s5 。$Q$ 如下所示：</p><div class="table-container"><table><thead><tr><th></th><th>数学</th><th>语文</th></tr></thead><tbody><tr><td>s3</td><td>2</td><td>5</td></tr><tr><td>s4</td><td>4</td><td>1</td></tr><tr><td>s5</td><td>3</td><td>3</td></tr></tbody></table></div><p>又因为 $A = QK^T$ ，如下所示：</p><div class="table-container"><table><thead><tr><th></th><th>s3</th><th>s4</th><th>s5</th></tr></thead><tbody><tr><td>s1</td><td>20</td><td>22</td><td>21</td></tr><tr><td>s2</td><td>27</td><td>9</td><td>20</td></tr></tbody></table></div><p> 可以看到非常合理，s1 擅长数学而不擅长语文，s4 也是如此，所以在 3 名往届学生中，s4 和 s1 最像，相关性也是最高的（22）。s2 擅长语文而不擅长数学，与 s3 最为相似，可以看到相关性也很高（27）。</p><p>往届同学的能力构成了 $V$ 矩阵，其中 $d_{out}$ 为 3，对应 3 种能力，如下所示：</p><div class="table-container"><table><thead><tr><th></th><th>记忆</th><th>创新</th><th>勤劳</th></tr></thead><tbody><tr><td>s3</td><td>15</td><td>6</td><td>7</td></tr><tr><td>s4</td><td>3</td><td>12</td><td>5</td></tr><tr><td>s5</td><td>9</td><td>9</td><td>6</td></tr></tbody></table></div><p>在我编的这个情景下，”记忆“越好，”语文“成绩就越高；”创新“越好，”数学“成绩就越高；”勤劳“越好，总成绩就越高。可以看到基本上都是合理的，比如 s3 擅长语文，它的”记忆“能力就比”创新“能力好。</p><p>然后我们用 $Y = AV$ 来看看当前这届同学的能力，有：</p><div class="table-container"><table><thead><tr><th></th><th>记忆</th><th>创新</th><th>勤劳</th></tr></thead><tbody><tr><td>s1</td><td>555</td><td>573</td><td>376</td></tr><tr><td>s2</td><td>612</td><td>450</td><td>354</td></tr></tbody></table></div><p>可以看到基本上还是合理的（当然我们也不能指望着只有 3 个数据的数据集有多准确）。s1 的数学成绩很高而语文成绩很差，按理说他的“创新”能力应该是高于“记忆”能力的；s2 的语文成绩很高而数学成绩很差，按理说他的“记忆”能力是高于“创新”能力的。这些推理都被 $Y$ 体现了。</p><p>当然 $Y$ 也存在两个问题：</p><ul><li>能力绝对值过大了，在 $V$ 矩阵中能力值都是两位数，而在 $Y$ 中都是 3 位数，很夸张。</li><li>能力相对值不明显，以 s1 同学为例，明明“数学”成绩比“语文”成绩高 3 分，但是“记忆”能力和“创新”能力却相差不大。</li></ul><p>第一个问题主要是因为 $A$ 矩阵没有按行归一化导致的，按理说加权和里的权重应该是一个“百分比”，而我们没有归一化，所以绝对值会偏大。而第二个问题是因为在数据集中，只有 s4 一个同学和 s1 一样是“数学比语文高”，而且 s4 还不如 s1 成绩好，所以 s1 的能力很容易被 s3 和 s5 的数据干扰，如果有办法让与 s1 更相似的同学（也就是 s4）相比于不相似的同学更突出。</p><p>上述两个问题都可以使用 $softmax$ 来改善，这是一个作用于向量的向量函数，如下所示：</p><script type="math/tex; mode=display">\sigma(\mathbf{z})_i = \frac{e^{z_i}}{\sum_{j=1}^{n} e^{z_j}}</script><p>可以看到这是一个归一化函数，所以解决了第一个问题。而 $softmax$ 中使用的指数函数，使得相关性高的分量变得更加明显，所以解决了第二个问题。</p><p>我们用 $softmax$ 来修正 $A$ ，$softmax$ 对矩阵作用，本质就是对矩阵中的每一个行向量作用，修正后的 $A$ 如下所示：</p><div class="table-container"><table><thead><tr><th></th><th>s3</th><th>s4</th><th>s5</th></tr></thead><tbody><tr><td>s1</td><td>0.09</td><td>0.67</td><td>0.24</td></tr><tr><td>s2</td><td>0.99</td><td>0</td><td>0</td></tr></tbody></table></div><p>可以看到这时的相关性非常完美，按照修正后的 $A$ 计算修正后的 $Y$：</p><div class="table-container"><table><thead><tr><th></th><th>记忆</th><th>创新</th><th>勤劳</th></tr></thead><tbody><tr><td>s1</td><td>5.5</td><td>10.7</td><td>5.4</td></tr><tr><td>s2</td><td>15.0</td><td>6.0</td><td>7.0</td></tr></tbody></table></div><p>可以看到非常合理。</p><p>此外，$A$ 还有一个问题，就是当 $d_{in}$ 过大时， $QK^T$ 很容易产生数值很大的分量。</p><p>所以在实践上，我们需要对每个分量除以 $\sqrt{d_{in}}$ 来避免数据的溢出，这个过程被称为 scale。</p><p>综上所述，我们得出了一个和最终版本非常像的算子，如下所示：</p><script type="math/tex; mode=display">Y = softmax(\frac{QK^T}{\sqrt{d_{in}}})V</script><p>当 $Q, K, V$ 来源不相同时，我们称之为 Cross-Attention，即交叉注意力机制，常用于机器翻译。而当 $Q, K, V$ 来源相同时，则被称为 Self-Attention 机制，常用于发现上下文联系，理解或者产生新的语义。</p><p>我们看一下 Transformer 的架构图：</p><p><img src="/posts/7dc4ea13/image-20250204155327984.png" alt="image-20250204155327984"></p><p>我们以“中译英”来距离， <code>inputs</code> 就是要中译英的语料库，<code>outputs</code> 刚开始就是要翻译的中文 ，<code>output probabilities</code> 是翻译好的英文（之所以叫作 probalities，应该是因为这里采用了 Self-Regression 架构）。在右上角的橙色 Attention 块中，<code>inputs</code> 负责提供 $K, V$ ，而 <code>outputs</code> 提供 $Q$。</p><p>那么如果在 Self-Attention 中，还有必要区分 $Q, K, V$ 吗？还是说只要像最开始那样，直接使用 $X$ 就好了呢？其实还是有必要区分 $Q, K, V$ 的，在上面的介绍中可以看出， $Q, K, V$ 是各司其职，所以即使在 Self-Attention 中，也是有这样的分工。我们可以使用三个权重矩阵，来使得来源相同的 $Q, K, V$ 有不同的作用，如下所示：</p><script type="math/tex; mode=display">Q = X W_Q \\K = X W_K \\V = X W_V</script><p>这样做，还可以改变 $Q, K, V$ 的形状，他们不再必须和 $X$ 保持相同的形状 $t \times d_{model}$ ，而是可以变成 $t \times d_k$ 和  $t \times d_v$ 。之所以没有 $d_q$ ，是因为 $d_q$ 和 $d_k$ 是相等的。</p><h3 id="3-4-Self-Regression"><a href="#3-4-Self-Regression" class="headerlink" title="3.4 Self-Regression"></a>3.4 Self-Regression</h3><p>正如前文所述，Attention 机制最初用于机器翻译，所以其核心部分是 Cross-Attention。而如今大火的生成式（Generative）大模型，则对原始模型的一个改进。也就是“自回归”（Self-Regression）。</p><p>自回归的意思是，将输出重新作为输入，用于产生新的输出，周而复始。这个概念还比较好理解，问题在于它和 Attention 机制并不搭配，如下所示：</p><script type="math/tex; mode=display">Y = softmax(\frac{QK^T}{\sqrt{d_{in}}})V</script><p>最后生成的是一个 $t \times d_{v}$ 的矩阵 $Y$ ，在机器翻译中，这就是那个翻译好的英文句子。但是在生成式中呢？难道就是把 prompt 翻译了吗？显然不是的，实际上 self-regression 的设计非常“浪费”，它只会选取 $Y$ 的最后一个行向量，作为生成出来的 token 输出，并将这个 token 连接 $X$ 的最后面，其伪代码如下：</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">generative</span><span class="token punctuation">(</span>prompt<span class="token punctuation">)</span><span class="token punctuation">:</span>    X <span class="token operator">=</span> prompt             <span class="token comment"># prompt 是最开始的输入</span>    R <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>                 <span class="token comment"># Result 最开始为空</span>        <span class="token keyword">while</span> <span class="token boolean">True</span><span class="token punctuation">:</span>        Y <span class="token operator">=</span> attention<span class="token punctuation">(</span>X<span class="token punctuation">)</span>   <span class="token comment"># 进行 attention 机制</span>        y <span class="token operator">=</span> Y<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">:</span><span class="token punctuation">]</span>         <span class="token comment"># 取最后一个 token</span>        <span class="token keyword">if</span> y <span class="token operator">==</span> <span class="token string">'&lt;EOS&gt;'</span><span class="token punctuation">:</span>   <span class="token comment"># 如果是 End of Sequence，则退出循环</span>            <span class="token keyword">break</span>        R <span class="token operator">+=</span> y             <span class="token comment"># 记录 token 作为输出</span>        X <span class="token operator">+=</span> y             <span class="token comment"># 将 token 作为输入</span>        <span class="token keyword">return</span> R<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>这种“浪费”会被下文的 KV-Cache 缓解。</p><h3 id="3-5-Encoder-Decoder"><a href="#3-5-Encoder-Decoder" class="headerlink" title="3.5 Encoder Decoder"></a>3.5 Encoder Decoder</h3><p>我们从上面的 Transformer 架构中注意到，上面一共有 3 种 Attention，我们详细介绍过的是位于右上角的 cross attention 块。在左下和右下还有两个 self-attention 快，分别是 encode-attention 和 decode-attention。</p><p>这两种 attention 实现的都不是翻译任务，而是一种“让 token 关注上下文语义”的任务。通过 attention，原本独立的 token 语义会在上下文的影响下发生变化，这对之后的 cross-attention 是一种帮助。</p><p>但是为什么 decoder-attention 相比于 encode-attention，多了一个 Sequence Mask 机制，它说得是对于 $A$ 矩阵中的 $a_{ij}$ ，如果有 $j &gt; i$ ，那么就会被 $softmax$ 忽略。这样的目的是确保模型在生成当前词时，只能使用当前词及其之前的词，而不能“偷看”未来的词。而 encoder 就没有这个问题，为了获得语料库中的所有语义，Encoder 是允许使用全部上下文的。</p><p>这里有个问题，就是在 Self-Regression 中，本来就是逐词生成的，在当前词没有生成的时候，未来的词也肯定没有生成，那么就算模型想偷看，也偷看不成。为了解释清楚，我们就需要理解逐词生成是推理的行为，而在训练的时候，模型是并行处理整个目标序列的，所以才需要掩码。</p><h3 id="3-5-Multi-Head"><a href="#3-5-Multi-Head" class="headerlink" title="3.5 Multi-Head"></a>3.5 Multi-Head</h3><p>除了计算资源的浪费之外，我们还注意到 Self-Attention 的并行度又变差了。本来在机器翻译中，Attention 机制改进了 RNN 每个 token 逐个翻译的缺点，可以并行生成一整个输出语句（也就是 token 集合 $Y$）。但是在这个算法中，并行生成的 $Y$ 只用最后一个 token 的行向量 $y$ ，就又变成串行生成了。</p><p>但是这种“串行生成”是 self-regression 的精髓，所以我个人感觉很难改变。但是我们依然有办法加速，那就是每次 attention 的时候通过减少 $d<em>k, d_v$ 来提高速度。这种缩减 $d_k, d_v$ 的行为，可以理解为在原本 $d</em>{model}$ 的空间里提取特征。</p><p>那么仅提供一个特征，就容易导致精度丧失，所以我们可以使用多个 attention，提取多个不同的特征，最后再将结果拼接在一起，这样提高了并行度和延迟，又不损失精度。我们设模型的 head 数为 $h$ ，通常有：</p><script type="math/tex; mode=display">d_{model} =  h \cdot d_k</script><p>我们举一个例子，有参数：</p><ul><li>$d_{model} = 4$</li><li>$t = 6$</li><li>$h = 2$</li><li>$d_k = 2$</li></ul><p>示意图如下：</p><p><img src="/posts/7dc4ea13/attention2.drawio.png" alt=""></p><h3 id="3-6-KV-Cache"><a href="#3-6-KV-Cache" class="headerlink" title="3.6 KV Cache"></a>3.6 KV Cache</h3><p>正如前所述，在 Self-Regression 中我们计算 $Y$ 的目的只是为了得到最后一个行向量 $Y_t$ ，在上述计算中，有很多计算是冗余的，我们在上图中用“实心”标出计算 $Y_t$ 所需要的分量：</p><p><img src="/posts/7dc4ea13/attention3.drawio.png" alt=""></p><p>也就是说，只需要 $Q$ 的最后一个行向量，全部的 $K, V$ 向量，就可以满足计算要求，我们并不需要全部的 $Q$ 。</p><p>更进一步，因为 $K, V$ 都是逐步增长的，也就是每次增加最后一个横向量，所以前面的部分都是可以被 cache 的，避免了 $X$ 每次都需要与 $W$ 进行运算，如果对 $K,V$ 进行 cache（用“交叉线”填充），那么计算量会进一步减少：</p><p><img src="/posts/7dc4ea13/attention4.drawio.png" alt=""></p><p>但是因为 $KV$ 的形状都包括一个 $t$ ，所以在长上下文场景下（也就是 $t$ 很大），会导致缓存的数据很多，这样</p>]]></content>
    
    
    <summary type="html">&lt;h2 id=&quot;一、总论&quot;&gt;&lt;a href=&quot;#一、总论&quot; class=&quot;headerlink&quot; title=&quot;一、总论&quot;&gt;&lt;/a&gt;一、总论&lt;/h2&gt;&lt;p&gt;当我们提到大模型 LLM 的时候，总是和 Transformer 这种架构联系在一起，似乎只有使用了 Transformer 架构的深度学习模型才配叫作大模型。&lt;/p&gt;
&lt;p&gt;不过以我目前浅薄的认知，我倒觉得 Transformer 并不是 LLM 的核心特征，因为 LLM 的算法变化很快，Transformer 从 2017 年到现在有了多种变体，也有完全不采用 Transformer 架构的 AI。我个人感觉 LLM 的核心有两点：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;模型参数极大：我们认为模型参数越多，模型就越智能。这是“涌现”的一种具体体现。&lt;/li&gt;
&lt;li&gt;采用“预训练-微调-推理”范式：这种范式使得模型的通用性得到了增强，划分了不同的生态位。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;我希望在下文中记录一下关于 LLM 或者 Foundation Model 的基础知识，以避免被这个时代抛下太久。&lt;/p&gt;</summary>
    
    
    
    <category term="Sys4AI" scheme="https://thysrael.github.io/categories/Sys4AI/"/>
    
    
    <category term="直观理解" scheme="https://thysrael.github.io/tags/%E7%9B%B4%E8%A7%82%E7%90%86%E8%A7%A3/"/>
    
    <category term="S9假期" scheme="https://thysrael.github.io/tags/S9%E5%81%87%E6%9C%9F/"/>
    
    <category term="Sys4AI" scheme="https://thysrael.github.io/tags/Sys4AI/"/>
    
  </entry>
  
  <entry>
    <title>计算机系统-分布式</title>
    <link href="https://thysrael.github.io/posts/47da48a7/"/>
    <id>https://thysrael.github.io/posts/47da48a7/</id>
    <published>2025-01-16T06:49:42.000Z</published>
    <updated>2025-01-18T14:37:11.432Z</updated>
    
    <content type="html"><![CDATA[<h2 id="一、分布式系统"><a href="#一、分布式系统" class="headerlink" title="一、分布式系统"></a>一、分布式系统</h2><h3 id="1-1-总论"><a href="#1-1-总论" class="headerlink" title="1.1 总论"></a>1.1 总论</h3><p>分布式系统指的是利用多个单体计算机系统构建的多体计算机系统。</p><p>与并行计算不同，分布式系统更侧重于用多个计算实体完成<strong>非常多个</strong>细碎的任务。而并行计算侧重于利用多个计算实体来更快更高效地完成<strong>一个</strong>计算任务。</p><p>分布式系统包括了执行流的分布式和数据的分布式。在北航 OO 课电梯问题中，涉及了多线程，属于是执行流的分布式，这就导致我以为分布式只是执行流的分布式，涉及的问题只是互斥和同步，这是非常片面的。数据的分布式指的是，存在多个数据副本，cache 就是一种数据分布式的实体。</p><h3 id="1-2-背景"><a href="#1-2-背景" class="headerlink" title="1.2 背景"></a>1.2 背景</h3><p>分布式系统虽然出现在各个系统层次，比如说多核的 CPU，多级存储系统，多线程的程序，分布式式的 Web APP。但是大部分的分布式理论都源于 Web APP，这是因为 Web 时代发展的红利导致的。</p><p>传统的 Web APP 架构被称为 LAMP，即 Linux + Apache + MySQL + PHP。</p><p>LAMP 的拓展性并不符合要求，其核心原因在于 Web APP 的用户拓展性非常好，一个用户生产 1M 的数据（非常小），那么一百万个用户就会生产出 1T 的数据，这就不再是一个磁盘可以简单存放的了，我们就需要一个存储的集群了。及时人们可以制造出一个非常大的磁盘，但是它的速度一定是会受到影响的。</p><p>计算也是同理，可能一个用户请求的计算量并不大，但是一百万个用户的计算量就非常大了。而受到摩尔定律和登纳德缩放定律失效的影响，人们是无法制造出一个超级强悍的单体芯片的，这就导致必须使用多个芯片。</p><p>这个时候将系统从单机拓展成分布式系统，就非常自然了。</p><h3 id="1-3-组成"><a href="#1-3-组成" class="headerlink" title="1.3 组成"></a>1.3 组成</h3><p>下面会介绍一个分布式的 Web APP （电商平台）由哪几个部分组成，其架构如图所示：</p><p><img src="/posts/47da48a7/image-20250116163924056.png" alt="image-20250116163924056" style="zoom:40%;"></p><p>存在如下分布式：</p><ul><li>外存的分布式：将数据存放在多个外存服务器上，也就是分布式的文件系统和分布式的数据库。</li><li>内存的分布式：分布式外存无法高效的缓存数据，且 APP 所在的单机的内存不够大，所以将内存也进拓展，也就是 Memcached</li><li>app 的分布式：app 不需要部署在同一个单机上，可以部署在不同单机上，每个单机负责不同的功能。</li><li>Load Balance：仅存在一个 app 依然非常局限，可以在多个单机上启动多个相同的 app，再由 Load Balancer 来决定请求发往哪个更为空闲的单机。这种技术除了依赖负载平衡技术外，还依赖 HTTP 协议的无状态性，使得负载均衡可以做得很轻松，如果是有状态的，那么负载均衡调度的就不再只是请求，就还包括之前的状态信息。</li><li>CDN：将一些多媒体资源，放置在距离用户更近的地方。</li><li>Compute 的分布式：将大量的计算任务放在单独的集群上（这张图上好像没有）。</li></ul><h3 id="1-4-CAP-理论"><a href="#1-4-CAP-理论" class="headerlink" title="1.4 CAP 理论"></a>1.4 CAP 理论</h3><h4 id="1-4-1-介绍"><a href="#1-4-1-介绍" class="headerlink" title="1.4.1 介绍"></a>1.4.1 介绍</h4><p>CAP 指的是分布式的三种重要属性，之所以将它们三个单独拎出来，是因为这三个属性构成了一个不可能三角（我也不知道有没有严格数学证明）。</p><p>我个人认为理解 CAP 理论的难点在于理解清楚这三个属性的定义，他们的定义如下：</p><ul><li><strong>C</strong>onsistency（一致性）：多个数据备份中的数据是一模一样的，用户可能会对某个备份中的数据进行修改，然后另一个数据备份中的数据也会跟随变化，保持一致。当系统没有一致性的时候，可能存在不同的数据备份，也就是正确性出现了问题。</li><li><strong>A</strong>vailable（可用性）：这是非常难理解的一个属性，他指的是用户对于数据的操作（读取或者写入一个数据等）是成功的概率非常高。而当失去可用性的时候，用户的操作经常会收到“操作失败，请重新尝试”的回应。</li><li><strong>P</strong>artition Tolerance（分区容忍性）：这个也非常难理解，它指的是在多个数据备份失去连接的时候（也就是所谓的“分区”），系统依然保持一致性和可用性的能力。C 和 A 对于一个单机系统而言，是非常自然的属性（要不然就是写出来 bug）了，但是如果是分布式系统，一旦数据备份之间失去同步能力，那么是很难保证 C 和 A 的。</li></ul><p>那么为什么这是一个不可能三角呢？我们考虑如下图这样的情况，目前有两个分布式服务器 $S_1$、$S_2$，这两个服务器里都存储着数据 $V$ 的数据备份，客户 $C$ 可以读写 $V$ ，在开始阶段，$S_1$、$S_2$ 中 $V$ 的值都是 $v_0$ 。</p><p>然后出现了网络故障，导致 $S_1$、$S_2$ 之间的同步机制失效，出现了分区情况。然后 $C$ 向 $S_1$ 写入 $V$ 的值为 $v_1$ ，因为缺乏同步机制，所以 $S_2$ 中 $V$ 的值依然是 $v_0$ 。</p><p>此时如果 $C$ 从 $S_2$ 处读取 $V$ 的值，那么有两种可能，第一种是为了可用性，我们告诉 $C$ ，$V$ 的值是 $v_0$ ，这样就牺牲了一致性原则。第二种是我们为了一致性，告诉 $C$ 目前网络出现问题，读取并不成功，那么这样就牺牲了可用性原则。</p><p><img src="/posts/47da48a7/image-20250117111613066.png" alt="image-20250117111613066" style="zoom:40%;"></p><p>从这个例子就可以看出，CAP 不可兼得。而根据业务场景的不同，我们选择牺牲的属性也不同：</p><ul><li>CA 牺牲 P：牺牲 P 就意味着系统不再是一个真正的分布式系统了，因为分布式系统出现“分区“是非常核心的场景，或者说，在分布式系统中不考虑”同步机制“，就过于理想和不可靠了。所以牺牲 P 的系统往往是一个单机系统（或者是某种无法享受分布式优势的分布式系统）。对于一个单机系统而言，保证 C 和 A 是非常基本的事情。</li><li>CP 牺牲 A：牺牲 A 意味着操作有可能失败，但是只要操作成功了，那么它的一致性（也就是正确性）就得到了保证。对于银行 APP 或者支付宝这种对于正确性比较看重的软件，一般会采用这种策略。毕竟谁也不希望自己的账户里的钱突然没了。</li><li>AP 牺牲 C：牺牲 C 意味着虽然每次操作都会得到响应，但是操作的结果不一定保证一致性。对于微信对这种实时性要求比较高的聊天软件，一般会采用这种策略。这也是我们在使用微信的时候，常常会出现”引用的内容不存在“的原因。</li></ul><h4 id="1-4-2-ACID-vs-BASE"><a href="#1-4-2-ACID-vs-BASE" class="headerlink" title="1.4.2 ACID vs BASE"></a>1.4.2 ACID vs BASE</h4><p>在传统的数据库理论研究中，有 ACID 理论：</p><ul><li><strong>原子性 (Atomicity)</strong>：原子性保证了事务中的所有操作要么全部成功，要么全部失败，不能只完成部分操作。如同“原子”一样，事务是不可分割的。</li><li><strong>一致性 (Consistency)</strong>：一致性保证了事务在执行前后，数据库的数据必须是合法的。当事务完成后，所有数据约束条件都必须得到满足。</li><li><strong>隔离性 (Isolation)</strong>：隔离性确保了并发执行的事务之间不会互相干扰。每个事务的执行都像是独占资源，其他事务不能看到其未提交的结果。</li><li><strong>持久性 (Durability)</strong>：持久性确保了已提交的事务所做的更改是永久性的，即使系统崩溃或出现故障，这些更改也不会丢失。</li></ul><p>可以看出大部分的属性都是在保证 C 和 A，而对于 P 是没有描述的。</p><p>而随着 Web 时代的来临，传统的 ACID 就跟不上时代了，所以人们又提出了 BASE 理论：</p><ul><li><strong>基本可用性 (Basically Available)</strong>：系统在大多数时间内是可用的，即使在部分节点出现故障时也能处理请求。这意味着要牺牲部分一致性来保证系统的可用性。</li><li><strong>柔性状态 (Soft state)</strong>：在 BASE 理论中，数据的状态不是瞬时的一致性，而是在某个时间点上可能处于“柔性”的状态，允许数据在一定时间内有暂时的不一致性。</li><li><strong>最终一致性 (Eventual consistency)</strong>：在较长的时间内，系统会最终达到一致状态。这意味着虽然可能存在短期的不一致性，但经过一段时间后，所有副本最终会一致。</li></ul><p>从这里可以看出，BASE 的思路是弱化 C 和 A ，来保证 P。理论的变化折射出不同的时代需求。</p><h3 id="1-5-指标"><a href="#1-5-指标" class="headerlink" title="1.5 指标"></a>1.5 指标</h3><p>虽然 CAP 理论提出了一些关于分布式理论的指标，但是我觉得它更像是为了理论服务的，而不是为了实际的生产。</p><p>在实际中，我们更看重这些指标：</p><p><img src="/posts/47da48a7/image-20250117115544649.png" alt="image-20250117115544649" style="zoom:35%;"></p><p>我们为了这些指标发明了很多技术：</p><p><img src="/posts/47da48a7/image-20250117115658051.png" alt="image-20250117115658051" style="zoom:35%;"></p><p>和 CAP 理论一样，这些指标之间也存在一定的权衡，不同的技术满足不同的场景：</p><p><img src="/posts/47da48a7/image-20250117115923738.png" alt="image-20250117115923738" style="zoom:50%;"></p><p>我们下面会详细介绍一些特性的实现。</p><hr><h2 id="二、一致性"><a href="#二、一致性" class="headerlink" title="二、一致性"></a>二、一致性</h2><h3 id="2-1-总论"><a href="#2-1-总论" class="headerlink" title="2.1 总论"></a>2.1 总论</h3><p>在分布式系统中，会存在多个数据备份和多个执行流。这种情况下，很容易出现各个实体间操作和数据不一致的情况。也就是说，不一致是自然的，我们希望通过我们的努力，让这个复杂的模型简单下来。</p><p>我们简化模型的方式是这样的：</p><ul><li>所有数据只有一份拷贝</li><li>整体并发的操作序列会被等价成一个串行序列</li></ul><p>也就是如下图所示：</p><p><img src="/posts/47da48a7/image-20250117152505550.png" alt="image-20250117152505550" style="zoom:33%;"></p><p>那这是怎么办到的呢？从图上可以看出，确实很多操作就是同时进行的，而不是串行执行的呀？我们改变操作的顺序，本质是在改变操作的起始时间，如果两个操作重叠在一起了，那么我们就让一个操作晚一些启动，也就是<strong>阻塞</strong>一个操作，来将两个操作错开。</p><p>也就是说，为了编程的易用性，我们牺牲的是系统的性能，更具体一些，牺牲的是操作的时延（可能还有些别的）。</p><p>一致性模型的光谱（Spectrum）如下：</p><p><img src="/posts/47da48a7/image-20250117153143453.png" alt="image-20250117153143453" style="zoom:30%;"></p><p>我们还可以从另一个角度去分析为什么性能和易用性可以形成 tradeoff，当我们有一个并发的操作序列的时候，我们可以将他们排列成多种串行的全排列。一致性模型的本质，就是规定一些全排列是符合要求的，而另一些全排列是不符合要求的。越严格的一致性模型，允许的全排列的数目就越少，那么行为就更好被预测，那么易用性就高；而越宽松的模型，允许的全排列的数目就越多，那么底层实现就可以越灵活，性能就可以越好。</p><p>此外还需要强调，这里的一致性，并不完全等价于正确性，并不是说，我们只要遵循了某个一致性的模型，那么程序就不会出我们意想不到的 bug 了（不同的一致性模型可能有不同强度的编程约束，在这个约束下可能有一些奇怪的行为，但是都是符合一致性模型的内在逻辑的）。这是因为这里说的一致性里的操作，每个操作只涉及一个数据 object，而涉及多个 object 的操作（比如说银行账户的转账，涉及一个账户金额的减少和另一个账户金额的增加），就不再是一致性的范畴了，而是下文讨论的隔离性的范畴了。这种涉及多个 object 的操作被称作一个事务（Transaction，TX）。</p><h3 id="2-2-一致性模型"><a href="#2-2-一致性模型" class="headerlink" title="2.2 一致性模型"></a>2.2 一致性模型</h3><h4 id="2-2-1-Strict"><a href="#2-2-1-Strict" class="headerlink" title="2.2.1 Strict"></a>2.2.1 Strict</h4><p>strict 模型指的是按照每个 operation 的起始时间来对这些 operation 进行排列。那么这种模型基本上就等同于只允许一个全排列（因为每个 operation 的开始时间一般都是不同的），是最严格的模型。</p><p>这种模型基本上只是只能存在于理论中，因为在分布式系统中很难建立起一个全局的统一时钟。</p><h4 id="2-2-2-Linearizability"><a href="#2-2-2-Linearizability" class="headerlink" title="2.2.2 Linearizability"></a>2.2.2 Linearizability</h4><p>Linearizability 指的是如果 op1 的终止时间在 op2 的起始时间之前，那么在串行排列中，也一定是 op1 在 op2 之前。如下图所示，这种排列就是不被允许的：</p><p><img src="/posts/47da48a7/image-20250117163653516.png" alt="image-20250117163653516" style="zoom:40%;"></p><p>Linearizability 看似也是需要全局时钟的，而实际上并不是，Linearizability 的本质是确定各个操作的相对顺序而不是绝对顺序，所以实现难度会低一些。</p><h4 id="2-2-3-Sequential"><a href="#2-2-3-Sequential" class="headerlink" title="2.2.3 Sequential"></a>2.2.3 Sequential</h4><p>Sequential 指的是在每个计算实体上维护操作的相对顺序，而 Linearizability 是全局的相对顺序。</p><p>也就是说，下面的这个图（就是上面的那个图），虽然不符合 Linearizability ，但是符合 Sequential 。这是因为原本在 Linearizability 中存在的依赖，因为分别属于 P0 和 P1，所以在 Sequential 中并不存在：</p><p><img src="/posts/47da48a7/image-20250117164908037.png" alt="image-20250117164908037" style="zoom:40%;"></p><h4 id="2-2-4-Eventual"><a href="#2-2-4-Eventual" class="headerlink" title="2.2.4 Eventual"></a>2.2.4 Eventual</h4><p>Eventual 是一种弱一致性模型，它只能保证最终每个数据副本的状态是一致的，而中途的状态就不一定了。</p><p>这种模型似乎就是微信这种实时聊天软件所采用的模型，所以微信的实时性更好，但是经常出现错误。</p><h3 id="2-3-实现"><a href="#2-3-实现" class="headerlink" title="2.3 实现"></a>2.3 实现</h3><p>Linearizability 有一个特性，就是如果每个 object 的 Linearizability  得到了维持，那么整个系统的 Linearizability  就得到了维持。这个特性我其实不是太理解，因为我感觉不同的 object 之间也会存在一些依赖关系。所以就算了，只是记录在这里。</p><p>下面我们开始介绍 Linearizability 的实现，其中最简单的一个模型就是 Primary-Backup Model，也就是将某个数据备份设置为 Primary，而其他的数据备份是 Backup。所有的写入操作都需要先对所有的 Backup 写入后，再对 Primary 进行写入。所有的读取操作，也只是对于 Primary 的读取，并不会读 Backup，也就是如下：</p><p><img src="/posts/47da48a7/image-20250117170621899.png" alt="image-20250117170621899" style="zoom:33%;"></p><p>这种方式有两个很有趣的点，一个是要先写 backup，然后写 Primary，这是因为如果先写 Primary，那么就又可能在写操作还没有 Done 的时候，另一个读操作就可以读出来新值了，这就违反了 Linearizability 的定义。换句话说，将 Primary 的写入视为整个写入操作的结束，是一种实现 Linearizability 的一种手段。</p><p>另一个就是即使本地有数据，也依然要到 Primary 中去读取，这是因为 Read 操作必须完全在 Write 操作之前或者之后，下图就表示了一种不遵循这种方式造成的问题，Read_1 读出了新值，而 Read_2 明明在 Read_1 之后，读出的却是旧值。</p><p><img src="/posts/47da48a7/image-20250117171434398.png" alt="image-20250117171434398" style="zoom:33%;"></p><p>当然这种非常愚蠢的读操作也是有办法缓解的，我们还是能读取本地值的，即使本地值是 backup，也就是我们设计每个 object 有两种模式，一种模式下只可以读取本地值，而另一个模式不允许，必须读取 Primary 的值，当 Primary 要写 object 的时候，就会把模式调整为不允许，而写入完成后，就调整成允许。这种设计非常类似于 Cache Coherency 的设计。</p><p>此外 Backup 的 op 的顺序也可能因为网络等问题，导致和 Primary 上的 op 的顺序存在差异，如下所示：</p><p><img src="/posts/47da48a7/image-20250117172212189.png" alt="image-20250117172212189" style="zoom:33%;"></p><p>明明在 P0 上是 op1，op2，到了 P1 上就变成了 op2，op1 。我们可以给操作一个 seq number，来解决这个问题：</p><p><img src="/posts/47da48a7/image-20250117172401101.png" alt="image-20250117172401101" style="zoom:33%;"></p><p>在 Primary-Backup 模型中，Primary 因为承担了过多的通信开销，导致其成为性能瓶颈。我们可以采用分区的方法，也就是不同的 object 的 Primary 并不是同一个，来避免瓶颈问题，下图中 x 的 Primary 是 P0，而 y 的 Primary 是 P1：</p><p><img src="/posts/47da48a7/image-20250117172756191.png" alt="image-20250117172756191" style="zoom:33%;"></p><p>在了解完 Linearizability 的实现后，如果我们每次都只读取 local 的数据，写入的时候也只写入 local 数据，对于其他的备份，采用后台写入的方式，那么我们就得到了 Eventual 模型。</p><hr><h2 id="三、隔离性"><a href="#三、隔离性" class="headerlink" title="三、隔离性"></a>三、隔离性</h2><h3 id="3-1-总论"><a href="#3-1-总论" class="headerlink" title="3.1 总论"></a>3.1 总论</h3><p>在一致性这一章，我们讨论了在分布式系统下，多个并发 op 的一致性模型，但是即使我们让这些 op 满足了某种一致性，也是依然会出现问题的。比如说银行转账问题。出现问题的原因就在于，这些 op 是一个个零散得进行排序的，而在生产中，我们希望一组 op 可以绑定在一起进行排序（起码看上去是绑定在一起的），这样绑定在一起的一组 operation 我们就称之为“事务”（Transaction，TX）。</p><p>隔离性（Isolation）就是描述事务的性质，它指的是事务之间看上去是相互隔离的，不会出现“犬牙交错”的情况，也就是不同 TX 里的 op 交替执行。隔离性还有很多其他的名字，比如说 Before-After Atomicity，Serializability 等，都是相同的意思。在下文中我们主要采用 Serializability 这个词。</p><p>那么 Serializability 和 Consistency 的关系是什么？我觉得它们是不完全正交的。虽然他们看上去都涉及了某种“视图”，但是其本质是不一样的。Consistency 的视图是一个 op 的串行序列，而 Serializability 的视图是多个 op 的串行序列，也就是常说的 Grid Notion，在 Grid Notion 中有 3 个概念：</p><p>Operation ⊂ Transaction ⊂ Schedule</p><p>也就是一个调度（Schedule）就是一个“历史记录”，这段历史记录里有所有事务（Transaction）里的所有 Operation 的排列顺序。数据库开发者能做得就是“歪曲” Schedule 来获得性能，而用户需要明确被开发者歪曲过的 Schedule 和一个理想的 Schedule （一般就是原子性事务形成的 Schedule）之间的差距有多大。</p><p>如下所示：</p><p><img src="/posts/47da48a7/clipboard-20241105T194227.png" alt="clipboard-20241105T194227" style="zoom: 50%;"></p><p>写到这里其实我迷茫了，感觉虽然上面是两个 op 序列，但是实际上依然是一个 op 序列（或者说实际上依然是并行的，只是在视图上变成了串行的）。所以我也说不好。</p><p>Serializability 只是要求 TX 看上去保持原子性，其中的 op 是不能被打散的。但是在实际上如果真的这样去做，那么性能就又会受到一定的影响。所以实际上不同 TX 的 op 依然是交错执行，甚至是并行执行的，只是看上去是满足 Serializability 的，这点和 Consistency 类似，也是存在着多种 Serializability 的模型，如下所示：</p><p><img src="/posts/47da48a7/image-20250118173609510.png" alt="image-20250118173609510" style="zoom:33%;"></p><p>我在网上找到了一个图，因为图上有一些我不懂的概念，所以我不知道是不是可以说明 Serializability 和 Consistency 的不完全正交性。</p><p><img src="/posts/47da48a7/clipboard-20241105T194446.png" alt="clipboard-20241105T194446"></p><h3 id="3-2-Serializability-模型"><a href="#3-2-Serializability-模型" class="headerlink" title="3.2 Serializability 模型"></a>3.2 Serializability 模型</h3><h4 id="3-2-1-Conflict-Serializability"><a href="#3-2-1-Conflict-Serializability" class="headerlink" title="3.2.1 Conflict Serializability"></a>3.2.1 Conflict Serializability</h4><p>Conflict Serializability 是一种约束较强的 Serializability 模型。它首先定义了什么是 operation 之间的 conflict：</p><ul><li>它们操作同一个 object</li><li>至少其中一个是写操作</li><li>它们属于不同的事务</li></ul><p>然后如果一个 Schedule 的 conflict order 和某个串行化 Schedule 的 conflict order 是一样的，那么这个 Schedule 就是符合 Conflict Serializability 。</p><p>这个定义说得非常的不清楚，其实应该是这样。所谓的“串行化 Schedule”指的是让这些 TX（注意不是 op）串行化的 schedule。我们在现实中希望能交替或者并行执行不同 TX 中的 op，如果两个 op 毫不相干，那么显然是可以交替执行的。而 conflict 定义了一种 op 之间“相干”的关系，存在 conflict 的 op 就不能随便调度了，它必须和一种串行化的调度的 conflict 顺序相同（相当于和理想状态一致）。</p><p>而在实践中，我们可以用 Conflict Graph 是否成环来判断一个 schedule 是否满足 Conflict Serializability。conflict graph 是有向图，的节点是 TX（注意不是 op），而如果两个 TX 中有 op 是 conflict，那么就有一条边，从在 schedule 中更靠前的 op 所在的 TX 的节点，指向更靠后的 op 所在的 TX 的节点。当 Conflict Graph 成环的时候，就说明这个 schedule 是不满足 Conflict Serializability 的。</p><p>为什么 Conflict Graph 是否成环就可以判断是否是 Conflict Serializability 呢？这是因为对于一个串行的 schedule 而言，它的 Conflict Graph 一定是不成环的，这是非常显然的，反之，当一个 schedule 对应的 Conflict Graph 是成环的，那么它一定没有办法表示成一个串行的 schedule。所以我们就可以用 Conflict Graph 来判断。</p><h4 id="3-2-2-View-Serializability"><a href="#3-2-2-View-Serializability" class="headerlink" title="3.2.2 View Serializability"></a>3.2.2 View Serializability</h4><p>Conflict Serializability 的约束还是过强了，类似于 CPU 指令的调度，RAW，WAW，WAR 都会被判定为 conflict，而实际上约束并不需要这么强。比如说下图的 schedule 不符合 Conflict Serializability，但是读出的值、最后的状态（也就是我们在调度中最关心的两点），和串行 schedule “T1 -&gt; T2 -&gt; T3”一样：</p><p><img src="/posts/47da48a7/image-20250118202954360.png" alt="image-20250118202954360" style="zoom:40%;"></p><p>为了允许这种情况，我们发明了 View Serializability。它的定义就是，如果读操作和最终状态都和一个串行 schedule 相同，那么就是符合 View Serializability 的。也就是 View 的含义，即“看上去没啥毛病”。</p><p>View Serializability 就是一种较为理想的状态，它一共有 3 点要求（非常数学形式化的要求），其中第二点就是 RAW，而剩下两点是关于 init 和 end 的约束，就比 Conflict Serializability 要更加合理地多。</p><p>可惜的是，View Serializability 很难检验是否达成，而且也很难实现；相反的，Conflict Serializability 可以用 Conflict Graph 来检验，而且可以用 2PL 来实现。</p><h3 id="3-3-实现"><a href="#3-3-实现" class="headerlink" title="3.3 实现"></a>3.3 实现</h3><h4 id="3-3-1-2PL"><a href="#3-3-1-2PL" class="headerlink" title="3.3.1 2PL"></a>3.3.1 2PL</h4><p>Lock 是一种保证多个 Serializability 的有效手段。而具体而言，需要使用 2PL （2 Phase Lock）的方式。</p><p>按理说是一份 object 对应一份锁，但是并非锁的粒度仅仅取决于资源的粒度。比如说我们希望将 A 账户里的钱转账到 B 账户上，在语义上，A 和 B 是一个共同体，所以锁不能仅仅是 A Lock 和 B Lock（这样会导致有一个中间态是 A 账户的钱已经没了，而 B 账户还没有收到钱），而应该是一个 AB Lock 。</p><p>在实践上，我们没有必要真的声明一个 AB Lock，这样的话，一个有 N 个账户的银行就需要 $C_{n}^{2}$ 个锁了，这显然是不现实的。我们只需要同时拿住 A Lock 和 B Lock 即可保证粒度是 AB 。</p><p>从上面我们说到，锁的粒度不仅取决于资源本身的粒度，还取决于事务（上面的例子是转账）的粒度。如果一个事务需要多种资源，那么它应该同时拿多把锁。问题在于，拿锁这个行为并不能同时发生。两阶段锁（Two Phase Locking, 2PL）这个理论告诉我们，只要按照它说得做，就可以达到跟“同时拿两个锁”一样的效果。</p><p>2PL 的两个阶段：</p><ul><li>Expanding phase：只拿锁，不放锁</li><li>Shrinking phase：只放锁，不拿锁</li></ul><p>也就是说，以对共享资源进行具体的操作为界，在操作前只拿锁，在操作后只放锁，不会存在放锁后再拿锁的情况。</p><p><img src="/posts/47da48a7/image-20250118204019137.png" alt="image-20250118204019137" style="zoom:33%;"></p><p>Lock 有一个问题 Deadlock，为了避免死锁，其实 2PL 已经给出了一个方法，就是在拿锁的时候需要按照一定的顺序，而放锁的时候按照相反的顺序，这样就可以避免死锁。</p><p>但是这种方法的难点在于，很难给所有的共享的 object 进行一个排序，而且对程序员也是负担。</p><p>此外，我们还可以用 Conflict Graph 来判断是否出现死锁，但是这种检验方式成本也太大。所以我们现在一般采用一些启发式方法。</p><h4 id="3-3-2-OCC"><a href="#3-3-2-OCC" class="headerlink" title="3.3.2 OCC"></a>3.3.2 OCC</h4><p>OCC 即 Optimistic Concurrency Control。</p><p>相对应的，Lock 的方式被视为 Pessimistic 。这是因为拿锁的目的是为了保证 object 的独占性，但是这建立于这个 object 真的会被多个 TX 并发访问的假设，这个假设在某些场景下有些过于悲观了。</p><p>OCC 的意思是 TX 不再使用锁，而是直接操作，如果出现了竞态，那么再修正。即：</p><ul><li><p><strong>阶段 1：并发本地处理</strong></p><ul><li><p>读取数据到读集。</p></li><li><p>将写操作缓存在写集中。</p></li></ul></li><li><p><strong>阶段 2：验证可串行化（在临界区内）</strong></p><ul><li>验证是否保证可串行化：</li><li>检查读集中的数据是否被修改过。</li></ul></li><li><p><strong>阶段 3：提交或中止（在临界区内）</strong></p><ul><li><p><strong>中止</strong>：如果验证失败，则中止事务。</p></li><li><p><strong>提交</strong>：如果验证成功，则安装写集并提交事务。</p></li></ul></li></ul><p>Git 就是一种 OCC，每个人都在自己本地进行修改，而如果发生冲突，再手动 merge。</p><p>后两个阶段还是需要用锁来保证独占性的，但是因为这两个阶段都很短，所以性能开销并不大。后两个阶段伪代码如下：</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">validate_and_commit</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment"># phase 2 &amp; 3 with before-or-after</span>    <span class="token keyword">for</span> d <span class="token keyword">in</span> <span class="token builtin">sorted</span><span class="token punctuation">(</span>write_set<span class="token punctuation">)</span><span class="token punctuation">:</span>        d<span class="token punctuation">.</span>lock<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token keyword">for</span> d <span class="token keyword">in</span> read_set<span class="token punctuation">:</span>        <span class="token keyword">if</span> d has changed <span class="token keyword">or</span> d has been locked<span class="token punctuation">:</span>           abort<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token keyword">for</span> d <span class="token keyword">in</span> write_set<span class="token punctuation">:</span>        write<span class="token punctuation">(</span>d<span class="token punctuation">)</span>    <span class="token comment"># release the locks</span>    <span class="token comment"># ...</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>OCC 的问题在于经常会出现假阳性的 abort。所以当并发事务增多的时候，OCC 的性能并不好，其与 2PL 的对比如下：</p><p><img src="/posts/47da48a7/image-20250118211510893.png" alt="image-20250118211510893" style="zoom:50%;"></p><h4 id="3-3-3-HTM"><a href="#3-3-3-HTM" class="headerlink" title="3.3.3 HTM"></a>3.3.3 HTM</h4><p>HTM 即 Hardware Transactional Memory。从本质上讲，HTM 就是 OCC 思想的硬件实现。</p><p>Intel 在 Haswell 处理器上首次支持了了 HTM，被称为 Restricted Transactional Memory（RTM）。RTM 引入了 3 条新指令</p><pre class="line-numbers language-assembly" data-language="assembly"><code class="language-assembly">xbegin() ; 标识事务开始 xend() ; 标识事务开始 xabort() ; 标识事务中断<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>HTM 在实现上，使用 CPU Cache 来追踪 read/write_set，那如何探测 conflict 呢？是基于 Cache Coherency 实现的。</p><p>HTM 的问题在于支持的事务不能特别长，read/write_set 也不能特别大。</p><h4 id="3-3-4-MVCC"><a href="#3-3-4-MVCC" class="headerlink" title="3.3.4 MVCC"></a>3.3.4 MVCC</h4><p>OCC 在多并发读的性能不好，2PL 也是同样的，那么有没有什么方式可以优化多读少写的场景呢？</p><p>MVCC 即 multi-versioning concurrency control ，就是一种适应这种场景的新式版本控制方式。</p><p>其设计思路是维护 object 的多个 version，也就是多个 snapshot，用 time 作为版本号，这样可以避免并行读的竞争。</p><p><img src="/posts/47da48a7/image-20250118220106083.png" alt="image-20250118220106083" style="zoom:40%;"></p><p>其伪代码形式如下：</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">Commit</span><span class="token punctuation">(</span>tx<span class="token punctuation">)</span><span class="token punctuation">:</span>   <span class="token keyword">for</span> record <span class="token keyword">in</span> tx<span class="token punctuation">.</span>write_set<span class="token punctuation">:</span>        lock<span class="token punctuation">(</span>record<span class="token punctuation">)</span>   let commit_ts <span class="token operator">=</span> FAA<span class="token punctuation">(</span>global_counter<span class="token punctuation">)</span>   <span class="token keyword">for</span> record <span class="token keyword">in</span> tx<span class="token punctuation">.</span>write_set<span class="token punctuation">:</span>       record<span class="token punctuation">.</span>insert_new_version<span class="token punctuation">(</span>commit_ts<span class="token punctuation">,</span> <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">)</span>        unlock<span class="token punctuation">(</span>record<span class="token punctuation">)</span> <span class="token keyword">def</span> <span class="token function">Get</span><span class="token punctuation">(</span>tx<span class="token punctuation">,</span> record<span class="token punctuation">)</span><span class="token punctuation">:</span>   <span class="token keyword">while</span> record<span class="token punctuation">.</span>is_locked<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>         <span class="token keyword">pass</span>   <span class="token keyword">for</span> version<span class="token punctuation">,</span>value <span class="token keyword">in</span> record<span class="token punctuation">.</span>sort_version_in_decreasing<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>       <span class="token keyword">if</span> version <span class="token operator">&lt;=</span> tx<span class="token punctuation">.</span>start_time<span class="token punctuation">:</span>           <span class="token keyword">return</span> value <span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>其中 <code>commit</code> 是事务最终提交前的工作（主要是写操作），<code>get</code> 是读操作。</p><hr><h2 id="四、容错性"><a href="#四、容错性" class="headerlink" title="四、容错性"></a>四、容错性</h2><h3 id="4-1-RSM"><a href="#4-1-RSM" class="headerlink" title="4.1 RSM"></a>4.1 RSM</h3><p>增加容错最常用的方法，就是增加数据备份。这样即使出现网络错误，或者有什么物理 crash，备份的数据也保存完好。</p><p>但是让多个数据备份保持一致性，非常的困难。这里说的一致性，并不是上面的一致性，上面的一致性更侧重于从并发控制流角度的一致性，而这里的一致性更侧重于数据的一致性。</p><p>RSM 即 Replicated State Machine。它是人们提出的一种理论模型，这个理论指导了人们如何实现多个具有一致性的数据备份服务器。它将备份服务器视为状态机，只要初始状态一致，操作的顺序一致，那么最终状态就一定是一致的。这个理论将“让备份服务器保持一致”这个问题转换成了“让所有备份服务器的操作顺序一致”。</p><p>也就是说，我们需要确定一个唯一的执行序列（如果操作中有随机函数，还需要将执行结果记录下来），这样就能保证多个备份服务器的内容都一致了。</p><h3 id="4-2-Primary-Backup"><a href="#4-2-Primary-Backup" class="headerlink" title="4.2 Primary-Backup"></a>4.2 Primary-Backup</h3><p>很容易想到可以使用 Primary-Backup 机制来实现 RSM，也就是 Primary 负责接受用户请求，确定执行序列，然后发送给 Backup 让它执行。其形式如下：</p><p><img src="/posts/47da48a7/image-20250118222048627.png" alt="image-20250118222048627" style="zoom:33%;"></p><p>当 S1 挂掉了，那么 S2 就可以担任起备份的重任：</p><p><img src="/posts/47da48a7/image-20250118222217330.png" alt="image-20250118222217330" style="zoom:33%;"></p><p>这里图中只画了一个 Coordinator 用于将 clients 的请求转发给 Primary，而在实际的生产中，可能出现多个 Coordinator，这样可以更好地转发多个 client 的请求。此时就有可能出现问题了，就是一旦发生网络分区（Network Partition），如果两个  Coordinator  可能会选出两个 primary，如下所示：</p><p><img src="/posts/47da48a7/image-20250118222721272.png" alt="image-20250118222721272" style="zoom:33%;"></p><p>那这样每个 Primary 收到的请求就不一样了，不一致性自然就产生了。</p><p>所以我们提出了 View Server，说白了就是将“选出 Primary”这个任务指派给一个全局单例服务器上</p><p><img src="/posts/47da48a7/image-20250118222955428.png" alt="image-20250118222955428" style="zoom:33%;"></p><p>不过这种方法其实治标不治本，如果 VS 挂了怎么办？就没有办法解决了。只是说 VS 挂掉的可能性很小。</p><p>这种思路其实代表一种“中心化”的思路，即 Primary 是被某个中心权威（这个例子中是 VS）指定的。而当中心权威出现故障的时候，就无能为力了。</p><h3 id="4-3-Raft-共识算法"><a href="#4-3-Raft-共识算法" class="headerlink" title="4.3 Raft 共识算法"></a>4.3 Raft 共识算法</h3><p>共识算法是一种“分布式选举 Primary”的算法，这就避免了中心权威出现问题，进而导致系统不一致的情况出现。经典的共识算法有 Paxos 和 Raft。</p><p>Raft 于 2013 年由 Diego Ongaro 和 John Ousterhout 提出，旨在提供一种易于理解和实现的一致性协议。Raft 似乎是一个非常易懂的方式（比另一种 Paxos “希腊选举”），因为它论文里直接写伪代码了（面向工程师而非数学家）。不过似乎在设计上它比 Paxos 更反直觉。</p><p>具体的实现细节就不在这里写了。</p>]]></content>
    
    
    <summary type="html">&lt;h2 id=&quot;一、分布式系统&quot;&gt;&lt;a href=&quot;#一、分布式系统&quot; class=&quot;headerlink&quot; title=&quot;一、分布式系统&quot;&gt;&lt;/a&gt;一、分布式系统&lt;/h2&gt;&lt;h3 id=&quot;1-1-总论&quot;&gt;&lt;a href=&quot;#1-1-总论&quot; class=&quot;headerlink&quot; title=&quot;1.1 总论&quot;&gt;&lt;/a&gt;1.1 总论&lt;/h3&gt;&lt;p&gt;分布式系统指的是利用多个单体计算机系统构建的多体计算机系统。&lt;/p&gt;
&lt;p&gt;与并行计算不同，分布式系统更侧重于用多个计算实体完成&lt;strong&gt;非常多个&lt;/strong&gt;细碎的任务。而并行计算侧重于利用多个计算实体来更快更高效地完成&lt;strong&gt;一个&lt;/strong&gt;计算任务。&lt;/p&gt;
&lt;p&gt;分布式系统包括了执行流的分布式和数据的分布式。在北航 OO 课电梯问题中，涉及了多线程，属于是执行流的分布式，这就导致我以为分布式只是执行流的分布式，涉及的问题只是互斥和同步，这是非常片面的。数据的分布式指的是，存在多个数据副本，cache 就是一种数据分布式的实体。&lt;/p&gt;</summary>
    
    
    
    <category term="计算机系统" scheme="https://thysrael.github.io/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%B3%BB%E7%BB%9F/"/>
    
    
    <category term="知识总结" scheme="https://thysrael.github.io/tags/%E7%9F%A5%E8%AF%86%E6%80%BB%E7%BB%93/"/>
    
    <category term="计算机系统" scheme="https://thysrael.github.io/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%B3%BB%E7%BB%9F/"/>
    
    <category term="S9复习" scheme="https://thysrael.github.io/tags/S9%E5%A4%8D%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>计算机系统-虚拟化</title>
    <link href="https://thysrael.github.io/posts/670dae13/"/>
    <id>https://thysrael.github.io/posts/670dae13/</id>
    <published>2025-01-02T09:48:54.000Z</published>
    <updated>2025-01-07T04:31:15.691Z</updated>
    
    <content type="html"><![CDATA[<h2 id="一、CPU-虚拟化"><a href="#一、CPU-虚拟化" class="headerlink" title="一、CPU 虚拟化"></a>一、CPU 虚拟化</h2><h3 id="2-1-背景"><a href="#2-1-背景" class="headerlink" title="2.1 背景"></a>2.1 背景</h3><p>CPU 虚拟化范畴还挺多的，但是我们这里应该指的不包括不同 ISA 的虚拟化，而只是 CPU 的虚拟化，也就是虚拟出来的 CPU 和原本的 CPU 具有相同的 ISA 。</p><h3 id="2-2-Trap-amp-Emulate"><a href="#2-2-Trap-amp-Emulate" class="headerlink" title="2.2 Trap &amp; Emulate"></a>2.2 Trap &amp; Emulate</h3><p>为了虚拟化出多个 CPU，我们让虚拟的 OS 跑在用户态，也就是如下结构：</p><p><img src="/posts/670dae13/image-20250104222633971.png" alt="image-20250104222633971"></p><p>但是这种方式的问题在于，一旦执行到在 User mode 和 Kernel mode 行为不一致的指令的时候，那么就会导致出现 bug。</p><p>于是我们提出了 Trap&amp;Emulate 技术，它基于这样的一种观察：行为不一致的指令（被称作敏感指令）大部分都是特权指令或者访问特权寄存器，那么这种指令在 user mode 下指令，本身就会引发 trap，而 trap 到 Host OS 时，我们就用软件模拟执行的效果，也就是 Emulate。示意图如下：</p><p><img src="/posts/670dae13/image-20250104223628736.png" alt="image-20250104223628736" style="zoom:50%;"></p><p>而 Trap&amp;Emulate 技术有两点缺陷：</p><ul><li>并不是所有敏感指令都是特权指令，那么可能有些指令不会触发 trap，那么就导致这个部分 bug 了。这种行为敏感指令都是特权指令的特性被称为 strictly virtualizable，不幸的是，X86 ISA 就不是一种严格虚拟化的 ISA。</li><li>Trap 的性能开销过大。</li></ul><p>为了解决这些缺陷，我们又提出了新的技术。</p><h3 id="2-3-解决方案"><a href="#2-3-解决方案" class="headerlink" title="2.3 解决方案"></a>2.3 解决方案</h3><h4 id="2-3-1-Instruction-Interpreter"><a href="#2-3-1-Instruction-Interpreter" class="headerlink" title="2.3.1 Instruction Interpreter"></a>2.3.1 Instruction Interpreter</h4><p>也就是用软件模拟出一个 CPU 来，这样所有的指令并不是通过硬件执行的，而是通过软件模拟，这样就解决了不严格虚拟化的问题（所有的指令现在都是模拟执行了）。</p><p>Boch 就采用了这种思路。</p><h4 id="2-3-2-Binary-Translator"><a href="#2-3-2-Binary-Translator" class="headerlink" title="2.3.2 Binary Translator"></a>2.3.2 Binary Translator</h4><p>在执行代码前，需要先经过一个 translate 的过程，也就是将代码进行扫描，并将其中的敏感指令，替换成函数调用，这样就可以避免不一致问题了。</p><p>翻译的基本单位是基本块，并且翻译好的基本块会被放入 translation cache 中，下次如果还使用这个基本块的话，那么就直接使用了。至于为什么一基本块为粒度，可能是因为按指令为粒度，会频繁触发翻译拖慢速度；按可执行文件为粒度，很多执行不到的基本块其实是不需要翻译的。</p><p>Binary translation 有两个缺点：</p><ul><li>难以处理中断：在翻译后的代码中，中断只能在基本块边界处发生，而真实机器上中断可以在任何指令处发生。这可能导致精度问题，影响程序的实时性和响应能力。而且为了处理中断，需要在基本块边界保存和恢复CPU状态。这增加了上下文切换的开销和复杂性。</li><li>难以处理自修改代码（SMC）：为了检测自修改代码，必须监控对翻译后代码的写操作，这会引入额外的性能开销。</li></ul><p>如 VMware，Qemu。</p><h4 id="2-3-3-Para-virtualization"><a href="#2-3-3-Para-virtualization" class="headerlink" title="2.3.3 Para-virtualization"></a>2.3.3 Para-virtualization</h4><p>半虚拟化的设计思路是让 OS 意识到自己是一个虚拟机的 OS，对于敏感指令，就主动调一个 hypercall 自己 trap，这样就避免了被动 trap 不完全的情况。</p><h4 id="2-3-4-Hardware-Supported"><a href="#2-3-4-Hardware-Supported" class="headerlink" title="2.3.4 Hardware Supported"></a>2.3.4 Hardware Supported</h4><p>以 Intel 提供的 VT-x （x 是 eXtend 的意思）为例，它引入了 root 和 non-root 两个模式，non-root 模式下，只要遇到敏感指令，都会 trap，这样就避免了使用原本的特权机制来 trap 的缺陷。</p><p><img src="/posts/670dae13/image-20250104232230440.png" alt="image-20250104232230440" style="zoom:50%;"></p><p>此外，VTX 还提供了 VMCS ，用于保存了虚拟机的状态信息和控制信息，使 VMM 能够精确管理和恢复虚拟机的执行状态。</p><hr><h2 id="二、内存虚拟化"><a href="#二、内存虚拟化" class="headerlink" title="二、内存虚拟化"></a>二、内存虚拟化</h2><h3 id="2-1-背景-1"><a href="#2-1-背景-1" class="headerlink" title="2.1 背景"></a>2.1 背景</h3><p>首先强调，除了 <code>load</code>，<code>store</code> 指令会涉及虚拟地址的使用，<code>call</code>， <code>return</code>， <code>jump</code> 这样的指令同样会涉及虚拟地址的使用。</p><p>在虚拟化背景下，一共有 3 种地址：</p><ul><li>GVA：Guest Virtual Address</li><li>GPA：Guest Physical Address</li><li>HPA：Host Physical Address</li></ul><p>又有 3 种页表：</p><ul><li>GPT：Guest Page Table</li><li>HPT：Host Page Table</li><li>SPT：Shadow Page Table</li></ul><p>正因为有 3 种地址的存在，VM 的 GPA 并不是真实的物理地址，所以我们需要将其映射到真实的物理地址 HPA，这就是内存虚拟化要解决的问题。</p><p>下图展示了 3 种地址的关系，和两种解决办法：</p><p><img src="/posts/670dae13/image-20250107104440121.png" alt="image-20250107104440121" style="zoom:33%;"></p><h3 id="2-2-Shadow-Page-Table"><a href="#2-2-Shadow-Page-Table" class="headerlink" title="2.2 Shadow Page Table"></a>2.2 Shadow Page Table</h3><p>按理来说，因为需要完成 3 个地址之间的转换，所以需要 2 个页表，但是在早期，我们只有一个页表基地址寄存器，如 <code>CR3</code> 。所以我们如果想借助 MMU 的力量完成地址翻译，那么就需要想办法把两个页表融合成一个页表，这个页表直接完成 GVA -&gt; HPA 的地址翻译，这种页表被称作影子页表，shadow paging。</p><p>影子页表的构建就是遍历 GPT 和 HPT 的过程，其伪代码如下：</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">set_cr3 <span class="token punctuation">(</span>guest_page_table<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">for</span> GVA <span class="token keyword">in</span> <span class="token number">0</span> to <span class="token number">220</span>        <span class="token keyword">if</span> guest_page_table<span class="token punctuation">[</span>GVA<span class="token punctuation">]</span> <span class="token operator">&amp;</span> PTE_P<span class="token punctuation">:</span>            GPA <span class="token operator">=</span> guest_page_table<span class="token punctuation">[</span>GVA<span class="token punctuation">]</span> <span class="token operator">&gt;&gt;</span> <span class="token number">12</span>            HPA <span class="token operator">=</span> host_page_table<span class="token punctuation">[</span>GPA<span class="token punctuation">]</span> <span class="token operator">&gt;&gt;</span> <span class="token number">12</span>            shadow_page_table<span class="token punctuation">[</span>GVA<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token punctuation">(</span>HPA <span class="token operator">&lt;&lt;</span> <span class="token number">12</span><span class="token punctuation">)</span> <span class="token operator">|</span> PTE_P        <span class="token keyword">else</span>            shadow_page_table <span class="token operator">=</span> <span class="token number">0</span>     CR3 <span class="token operator">=</span> PHYSICAL_ADDR<span class="token punctuation">(</span>shadow_page_table<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>影子页表的维护也比较繁琐，主要有两个问题。一个问题是如果 VM 修改自己的 GPT 怎么办？实际上 GPT 并不存在，那么修改后不会有任何效果，所以我们需要 trap 这种修改行为（通过将 GPT 设置成只读的），并将修改同步到影子页表。</p><p>另一个问题是如果 Guest App 访问 Guest OS 的虚拟地址怎么办，因为此时 SPT 本质上是一个用户页表，所以也不存在用户地址空间和内核地址空间的隔离问题。我们可以准备两个 SPT，为 Guest App 提供的 SPT 中不包含 Guest OS 的地址映射，这样就解决了问题。</p><p>SPT 的优点在于对落后硬件的兼容性强，并且只需要一次地址翻译流程，访问时延较低。而缺点在于，对于页表的修改需要时时 trap，性能不佳。此外，SPT 的数目会非常膨胀（其实也不是太多），这是因为每个 SPT 对应一个 (GPT, HPT) 对，而每个 Guest App 都有自己的 GPT，这就导致 SPT 的数量和所有 VM 上的所有 App 一致。如果为了避免 Guest OS 地址空间被 Guest App 读写，还需要多一倍的 SPT。</p><h3 id="2-3-Direct-Paging"><a href="#2-3-Direct-Paging" class="headerlink" title="2.3 Direct Paging"></a>2.3 Direct Paging</h3><p>Direct Paging 是一种半虚拟化方法，也就是 Guest OS 使用 hypercall 来更新页表，并不能直接修改页表。页表记录的是 GVA -&gt; HPA 。</p><p>这个的好处是实现简单，而问题在于对于 VM 不透明，而且 VM 会获得更多 Host Memory 的信息，引发安全事故。</p><h3 id="2-4-Hardware-Support"><a href="#2-4-Hardware-Support" class="headerlink" title="2.4 Hardware Support"></a>2.4 Hardware Support</h3><p>硬件支持的方式就是拓展 MMU 的功能，使其可以完成二级翻译，如 Intel 的 EPT（Extended Page Table），AMD 的 NPT（Nested Page Table）。</p><p>而二级翻译最大的缺点是，二级页表的内存访问次数会过多。对于 4 级页表而言，一次地址翻译最多需要访问内存 20 次。</p><p><img src="/posts/670dae13/image-20250107123106563.png" alt="image-20250107123106563" style="zoom:50%;"></p><hr><h2 id="三、设备虚拟化"><a href="#三、设备虚拟化" class="headerlink" title="三、设备虚拟化"></a>三、设备虚拟化</h2><h3 id="3-1-背景"><a href="#3-1-背景" class="headerlink" title="3.1 背景"></a>3.1 背景</h3><p>我们希望一个真实设备可以供多个虚拟机使用，在此基础上，我们希望有如下功能：</p><ul><li>无论虚拟机想使用什么设备，我们都能模拟出来，这样便于迁移</li><li>虚拟机看到的设备应该是独占的</li></ul><p>为此我们开发了以下技术：</p><h3 id="3-2-Direct-access"><a href="#3-2-Direct-access" class="headerlink" title="3.2 Direct access"></a>3.2 Direct access</h3><p>指的是，每个 VM 都独占设备，并不存在设备同时给多个 VM 使用的情况。不过同一个设备可以在不同时间给不同的 VM 使用。</p><p>这就引出了一个问题，就是现代 DMA 设备，是可以访问物理内存的，那么一个 VM 就可以利用设备，去接触另一个 VM 的物理内存。为了解决这一点，Intel 引入了 VT-d 拓展，这个拓展提供了 IOMMU，IOMMU 里也有一套页表，用于完成 device addr 到 physical addr 的映射，切换 VM 的时候需要切换 IOMMU 中的页表，这样就限制了设备的访存能力，增强了隔离性：</p><p><img src="/posts/670dae13/image-20250104234121679.png" alt="image-20250104234121679" style="zoom:50%;"></p><p>这种 Direct Acess 的优点在于，性能非常好；而且 VMM 实现简单（基本上没有引入额外的功能）。但是缺点在于，只能提供特定的设备（host 上得有这个设备）；而且不利于拓展，如果有 100 个 VM 同时运行，难道要 100 个网卡吗？此外，也不利于 VMM 监控设备情况，因为 VM 有设备的全部控制权，VMM 不好拦截。</p><h3 id="3-3-Emulating-Devices"><a href="#3-3-Emulating-Devices" class="headerlink" title="3.3 Emulating Devices"></a>3.3 Emulating Devices</h3><p>我们也可以使用软件去模拟真实硬件（需要注意，有些模拟硬件功能的实现还是要依赖真实硬件，比如网卡收发包）。VM 使用设备时，会 trap 到 VMM，VMM 调用模拟器，如下所示：</p><p><img src="/posts/670dae13/image-20250104234817734.png" alt="image-20250104234817734" style="zoom:40%;"></p><p>这种方式的优势在于，可以模拟出多种硬件，而且允许插桩。但是缺点是性能较差。</p><h3 id="3-4-Para-Virtualized-Devices"><a href="#3-4-Para-Virtualized-Devices" class="headerlink" title="3.4 Para-Virtualized Devices"></a>3.4 Para-Virtualized Devices</h3><p>这种方式类似于 CPU 的半虚拟化，即 VM 知道自己使用的不是真实设备，而是虚拟设备。这样的好处在于，虚拟设备可以比真实设备更简单，软件栈更薄，比如说 virtio：</p><p><img src="/posts/670dae13/image-20250104235458673.png" alt="image-20250104235458673" style="zoom:50%;"></p><h3 id="3-5-Hardware-Support"><a href="#3-5-Hardware-Support" class="headerlink" title="3.5 Hardware Support"></a>3.5 Hardware Support</h3><p>我们也可以让设备自身具有虚拟化的能力（有点类似于虚拟地址空间的感觉）。这种能力被称为 SR-IOV。一个支持 SR-IOV 功能的设备，在 PCI 配置空间中呈现为“多个设备”。其物理功能部分被称为 PF，虚拟功能部分被称为 VF，如下图所示：</p><p><img src="/posts/670dae13/image-20250104235923446.png" alt="image-20250104235923446" style="zoom:30%;"></p><h3 id="3-6-总结"><a href="#3-6-总结" class="headerlink" title="3.6 总结"></a>3.6 总结</h3><p>虚拟化技术总结如下：</p><p><img src="/posts/670dae13/image-20250105000018381.png" alt="image-20250105000018381" style="zoom:40%;"></p>]]></content>
    
    
    <summary type="html">&lt;h2 id=&quot;一、CPU-虚拟化&quot;&gt;&lt;a href=&quot;#一、CPU-虚拟化&quot; class=&quot;headerlink&quot; title=&quot;一、CPU 虚拟化&quot;&gt;&lt;/a&gt;一、CPU 虚拟化&lt;/h2&gt;&lt;h3 id=&quot;2-1-背景&quot;&gt;&lt;a href=&quot;#2-1-背景&quot; class=&quot;headerlink&quot; title=&quot;2.1 背景&quot;&gt;&lt;/a&gt;2.1 背景&lt;/h3&gt;&lt;p&gt;CPU 虚拟化范畴还挺多的，但是我们这里应该指的不包括不同 ISA 的虚拟化，而只是 CPU 的虚拟化，也就是虚拟出来的 CPU 和原本的 CPU 具有相同的 ISA 。&lt;/p&gt;
&lt;h3 id=&quot;2-2-Trap-amp-Emulate&quot;&gt;&lt;a href=&quot;#2-2-Trap-amp-Emulate&quot; class=&quot;headerlink&quot; title=&quot;2.2 Trap &amp;amp; Emulate&quot;&gt;&lt;/a&gt;2.2 Trap &amp;amp; Emulate&lt;/h3&gt;&lt;p&gt;为了虚拟化出多个 CPU，我们让虚拟的 OS 跑在用户态，也就是如下结构：&lt;/p&gt;</summary>
    
    
    
    <category term="计算机系统" scheme="https://thysrael.github.io/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%B3%BB%E7%BB%9F/"/>
    
    
    <category term="知识总结" scheme="https://thysrael.github.io/tags/%E7%9F%A5%E8%AF%86%E6%80%BB%E7%BB%93/"/>
    
    <category term="计算机系统" scheme="https://thysrael.github.io/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%B3%BB%E7%BB%9F/"/>
    
    <category term="S9复习" scheme="https://thysrael.github.io/tags/S9%E5%A4%8D%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>计算机系统-文件系统</title>
    <link href="https://thysrael.github.io/posts/15ec58e/"/>
    <id>https://thysrael.github.io/posts/15ec58e/</id>
    <published>2025-01-02T09:33:50.000Z</published>
    <updated>2025-01-04T16:00:42.269Z</updated>
    
    <content type="html"><![CDATA[<h2 id="一、数据结构"><a href="#一、数据结构" class="headerlink" title="一、数据结构"></a>一、数据结构</h2><h3 id="1-1-Inode"><a href="#1-1-Inode" class="headerlink" title="1.1 Inode"></a>1.1 Inode</h3><h4 id="1-1-1-整体结构"><a href="#1-1-1-整体结构" class="headerlink" title="1.1.1 整体结构"></a>1.1.1 整体结构</h4><p>Inode FS 被分为了 5 个区域“</p><p><img src="/posts/15ec58e/image-20250102215509118.png" alt="image-20250102215509118" style="zoom:40%;"></p><ul><li>SuperBlock：存储着后面分区的元数据</li><li>Inode Bitmap：记录着 Inode 区的使用情况</li><li>Data Bitmap：记录着 Data 区的使用情况</li><li>Inodes：所有 Inode 的数组，使用 Inode Number 索引，每个 Inode 记录着 Data 的组织形式</li><li>Data Region：数据区</li></ul><h4 id="1-1-2-文件"><a href="#1-1-2-文件" class="headerlink" title="1.1.2 文件"></a>1.1.2 文件</h4><p>在 Inode FS 中，每个文件对应一个 Inode。</p><p>Inode 是一种与页表非常相像的数据结构，都是利用偏移量来查找对应的数据块位置，所不同的是，Inode 的翻译是不均匀的（偏移量越大，需要的翻译级数越多），而页表的翻译是均匀的（无论偏移量是多少，翻译的次数都相同）。</p><p><img src="/posts/15ec58e/image-20250102214457730.png" alt="image-20250102214457730" style="zoom: 40%;"></p><p>有一种解释是，页表翻译是硬件过程，不太灵活；而 inode 的翻译是软件过程，所以可以设计的很灵活。我是觉得之所以 inode 设计得不均匀，是因为文件的大小是不固定且偏小的，所以大部分小文件可以直接翻译或者只使用一级翻译来完成。</p><p>至于为什么页表翻译要用硬件，是因为内存访问是一个很快的事情，如果用软件实现那就太慢了；相反，因为外存的访存速度过慢，软件翻译 inode 的过程并不构成关键路径。</p><p>当外存访存速度提升时（比如说用非易失内存做外存），就会导致软件翻译的速度变慢，原本的方法就不再适用了。</p><p>除了记录拥有的数据块以外，Inode 中还记录着文件的属性。</p><h4 id="1-1-3-目录"><a href="#1-1-3-目录" class="headerlink" title="1.1.3 目录"></a>1.1.3 目录</h4><p>Inode FS 的目录项，是由文件名和文件 Inode Number 组成的。我们检索文件名，就可以得到 Inode Number，然后根据 Inode Number 去 Inode 表中检索出对应的 Inode ，就可以访问对应的数据块了：</p><p><img src="/posts/15ec58e/image-20250102214950045.png" alt="image-20250102214950045" style="zoom:40%;"></p><p><code>/</code> 的 Inode Number 为 1。</p><p>如果我们希望访问 <code>/programs/pong.c</code>，那么访问磁盘 block id 的顺序是 <code>1(/ inode) -&gt; 14 (/ data) -&gt; 7 -&gt; (program inode) -&gt; 23 (program data) -&gt; 9(pong inode) -&gt; 61 (pong data)</code>  。</p><h4 id="1-1-4-链接"><a href="#1-1-4-链接" class="headerlink" title="1.1.4 链接"></a>1.1.4 链接</h4><p>硬链接指的是两个目录项都指向同一个 Inode Number，而软链接则是创建一个文件，里面是指向文件的文件名。可以说，硬链接是文件的指针，而软链接是指针的指针。如下所示：</p><p><img src="/posts/15ec58e/image-20250102220255509.png" alt="image-20250102220255509" style="zoom:33%;"></p><p>硬链接的一个重要作用是在不拷贝文件的情况下备份文件，可以避免对于文件的误删除。软链接就不可以，因为软链接与本身的文件并不平权，原文件一旦删除，软链接也就失去作用了。</p><h3 id="1-2-FAT"><a href="#1-2-FAT" class="headerlink" title="1.2 FAT"></a>1.2 FAT</h3><h4 id="1-2-1-整体结构"><a href="#1-2-1-整体结构" class="headerlink" title="1.2.1 整体结构"></a>1.2.1 整体结构</h4><p>FAT 即 File Allocation Table。是一种 Free-List 结构。它总共有 3 个区域：</p><p><img src="/posts/15ec58e/image-20250102222430225.png" alt="image-20250102222430225"></p><ul><li>SuperBlock：对应图上的“保留区域”，也被称为 BPB（BIOS Parameter Block）。</li><li>FAT 表：记录着文件的链表元数据，本质是一个 <code>next</code> 数组。一共有 2 个相同的拷贝，互为备份。</li><li>数据区：FAT 的数据块也被叫作簇，即 Cluster 。</li></ul><h4 id="1-2-2-文件"><a href="#1-2-2-文件" class="headerlink" title="1.2.2 文件"></a>1.2.2 文件</h4><p>FAT 中每个文件的所有数据块组成一个链表，链表的 <code>next</code> 域记录在 FAT 表中。如下图所示：</p><p><img src="/posts/15ec58e/image-20250102223119987.png" alt="image-20250102223119987"></p><p>单独把 <code>next</code> 域分离出来组成 FAT 表，是因为这样可以提高访存效率。此外，空闲的簇也会在 FAT 表中组织成一个 free list 。</p><h4 id="1-2-3-目录"><a href="#1-2-3-目录" class="headerlink" title="1.2.3 目录"></a>1.2.3 目录</h4><p>FAT 目录项记录着文件的起始簇号，根据起始簇号查阅 FAT 表，就可以顺序的读出所有的数据块。</p><p>最关键的是，文件的元数据不是存在 FAT 中的，而是存在目录项中。</p><h4 id="1-2-4-链接"><a href="#1-2-4-链接" class="headerlink" title="1.2.4 链接"></a>1.2.4 链接</h4><p>FAT 系统并不支持硬链接，因为两个目录项就有两份文件的元数据，这样维护一致性就太困难了。</p><h4 id="1-2-5-与-Inode-对比"><a href="#1-2-5-与-Inode-对比" class="headerlink" title="1.2.5 与 Inode 对比"></a>1.2.5 与 Inode 对比</h4><p>Inode 的设计，采用了类似页表的方式来记录和组织磁盘块，这种方式有利于随机访问；而 FAT 用链表的方式组织磁盘块，有利于顺序访问。</p><p>我个人觉得 FAT 更容易损坏，因为链表的特性就是，一旦一个节点损坏，那么后续节点都无法访问了。这可能也是为啥 FAT 表有双备份的原因。</p><p><img src="/posts/15ec58e/image-20250102224448955.png" alt="image-20250102224448955" style="zoom:150%;"></p><hr><h2 id="二、Crash-Consistency"><a href="#二、Crash-Consistency" class="headerlink" title="二、Crash Consistency"></a>二、Crash Consistency</h2><h3 id="2-1-背景"><a href="#2-1-背景" class="headerlink" title="2.1 背景"></a>2.1 背景</h3><p>有些文件操作需要更新 data 和 metadata 两个部分，而如果在这中间发生了 Crash，可能会导致出现一致性问题，也就是 data 和 metadata 不匹配的情况。为了解决这个问题，人们开发了多种方法，下面我们会介绍一些。</p><h3 id="2-2-Journaling"><a href="#2-2-Journaling" class="headerlink" title="2.2 Journaling"></a>2.2 Journaling</h3><h4 id="2-2-1-介绍"><a href="#2-2-1-介绍" class="headerlink" title="2.2.1 介绍"></a>2.2.1 介绍</h4><p>日志（journaling）指的是先将修改写到别的地方（journal），然后将修改进行原子性的提交（commit），最后再按照日志里的内容修改文件系统。</p><p><img src="/posts/15ec58e/image-20250102225924491.png" alt="image-20250102225924491" style="zoom:40%;"></p><p>按照这种设计，如果在 journal 阶段发生 crash，那么操作只是失败了，而原本的数据依然在文件系统中完好无损。commit 阶段是原子操作，不会被 crash。而如果在 overwrite 阶段发生 crash，那么文件系统的数据会被破坏，但是我们可以根据 journal 恢复损坏的部分。</p><p>Journaling 最大的问题是所有的数据都需要写两次，这样开销是不可接受的。所以我们退而求其次，我们只对 metadata 进行 journal 。也就是先写入 Data，然后再对 MetaData 进行 journaling ，最终效果如图。</p><p><img src="/posts/15ec58e/journal2.gif" alt="journal2" style="zoom:33%;"></p><h4 id="2-2-2-Journal-Order"><a href="#2-2-2-Journal-Order" class="headerlink" title="2.2.2 Journal Order"></a>2.2.2 Journal Order</h4><p>而在实际生产中，并不是只有 disk 这一层存在的，我们会在内存中构建一个 disk cache 用于提高访问 disk 的延迟。但是这种方式会导致我们写入 disk 的时候会存在乱序现象，也就是 A 先存入 disk cache，B 后存入 disk cache，但是 B 先从 cache 中写回，而 A 后写回，则在 disk 的角度，看到的是先 B 后 A，与在应用角度看到的先 A 后 B 是矛盾的。</p><p>而 Journaling 是依靠顺序的（order），这体现在，Data 和 MetaData Journal 的写入需要在 Journal Commit 之前，而 Journal Commit 需要在 MetaData 真正写入之前。为了确保顺序，我们使用了 flush 操作，最终效果如图：</p><p><img src="/posts/15ec58e/journal3.gif" alt="journal3" style="zoom:33%;"></p><p>但是 flush 操作又是极其影响性能的一个操作，所以我们一般不 flush，任由有可能出现的不一致性发生。</p><p>OptFS 是一种学界提出的解决 flush 低效的 idea，在上文中，主要有两个地方需要维护时序。OptFS 使用 checksum 技术来保证 Commit 一定在 Data 和 MetaData Journal 的写入之后发生，使用 Delay Write（似乎是一个硬件修改），来保证 MetaData 真正写入发生在前三者之后。</p><h3 id="2-3-Shadow-Paging"><a href="#2-3-Shadow-Paging" class="headerlink" title="2.3 Shadow Paging"></a>2.3 Shadow Paging</h3><p>还有一种叫作 Shadow Paging 的方式，也叫作 Copy-on-Write，指的是当涉及到写入文件系统的时候，并不直接 in-place write（overwrite）原本的文件，而是拷贝一个新的文件并写入，写入后，让目录项从原来的文件指向这个新的文件。</p><p><img src="/posts/15ec58e/image-20250104210055159.png" alt="image-20250104210055159" style="zoom:40%;"></p><p>Journaling 是先将修改写到日志中，然后再从日志中誊抄到真正的文件系统中，而 Shadow Paging 也是不先修改原本的文件，写到另一个地方去，但是并不需要再写一遍，不过它需要复制整个文件，而日志法，可能只需要记录 diff 部分，所以性能孰优孰劣，也并不好说。</p><p>Short-Circuit Shadow Paging 是一种学界提出的优化 Shadow Paging 的方法，简单来说就是利用原子变量来进行 in-place 操作，这样就避免了对整个文件的拷贝。</p><p><img src="/posts/15ec58e/image-20250104211213687.png" alt="image-20250104211213687" style="zoom:40%;"></p><hr><h2 id="三、NVMFS"><a href="#三、NVMFS" class="headerlink" title="三、NVMFS"></a>三、NVMFS</h2><h3 id="3-1-NVM"><a href="#3-1-NVM" class="headerlink" title="3.1 NVM"></a>3.1 NVM</h3><p>NVM 即 Non Volatile Memory，非易失性存储。这个概念我觉得应该要囊括磁盘这种传统外存，和现在新型的“非易失性内存”：</p><p><img src="/posts/15ec58e/image-20250104212311015.png" alt="image-20250104212311015" style="zoom:50%;"></p><p>在授课中，我们用 NVM 表示“非易失性内存”。NVMFS 就是基于非易失性内存开发的文件系统。</p><p><img src="/posts/15ec58e/image-20250104212755464.png" alt="image-20250104212755464" style="zoom:50%;"></p><p>NVM 的优点在于不再需要复杂的软件栈，因为与传统外存相比，我们使用访存指令就可以实现数据的访问；地址索引的方式，也不需要我们设计过于复杂的数据结构。而 NVM 的缺点在于，它的价格比传统外存贵，而性能又比传统内存差，性价比不高。</p><h3 id="3-2-挑战"><a href="#3-2-挑战" class="headerlink" title="3.2 挑战"></a>3.2 挑战</h3><p>NVMFS 的有一个挑战是，现在 cache 不再是由软件负责了（disk cache），而是由硬件 cache 负责，这就导致 NVMFS 很多乱序情况都更难处理（因为不如软件好操控）。</p><hr>]]></content>
    
    
    <summary type="html">&lt;h2 id=&quot;一、数据结构&quot;&gt;&lt;a href=&quot;#一、数据结构&quot; class=&quot;headerlink&quot; title=&quot;一、数据结构&quot;&gt;&lt;/a&gt;一、数据结构&lt;/h2&gt;&lt;h3 id=&quot;1-1-Inode&quot;&gt;&lt;a href=&quot;#1-1-Inode&quot; class=&quot;headerlink&quot; title=&quot;1.1 Inode&quot;&gt;&lt;/a&gt;1.1 Inode&lt;/h3&gt;&lt;h4 id=&quot;1-1-1-整体结构&quot;&gt;&lt;a href=&quot;#1-1-1-整体结构&quot; class=&quot;headerlink&quot; title=&quot;1.1.1 整体结构&quot;&gt;&lt;/a&gt;1.1.1 整体结构&lt;/h4&gt;&lt;p&gt;Inode FS 被分为了 5 个区域“&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/posts/15ec58e/image-20250102215509118.png&quot; alt=&quot;image-20250102215509118&quot; style=&quot;zoom:40%;&quot;&gt;&lt;/p&gt;</summary>
    
    
    
    <category term="计算机系统" scheme="https://thysrael.github.io/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%B3%BB%E7%BB%9F/"/>
    
    
    <category term="知识总结" scheme="https://thysrael.github.io/tags/%E7%9F%A5%E8%AF%86%E6%80%BB%E7%BB%93/"/>
    
    <category term="计算机系统" scheme="https://thysrael.github.io/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%B3%BB%E7%BB%9F/"/>
    
    <category term="S9复习" scheme="https://thysrael.github.io/tags/S9%E5%A4%8D%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>计算机系统-总论</title>
    <link href="https://thysrael.github.io/posts/cd771bfa/"/>
    <id>https://thysrael.github.io/posts/cd771bfa/</id>
    <published>2025-01-02T09:33:34.000Z</published>
    <updated>2025-01-04T16:00:42.269Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>那是 2023 年的夏天，楠神走出门，看向焦急等待的杰哥和我，问我们：</p><p>“你们知道“系统”和“体系结构”的区别吗？”</p></blockquote><h2 id="一、总论"><a href="#一、总论" class="headerlink" title="一、总论"></a>一、总论</h2><p>计算机系统这个系列，是我作为一名方向是 system 的研究生的，基于 IPADS 实验室开设的“计算机系统原理”等课程，整理而成的，并不保证正确性，因为 system 实在是浩如烟海，而我又太菜了。</p><p>在这篇博文里，我想谈谈我心目中的 system 是什么，这并不是 IPADS 课程的观点。</p><hr><h2 id="二、定义"><a href="#二、定义" class="headerlink" title="二、定义"></a>二、定义</h2><p>给 system 下一个定义，是我一直想干的事情。Wiki 百科和 ScienceDirect 都把 Compute System 定义为“一个由硬件、软件、数据组成的系统”。我觉得这个定义并不是很好，因为它是一句正确的废话，这个定义并不能指导科研。</p><p>还有一种方式，是将 system 定义为一套方法论和需求的集合。比如说在系统中常采用的方式是权衡、抽象、缓存、备份、并行和隔离等，而需求如下：</p><p><img src="/posts/cd771bfa/image-20250102194609112.png" alt="image-20250102194609112" style="zoom: 33%;"></p><p>这并不是全部的需求，但是好消息是 system researcher 经常在这个表中删除和增加条目。这种方式我觉得虽然和 system research 更加贴合，但是有些过于零散和变化，并没有一个核心的东西。</p><p>我想了很久，我现在觉得（也就是可能未来就改了），系统的定义是：</p><blockquote><p>在<strong>有限资源</strong>的封闭系统内，通过<strong>权衡（tradeoff）</strong>的方式，来达到我们的目的。</p></blockquote><p>对于这个定义，有如下细节：</p><ul><li>有限资源：系统并不能修改算法，因为算法可以将 $O(2^{n})$ 的方法优化成 $O(n)$ 的方法，这相当于凭空创造了资源；同样的，系统也不能修改硬件，不能优化 cache 的方式就是扩大 cache 容量，提高吞吐的方式是多买几个 GPU，这都是在系统中增加资源的方式。</li><li>权衡（tradeoff）：正因为资源是有限的，所以为了增强某项指标，就必须损害另一项指标。更进一步，为了更好的权衡，我们有诸多方法：<ul><li>牺牲一些我们不在乎的指标，增强一些我们看重的指标：其核心在于，寻找和发现那些我们并不在意的指标。</li><li>扩大系统范围：即使在当前系统中无法权衡，也可以通过将系统扩大的方式，包容进更多的资源，来进行权衡。这些资源可以是用户、硬件、算法、时间等（是的，这里违背定义的第一点了）。</li></ul></li></ul><p>在给出系统定义后，我还想在这里记录记录一下“抽象 abstract”，它不是系统的本质定义（封闭系统里的权衡），它只是多样复杂性与简单易用性的一种权衡。但是我正是出于对 abstract 和 complexity 的迷恋，而选择了 system 的方向。这种迷恋在我接触计算机之前就存在了，我小时候，是那种在熄灯后会一骨碌爬起来，恶狠狠地盯着窗帘思考这背后有什么的小屁孩。</p><p>我念研究生时，旧的时代已经过去，而新的时代还没有来临，希望它等等我。</p><p><img src="/posts/cd771bfa/image-20250102204434915.png" alt="image-20250102204434915" style="zoom:40%;"></p><hr><h2 id="三、意志"><a href="#三、意志" class="headerlink" title="三、意志"></a>三、意志</h2><p>虽然很不想承认，但是不得不承认，system 并不是自由发展的，它的发展深刻受到了社会需求和底层硬件的影响，总的来看，还是社会需求。</p><p>在最开始的时候，那时候的计算机还非常不人性化，冷冰冰的，人们研究的是操作系统内核和编程语言。</p><p>随着互联网时代的到来，人们研究的是并行、分布式、虚拟化、数据库。</p><p>而手机的普及，使得人们的研究焦点变成了安全、低功耗和异构计算。</p><p>现在 AI 时代来了，系统又会出现什么样的特征呢？这不取决于系统本身，这取决于 AI 。</p><hr>]]></content>
    
    
    <summary type="html">&lt;blockquote&gt;
&lt;p&gt;那是 2023 年的夏天，楠神走出门，看向焦急等待的杰哥和我，问我们：&lt;/p&gt;
&lt;p&gt;“你们知道“系统”和“体系结构”的区别吗？”&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&quot;一、总论&quot;&gt;&lt;a href=&quot;#一、总论&quot; class=&quot;headerlink&quot; title=&quot;一、总论&quot;&gt;&lt;/a&gt;一、总论&lt;/h2&gt;&lt;p&gt;计算机系统这个系列，是我作为一名方向是 system 的研究生的，基于 IPADS 实验室开设的“计算机系统原理”等课程，整理而成的，并不保证正确性，因为 system 实在是浩如烟海，而我又太菜了。&lt;/p&gt;
&lt;p&gt;在这篇博文里，我想谈谈我心目中的 system 是什么，这并不是 IPADS 课程的观点。&lt;/p&gt;
&lt;hr&gt;</summary>
    
    
    
    <category term="计算机系统" scheme="https://thysrael.github.io/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%B3%BB%E7%BB%9F/"/>
    
    
    <category term="知识总结" scheme="https://thysrael.github.io/tags/%E7%9F%A5%E8%AF%86%E6%80%BB%E7%BB%93/"/>
    
    <category term="计算机系统" scheme="https://thysrael.github.io/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%B3%BB%E7%BB%9F/"/>
    
    <category term="S9复习" scheme="https://thysrael.github.io/tags/S9%E5%A4%8D%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>吃喝玩乐-三周年</title>
    <link href="https://thysrael.github.io/posts/9925eca3/"/>
    <id>https://thysrael.github.io/posts/9925eca3/</id>
    <published>2024-12-18T09:55:40.000Z</published>
    <updated>2024-12-29T05:19:57.104Z</updated>
    
    <content type="html"><![CDATA[<h2 id="一、总论"><a href="#一、总论" class="headerlink" title="一、总论"></a>一、总论</h2><p>今天是 2024 年 12 月 18 日，距离我在北航新主楼 F534 的夜晚写下这个博客的 About 板块已经过去了 3 年时间，时间过得真是太快了。</p><p>这个博客能够坚持 3 年时间，最重要的原因是有人（当然我希望小姑娘多一些）去看我的博客，博客的读者是我更新的最大动力。感谢读者们的支持和反馈，没有你们就没有“钟鼓楼”。</p><p>当时我在博客里写了“我没有报六级，也没有报冬奥会志愿者，没有小姑娘需要陪”，三年后，我居然也还是“没有报六级，也没有报冬奥会志愿者，没有小姑娘需要陪”的状态，也算是不忘初心了，乐。</p><h2 id="二、回顾"><a href="#二、回顾" class="headerlink" title="二、回顾"></a>二、回顾</h2><p>回想起来，我窝在 F534 通宵写祭祖博客的日子还历历在目。那个时候 F534 还没有被“安全检查”，是北航的一个通宵好地方，很多二系兄弟在那里做实验，打打闹闹、互相欢谑的声音是最好的解压剂；那里还有很多“住在实验室”里的人，我每次看到角落里的饭盆、折叠床和小被子，都觉得这地方比我宿舍还有生活气息，我觉得就算丧尸爆发，F534 也可以靠这些物资成为末世之光，不过这个幻想在安全检查后破灭了；当然也有不是那么开心的事情，那里有可能会刷新出可恶的情侣，他们不但互相啃来啃去的，四条腿混在一起我都分不清谁是谁的。他们甚至还会抽空泡个面条，大冬天的腾起一个宏大的雾柱，这对于当时形单影只的我是一个巨大的刺激。</p><p>在我写完祭祖博客以后，我认识了很多很好的朋友，也当上了祭祖助教，可以说是春风得意了。如果你那时候就认识我，你或许可以看到我在北航的校园里，骑着那辆特别漂亮的邮差二八大杠，摇头晃脑地去图书馆写博客。我这段时间写了基本上将所有我想写的东西都写了个遍，我那段时间简直入魔了。现在我想起来我和我 OO 助教拍胸脯保证的要写的那些博客，都感觉非常羞耻，我那个时候想过写“IDEA 的快捷键”，但是直到现在，我其实都没有搞懂过 Java 项目的管理工具，我当时是怎么有自信纠结这种无聊的细节的？奥，我想起来了六系 21 级水群刚成立的时候，我在群里半推半让、暗戳戳地安利我自己的博客的时候的搞笑嘴脸，从外人角度看上去，应该还挺猖狂的吧。</p><p>再后来就到了大三下学期，我接了三个活儿：罗杰软工、操作系统比赛、保研。那段时间真的是啊，罗杰软工榨干了所有我的写博客的动力，当然其他事情其实也扎破了我为我自己吹起的幻象泡泡。那个学期我几乎没有更新我的博客，后面也没有补上。我对于大三下学期，我觉得是我做错了很多事情，我不过就是一个幼稚的孩子，喜欢提着别人的领子去问“我对没有对？你错没有错？”。再深入的思考我也没有勇气再进行了，我不知道最后的那个结果我是不是可以接受（这么看我比大一结束的时候还怂）。</p><p>后来我进了新的实验室，到现在也是这样，新实验室的有很多有趣的知识，任务也很紧（主要原因是我太菜了，本科四年光玩了），很少有时间能坐下来写博客了。而且新的知识相比于授课知识，也变得更加零碎无体系化，我将这些知识记录到 <a href="https://thysrael.github.io/Roam-Site/">roam</a> 里面，我也不确定这是一种形式上的进化，还是一种心灰意懒的妥协。</p><p>奥对了，后来那辆二八大杠我再也不骑了，那辆车的链条很久没有膏过油了，我再也骑不动了。我之前还喜欢在匿名提问箱里写东西，后来我收到了一个提问，他说他看完了我的所有回答，说我是一个虚伪的人。我不知道怎么回答这个提问，所以也不再用提问箱了。其他的事情，我也没有思考出什么确定的结论来，瑷。</p><h2 id="三、未来"><a href="#三、未来" class="headerlink" title="三、未来"></a>三、未来</h2><p>上交这边的课真的很有意思，无论是分布式和并行计算相关的课程，还是 Firmware 的课程，甚至是自然辩证法，经常是上完课后恨不得一拍大腿，说“原来是这样子的，我之前真是井底之蛙呀！”。我记了很多笔记，希望有时间能够整理好发到博客上，真的超级有趣！自然辩证法相关的东西已经被写到 roam 上了，但是其他的，我更希望是以正式博文的形式表达出来，但是这样难度很高。</p><p>另外这个学期我补充了很多西方的历史，把很多之前在脑子中零散的概念都梳理出来了，感觉以后吹逼小故事可以更加真实了，要是也有时间总结出来就好了。</p><p>另外我还希望写一些关于《金瓶梅》的东西，但是它真的好难读啊，每天下班后脑子晕晕的，根本读不进去呀！！！</p><h2 id="四、其他"><a href="#四、其他" class="headerlink" title="四、其他"></a>四、其他</h2><p>我有想过停更的，一直以来支持我写博客的动力都是有人看我的博客，但是，似乎今后再也没有人会看我写的东西了，我现在都不知道我在做什么，怎么能指望读者会知道呢？</p><p>但是我看到最刚毅的人使用了迂回的方式，最聪明的人选择了无聊，最真诚的人让人生厌。我觉得事情不应该是这样的，这个世界上，一定会有人，也应当有人，选择一条路走到黑，选择痛苦而不是无聊，而真诚，也应当有好的回报。所以我还是希望写下去，写到这样的人看到我的博客。</p>]]></content>
    
    
    <summary type="html">&lt;h2 id=&quot;一、总论&quot;&gt;&lt;a href=&quot;#一、总论&quot; class=&quot;headerlink&quot; title=&quot;一、总论&quot;&gt;&lt;/a&gt;一、总论&lt;/h2&gt;&lt;p&gt;今天是 2024 年 12 月 18 日，距离我在北航新主楼 F534 的夜晚写下这个博客的 About 板块已经过去了 3 年时间，时间过得真是太快了。&lt;/p&gt;
&lt;p&gt;这个博客能够坚持 3 年时间，最重要的原因是有人（当然我希望小姑娘多一些）去看我的博客，博客的读者是我更新的最大动力。感谢读者们的支持和反馈，没有你们就没有“钟鼓楼”。&lt;/p&gt;
&lt;p&gt;当时我在博客里写了“我没有报六级，也没有报冬奥会志愿者，没有小姑娘需要陪”，三年后，我居然也还是“没有报六级，也没有报冬奥会志愿者，没有小姑娘需要陪”的状态，也算是不忘初心了，乐。&lt;/p&gt;
&lt;h2 id=&quot;二、回顾&quot;&gt;&lt;a href=&quot;#二、回顾&quot; class=&quot;headerlink&quot; title=&quot;二、回顾&quot;&gt;&lt;/a&gt;二、回顾&lt;/h2&gt;</summary>
    
    
    
    <category term="吃喝玩乐" scheme="https://thysrael.github.io/categories/%E5%90%83%E5%96%9D%E7%8E%A9%E4%B9%90/"/>
    
    
    <category term="吃喝玩乐" scheme="https://thysrael.github.io/tags/%E5%90%83%E5%96%9D%E7%8E%A9%E4%B9%90/"/>
    
    <category term="S9课上" scheme="https://thysrael.github.io/tags/S9%E8%AF%BE%E4%B8%8A/"/>
    
  </entry>
  
  <entry>
    <title>沟通交流-学术写作</title>
    <link href="https://thysrael.github.io/posts/2d78b508/"/>
    <id>https://thysrael.github.io/posts/2d78b508/</id>
    <published>2024-11-28T02:07:14.000Z</published>
    <updated>2024-11-28T08:33:31.893Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Overview"><a href="#Overview" class="headerlink" title="Overview"></a>Overview</h2><p>这本书是对《Science Research Writing For Non-Native Speakers of English》的总结梳理。这本书分为多个章节，每个章节对应一个论文写作里的部分。在每个章节内部，又有如下几个部分：</p><ol><li>介绍一下这个章节在整体文章中的作用</li><li>展示一篇例文</li><li>介绍一些基础的英语语法和词汇</li><li>对例文结构进行分析（分解成小组件），也就是他说的 model</li><li>对 model 进行一些心法层面的阐述，也就是他说的 key</li><li>按照 model 和 key 介绍一些固定词汇、句式和搭配，也就是他说的 vocabulary</li><li>最后让你自己写一个文章</li></ol><p>很多东西都是实践性质的，并非专业知识本身。所以如果总结的话，其实可以按照 model 的形式来组织 vocabulary ，其他的东西（比如例文、基础语法、动手实践）都可以省略，结构清晰。</p><p>因为时间问题，所以我会逐步更新这篇博文。</p><h2 id="Architecture"><a href="#Architecture" class="headerlink" title="Architecture"></a>Architecture</h2><p>这篇文章将一片论文分成了 5 个部分：</p><p><img src="/posts/2d78b508/shape.png" alt="shape"></p><ul><li>Abstract 用于提供一个对文章的总结</li><li>Introduction 初步介绍问题，帮助原本陌生的读者对问题的认识更加具象和熟悉</li><li>Methodology 用于描述自己是如何进行这项研究的</li><li>Results 用于描述研究的现象和结构</li><li>Conclusion/Discussion 用于升华主题，让具象问题变得抽象普适</li></ul><p>而对于计算机会议论文来说，在章节方面会有一定程度的细化。Introduction 部分会包括：</p><ul><li>Background: 介绍背景知识</li><li>Motivation: 介绍研究动机</li></ul><p>Methodology 部分会包括：</p><ul><li>Insight: 完成设计的核心思想</li><li>Design: 设计本身</li><li>Implementation: 具体的实现</li></ul><p>Results 部分会包括：</p><ul><li>如果一个新技术，那么需要指明技术的应用场景 Use Case ；如果是原有技术改进，那么需要指明 Baseline </li><li>Evaluation: 对设计的评估</li></ul><p>Conclusion/Discussion 部分会包括：</p><ul><li>Discussion: 负责将研究升华，提供一些更加定性和抽象的描述</li><li>Related Work: 用于和现有工作对比</li><li>Conclusion: 对上文的总结回顾，起行文上的收束作用（而 Discussion 则承担设计上的发散升华作用）。</li></ul><p>如果有机会，我希望按照更加符合计算机会议的方式重新组织一下这个模板。</p><h2 id="Results"><a href="#Results" class="headerlink" title="Results"></a>Results</h2><h3 id="Revisit-the-Research-Aim-Exisiting-Research"><a href="#Revisit-the-Research-Aim-Exisiting-Research" class="headerlink" title="Revisit the Research Aim / Exisiting Research"></a>Revisit the Research Aim / Exisiting Research</h3><p>不要直接描述自己的实验结果，这样过于唐突了，要想办法把读者和后面的实验联系起来，比较有效的方法就是回顾前文或者已有的其他人的工作，这些都是对实验的一种背景介绍，一种铺垫。</p><p>对前文的回顾：</p><blockquote><p>as discussed previously, …<br>as mentioned earlier/before, ..<br>as outlined in the introduction, …</p></blockquote><p>对实验目的的回顾：</p><blockquote><p>in order to …, we examined …<br>it is important to reiterate that …<br>our aim/purpose/intention was to …<br>since/because …, we investigated …<br>to investigate …, we needed to …<br>the main purpose of this work was …<br>In this work, we sought to …</p></blockquote><p>对现有其他实验的回顾：</p><blockquote><p>as reported, …<br>it is known from the literature that …<br>the aforementioned theory/aim/prediction …<br>in earlier studies …</p></blockquote><p>对结果的预期：</p><blockquote><p>we reasoned/predicted that …<br>it was predicted that …</p></blockquote><h3 id="General-Overview-of-Results"><a href="#General-Overview-of-Results" class="headerlink" title="General Overview of Results"></a>General Overview of Results</h3><p>在介绍具体的实验之前，应当先给读者一个整体印象，这样才能避免读者陷入“流水帐式阅读”。整体印象应当包括我们的实验设置、实验目的、最终的实现效果。</p><p>对实验的总结概括：</p><blockquote><p>in this section, we compare/evaluate/present …<br>the results are divided into two parts as follows:</p></blockquote><p>对结果的总结概括：</p><blockquote><p>generally speaking, …<br>in general, …<br>in most/all cases, …<br>in the main, …<br>it is appparent that in all/most/the majority of cases, …<br>it is evident from the results that …<br>on the whole, …<br>the overall response was …<br>using the method described above, we obtained …</p></blockquote><h3 id="Invitation-to-View-Results"><a href="#Invitation-to-View-Results" class="headerlink" title="Invitation to View Results"></a>Invitation to View Results</h3><p>应当主动引导读者去看图或者看表，而不是只画图，而在正文里绝口不提。</p><p>对结果的被动引用：</p><blockquote><p>(see Fig)<br>according to Fig<br>as detailed/evident/illustrated/indicated/listed/shown from/in Fig<br>as can be seen/found/identified/observed from/in Fig<br>comparing Fig.1 and Fig.4 shows that …<br>displayed in Fig<br>evidence for this is in Fig<br>inspection of Fig indicates …<br>be given/represented/visible in Fig<br>in Fig we compare/present ….<br>results are given in Fig</p></blockquote><p>对结果的主动引用</p><blockquote><p>Fig contains/corresponds/demostrates/displays/gives/illustates/lists/plots/presents/provides/reports/represents/reveals/shows/summaries</p></blockquote><p>在引用结果时，某张图或者某张表的粒度可能过粗，可以更细一些，指向图中的某个具体数据：</p><blockquote><p>the data in Fig<br>the rate in Table<br>the results of Fig</p></blockquote><h3 id="Special-Key-Results-in-Detail"><a href="#Special-Key-Results-in-Detail" class="headerlink" title="Special/Key Results in Detail"></a>Special/Key Results in Detail</h3><p>讲究的是客观描述与主观判断的结合。</p><h4 id="Objective-Description"><a href="#Objective-Description" class="headerlink" title="Objective Description"></a>Objective Description</h4><p>这些词应当加上具体的数据来修饰，这样才能更有说服力和客观。比如说</p><blockquote><p>2% increase</p></blockquote><p>增加：</p><blockquote><p>accelerate<br>expand<br>increase<br>be higher/highest<br>peak<br>precede<br>rise</p></blockquote><p>减少：</p><blockquote><p>decline<br>decrease<br>delay<br>drop<br>fall<br>be lower/lowest<br>reduce</p></blockquote><p>变化：</p><blockquote><p>change<br>vary<br>be different<br>produce</p></blockquote><p>不变：</p><blockquote><p>be constant/unaffected/unchanged<br>remain constant/the same<br>level off</p></blockquote><p>存在：</p><blockquote><p>exist<br>find<br>range from<br>be found/seen<br>occur</p></blockquote><p>对比：</p><blockquote><p>be equal/indentical/uniform<br>match</p></blockquote><h4 id="Subjective-Description"><a href="#Subjective-Description" class="headerlink" title="Subjective Description"></a>Subjective Description</h4><p>数量评价：</p><blockquote><p>abundant<br>adequate<br>inadequate<br>minimal<br>negligible<br>imperceptible<br>few<br>brief<br>sufficient<br>scarce<br>substantial<br>immense</p></blockquote><p>程度评价：</p><blockquote><p>almost<br>largely<br>likelihood<br>more or less<br>somewhat<br>most<br>mild<br>virtual<br>considerable<br>general</p></blockquote><p>图表评价：</p><blockquote><p>clear<br>measurable<br>sharp<br>smooth<br>steep<br>sudden</p></blockquote><p>符合预期/不符合预期：</p><blockquote><p>acceptable<br>appreciable<br>appropriate<br>unexpected<br>unusual</p></blockquote><p>非常好/差：</p><blockquote><p>dramatic<br>drastic<br>essential<br>excellent<br>extensive<br>important<br>marked<br>noticeable<br>overwhelming<br>poor<br>remarkable<br>satisfactory<br>serious<br>severe<br>significant<br>simple<br>striking<br>strong<br>suitable<br>surprising<br>radical<br>rapid<br>valuable</p></blockquote><p>比较：</p><blockquote><p>comparable<br>consistent<br>distinct<br>equivalent<br>excessive<br>exceptional<br>extreme<br>fair<br>obvious<br>only<br>resembling<br>similar<br>dominant</p></blockquote><p>名词：</p><blockquote><p>tendency<br>the majority of<br>main</p></blockquote><h3 id="Comparison-with-Other-Results"><a href="#Comparison-with-Other-Results" class="headerlink" title="Comparison with Other Results"></a>Comparison with Other Results</h3><p>和其他已有成果对比是非常必要的，baseline 必须好好选取，才能增加说服力。</p><p>印证/推翻：</p><blockquote><p>as anticipated, …<br>as expected, …<br>as predicted by …<br>as reported by …<br>confirm<br>corroborate<br>disprove<br>inconsistent with<br>concur with<br>inline with<br>be in good agreement<br>prove<br>refute<br>reinforce<br>support<br>validate<br>verify</p></blockquote><p>优劣：</p><blockquote><p>compare well with<br>be better than</p></blockquote><p>相似性：</p><blockquote><p>consistent with<br>contrary to<br>match<br>be identical<br>be similar/dissimilar to<br>be parallel to<br>be unlike<br>correlate</p></blockquote><h3 id="Problems-with-Results"><a href="#Problems-with-Results" class="headerlink" title="Problems with Results"></a>Problems with Results</h3><p>似乎这个会被写入 future work 而不是 evaluation 中。</p><p>问题：</p><blockquote><p>immaterial<br>incompelte<br>infinitesimal<br>insignificant<br>less than ideal/perfect<br>a minor deficit/limitation</p></blockquote><p>转折：</p><blockquote><p>despite this<br>however<br>nevertheless</p></blockquote><p>开脱：</p><blockquote><p>at a preliminary attempt<br>neligible<br>not always/completely reliable/accurate/ideal/identical/clear/perfect/precise/significant<br>of no/little consequence/significance<br>only<br>reasonable results were obtain<br>room for improvement<br>slightly<br>a slight mismatch/limitation<br>somewhat<br>technicality<br>unimportant</p></blockquote><p>原因：</p><blockquote><p>may/could/might have been<br>beyond the scope of this study<br>be not the focus of this paper<br>be not within the scope of this paper<br>caused by<br>difficult to<br>due to<br>hard to control<br>inevitable<br>it should be noted that …<br>be not attempted/examined/expored in this study<br>possible sources of error<br>unavoidable<br>unexpected<br>unfortunately<br>unpredictable<br>unworkable<br>unavailable</p></blockquote><p>解决办法：</p><blockquote><p>futher work is planned<br>futher work should …<br>future work will<br>in future, care should be taken<br>in future, it is advised that</p></blockquote><h3 id="Possible-Implications-on-Results"><a href="#Possible-Implications-on-Results" class="headerlink" title="Possible Implications on Results"></a>Possible Implications on Results</h3><p>感觉似乎过于侧重 possible 了，有些让人感到虚弱了，不应该出现在这里。不应当成为一个必要的结构，而是应当成为一种行文的小修饰。</p><blockquote><p>apparently<br>could be due to / explained by / attributed to / interpreted as / seen as<br>could account for<br>evidently<br>imply that<br>indicate that<br>in some circumstances<br>be owing to / associated with / likely / linked to / related to<br>it appears that<br>it could be concluded/infered/speculated/assumed that …<br>it is conceivable …<br>it is evident<br>it is logical that<br>it is thought/believed that<br>plausible<br>suggesting<br>likely<br>may/might/perhaps<br>possibly/possiblity<br>potentially<br>presumably<br>probably<br>provide compelling evidence<br>tend to / tendency</p></blockquote>]]></content>
    
    
    <summary type="html">&lt;h2 id=&quot;Overview&quot;&gt;&lt;a href=&quot;#Overview&quot; class=&quot;headerlink&quot; title=&quot;Overview&quot;&gt;&lt;/a&gt;Overview&lt;/h2&gt;&lt;p&gt;这本书是对《Science Research Writing For Non-Native Speakers of English》的总结梳理。这本书分为多个章节，每个章节对应一个论文写作里的部分。在每个章节内部，又有如下几个部分：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;介绍一下这个章节在整体文章中的作用&lt;/li&gt;
&lt;li&gt;展示一篇例文&lt;/li&gt;
&lt;li&gt;介绍一些基础的英语语法和词汇&lt;/li&gt;
&lt;li&gt;对例文结构进行分析（分解成小组件），也就是他说的 model&lt;/li&gt;
&lt;li&gt;对 model 进行一些心法层面的阐述，也就是他说的 key&lt;/li&gt;
&lt;li&gt;按照 model 和 key 介绍一些固定词汇、句式和搭配，也就是他说的 vocabulary&lt;/li&gt;
&lt;li&gt;最后让你自己写一个文章&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;很多东西都是实践性质的，并非专业知识本身。所以如果总结的话，其实可以按照 model 的形式来组织 vocabulary ，其他的东西（比如例文、基础语法、动手实践）都可以省略，结构清晰。&lt;/p&gt;
&lt;p&gt;因为时间问题，所以我会逐步更新这篇博文。&lt;/p&gt;</summary>
    
    
    
    <category term="沟通交流" scheme="https://thysrael.github.io/categories/%E6%B2%9F%E9%80%9A%E4%BA%A4%E6%B5%81/"/>
    
    
    <category term="知识总结" scheme="https://thysrael.github.io/tags/%E7%9F%A5%E8%AF%86%E6%80%BB%E7%BB%93/"/>
    
    <category term="S9课上" scheme="https://thysrael.github.io/tags/S9%E8%AF%BE%E4%B8%8A/"/>
    
    <category term="沟通交流" scheme="https://thysrael.github.io/tags/%E6%B2%9F%E9%80%9A%E4%BA%A4%E6%B5%81/"/>
    
  </entry>
  
  <entry>
    <title>并行计算-并行原语</title>
    <link href="https://thysrael.github.io/posts/cf617ad0/"/>
    <id>https://thysrael.github.io/posts/cf617ad0/</id>
    <published>2024-09-29T08:42:45.000Z</published>
    <updated>2024-10-21T06:12:52.420Z</updated>
    
    <content type="html"><![CDATA[<h2 id="一、总论"><a href="#一、总论" class="headerlink" title="一、总论"></a>一、总论</h2><p>在并行编程中，除了“互斥”这个原语外（一般是采用“锁”来实现），还存在“同步（synchronous）”这个原语，这个原语指的是“各个事件按照特定顺序执行”的需求。比如说在生产者消费者模型中，必须要让生产者先生产，消费者才可以进行消费，这就是一种同步行为，是没有办法仅仅依靠锁来实现的。</p><p>当涉及互斥时，涉及到的术语是 <code>lock, unlock, mutex</code> ，而涉及到同步是术语是 <code>wait, signal, notify, barrier</code> 等。之前我只重视了互斥的学习，而对于同步语义，则非常忽视。</p><hr><h2 id="二、互斥"><a href="#二、互斥" class="headerlink" title="二、互斥"></a>二、互斥</h2><p>上锁是维护互斥性的方式，只有拿到锁的线程，可以访问关键区域。</p><h3 id="2-1-自旋锁"><a href="#2-1-自旋锁" class="headerlink" title="2.1 自旋锁"></a>2.1 自旋锁</h3><p>自旋锁（Spinlock）是最为朴素的锁，它的形式是这样的：</p><pre class="line-numbers language-c" data-language="c"><code class="language-c"><span class="token keyword">while</span> <span class="token punctuation">(</span><span class="token operator">!</span>condition<span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token comment">// test lock</span>condition <span class="token operator">=</span> false<span class="token punctuation">;</span> <span class="token comment">// lock</span><span class="token comment">// do some critical thing...</span>condition <span class="token operator">=</span> true<span class="token punctuation">;</span> <span class="token comment">// unlock</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>只要不满足 <code>condition</code>，那么就会一直停留在 <code>while</code> 语句中执行。所谓的“自旋”，指的就是“自我重复循环”的意思。</p><h3 id="2-2-互斥锁"><a href="#2-2-互斥锁" class="headerlink" title="2.2 互斥锁"></a>2.2 互斥锁</h3><p>互斥锁（mutex，mutual exclusive）的形式如下：</p><pre class="line-numbers language-c" data-language="c"><code class="language-c"><span class="token keyword">while</span> <span class="token punctuation">(</span><span class="token operator">!</span>condition<span class="token punctuation">)</span> <span class="token function">yield</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token comment">// test lock</span>condition <span class="token operator">=</span> false<span class="token punctuation">;</span> <span class="token comment">// lock</span><span class="token comment">// do some critical thing...</span>condition <span class="token operator">=</span> true<span class="token punctuation">;</span> <span class="token comment">// unlock</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>一旦条件检验不通过，自旋锁会立刻进行下一次条件检验，而互斥锁则会 <code>yield</code>，将执行权让给其他线程。自旋锁的设计，是在自旋的过程中依然占据资源，其优势在于并不会引入额外的上下文切换开销，当自旋时间不多的时候（也就是关键区比较短），那么用自旋锁比较合适。而如果关键区比较长，切换上下文开销小于资源占用的开销，那么就用互斥锁更为合适。</p><h3 id="2-3-CAS"><a href="#2-3-CAS" class="headerlink" title="2.3 CAS"></a>2.3 CAS</h3><p>上述的锁的实现都是“伪代码”，如果是 C 代码的话，是会存在问题的。考虑这样一个情形，此时有 A 和 B 都在等待 <code>condition</code> 发生变化，一旦 <code>condition</code> 变成 <code>true</code>，A 从 <code>while</code> 中离开，然后在“ A 设置 <code>condition = false</code> 来阻止其他的线程访问”这个时刻之前，突然调度器将 A 挂起，将 B 执行，此时 <code>conditon</code> 已然是 <code>true</code>，所以 B 也可以进入关键区，此时有两个线程在关键区，那么就发生了错误。</p><p>从上述描述中可以看出，发生错误的核心在于“检测 condition”和“设置 condition”这两个行为是没有绑定在一起的，一旦上下文切换发生在二者之间，就会导致发生错误。我们可以在硬件层面上将这两个行为统一成一个“原子行为”，一个常见的实现就是 CAS（Compare And Swap），其伪代码如下：</p><pre class="line-numbers language-c" data-language="c"><code class="language-c"><span class="token keyword">int</span> <span class="token function">CompareAndSwap</span><span class="token punctuation">(</span><span class="token keyword">int</span> <span class="token operator">*</span>ptr<span class="token punctuation">,</span> <span class="token keyword">int</span> expected<span class="token punctuation">,</span> <span class="token keyword">int</span> new<span class="token punctuation">)</span> <span class="token punctuation">{</span>  <span class="token keyword">int</span> old <span class="token operator">=</span> <span class="token operator">*</span>ptr<span class="token punctuation">;</span>  <span class="token keyword">if</span><span class="token punctuation">(</span>old <span class="token operator">==</span> expected<span class="token punctuation">)</span> <span class="token punctuation">{</span>    <span class="token operator">*</span>ptr <span class="token operator">=</span> new<span class="token punctuation">;</span>  <span class="token punctuation">}</span>  <span class="token keyword">return</span> old<span class="token punctuation">;</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>可以看到这个行为基本上就是检验旧值是否符合预期，如果符合预期就将旧值修改为新值，否则保持不变。此时就可以轻易实现一个自旋锁：</p><pre class="line-numbers language-c" data-language="c"><code class="language-c"><span class="token keyword">void</span> <span class="token function">lock</span><span class="token punctuation">(</span><span class="token class-name">lock_t</span> <span class="token operator">*</span>lock<span class="token punctuation">)</span> <span class="token punctuation">{</span>  <span class="token keyword">while</span><span class="token punctuation">(</span><span class="token function">CompareAndSwap</span><span class="token punctuation">(</span><span class="token operator">&amp;</span>lock<span class="token operator">-&gt;</span>condition<span class="token punctuation">,</span> true<span class="token punctuation">,</span> false<span class="token punctuation">)</span> <span class="token operator">==</span> false<span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token punctuation">}</span><span class="token keyword">void</span> <span class="token function">unlock</span><span class="token punctuation">(</span><span class="token class-name">lock_t</span> <span class="token operator">*</span>lock<span class="token punctuation">)</span> <span class="token punctuation">{</span>  lock<span class="token operator">-&gt;</span>condition <span class="token operator">=</span> true<span class="token punctuation">;</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>突然想起来，<code>lock/unlock</code> 之间的关键区，也可以看作是原子性的，没有任何其他的指令可以插手这个区域。锁机制可以看作是对 CAS 原子性的一种拓展，原先只有一条指令是原子性的，现在是一个区域内的所有指令都是原子性的了。</p><p>我们设计关键区的时候，除了“共享”外，还可以从“不被打断”的角度去设计。 </p><hr><h2 id="三、同步"><a href="#三、同步" class="headerlink" title="三、同步"></a>三、同步</h2><h3 id="3-1-条件变量"><a href="#3-1-条件变量" class="headerlink" title="3.1 条件变量"></a>3.1 条件变量</h3><p>可以看到上述描述的互斥原语和锁机制，往往是发生在身份相同的线程中的，它们往往执行同一段代码，履行相同的职责，所以需要互斥机制来保证独立性。不过线程并不只有“竞争者”这一个身份，还有可能是”协作者“，此时他们就需要”同步“机制来确保他们的协同性。</p><p>同步机制比较简单的一个版本就是“先 <code>2</code> 后 <code>1</code>”，其中 <code>1</code> 和 <code>2</code> 是两个不同的线程，如果仅有锁机制，我们没法保证执行的顺序问题。但是如果当 <code>1</code> 先执行的时候，让它先 <code>wait</code> 一下 <code>2</code> ，直到 <code>2</code> 执行完了以后 <code>signal</code> 提醒一下它，它再加入就绪队列。其中 <code>1</code> 的“等待室”，就被称为条件变量（Condition Variable）。</p><p>基于这种思想，我们有了第一版代码：</p><pre class="line-numbers language-c" data-language="c"><code class="language-c"><span class="token keyword">void</span> <span class="token operator">*</span><span class="token function">f1</span><span class="token punctuation">(</span><span class="token keyword">void</span> <span class="token operator">*</span>arg<span class="token punctuation">)</span><span class="token punctuation">{</span><span class="token function">pthread_cond_wait</span><span class="token punctuation">(</span><span class="token operator">&amp;</span>cond<span class="token punctuation">,</span> <span class="token operator">&amp;</span>mutex<span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token function">printf</span><span class="token punctuation">(</span><span class="token string">"I am f1\n"</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token punctuation">}</span><span class="token keyword">void</span> <span class="token operator">*</span><span class="token function">f2</span><span class="token punctuation">(</span><span class="token keyword">void</span> <span class="token operator">*</span>arg<span class="token punctuation">)</span><span class="token punctuation">{</span><span class="token function">printf</span><span class="token punctuation">(</span><span class="token string">"I am f2\n"</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token function">pthread_cond_signal</span><span class="token punctuation">(</span><span class="token operator">&amp;</span>cond<span class="token punctuation">)</span>；<span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>需要注意此时的 <code>cond_wait</code> 和 mutex 的 <code>yield</code> 不同，<code>yield</code> 是将线程加入到 OS 的待调度队列中，如果队列中没有其他线程了，那么等待锁的线程还是会反复被调用，而 <code>cond_wait</code> 是一个独立的等待队列，如果不被 <code>signal/notify</code> ，那么就永远不会被调度。这就导致在同步的应用中，常常出现有些线程在等待室里“醒不过来”的情况。</p><p>然后我们就会发现一个问题，就是如果 <code>2</code> 先执行完成呢？那么 <code>1</code> 就会一直 <code>wait</code> 下去，因为 <code>signal</code> 信号早就执行完了，这个问题被称为“唤醒丢失”。让我们再回顾需求，会发现其实 <code>1</code> 只有在 <code>2</code> 还没有执行的时候，才需要 <code>wait</code> ，如果本来就是 <code>2</code> 先执行，那么就无须 <code>wait</code> 了，我们可以用一个共享变量来指示是否线程 <code>1</code> 已经执行完了，于是我们得到了第二版：</p><pre class="line-numbers language-c" data-language="c"><code class="language-c"><span class="token keyword">void</span> <span class="token operator">*</span><span class="token function">f1</span><span class="token punctuation">(</span><span class="token keyword">void</span> <span class="token operator">*</span>arg<span class="token punctuation">)</span><span class="token punctuation">{</span><span class="token keyword">if</span> <span class="token punctuation">(</span>condition <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">)</span> <span class="token punctuation">{</span><span class="token function">pthread_cond_wait</span><span class="token punctuation">(</span><span class="token operator">&amp;</span>cond<span class="token punctuation">,</span> <span class="token operator">&amp;</span>mutex<span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token punctuation">}</span><span class="token function">printf</span><span class="token punctuation">(</span><span class="token string">"I am f1\n"</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token punctuation">}</span><span class="token keyword">void</span> <span class="token operator">*</span><span class="token function">f2</span><span class="token punctuation">(</span><span class="token keyword">void</span> <span class="token operator">*</span>arg<span class="token punctuation">)</span><span class="token punctuation">{</span><span class="token function">printf</span><span class="token punctuation">(</span><span class="token string">"I am f2\n"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>condition <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">;</span><span class="token function">pthread_cond_signal</span><span class="token punctuation">(</span><span class="token operator">&amp;</span>cond<span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>但是这就有一个问题，就是 <code>condition</code> 作为共享变量，有可能出现“共同访问”的问题，比如先调度 <code>1</code> 时完成了对于 <code>condition == 0</code> 的检查，然后切换到了 <code>2</code>，并完成了 <code>signal</code>，然后再切换到 <code>1</code> 来执行 <code>wait</code>，那么就收不到信号了。那么此时就需要用锁来实现原子性，要保证对 <code>condition</code> 的访问和 <code>wait/signal</code> 是绑定在一起的，于是我们得到了第三版：</p><pre class="line-numbers language-c" data-language="c"><code class="language-c"><span class="token class-name">pthread_cond_t</span> cond<span class="token punctuation">;</span><span class="token class-name">pthread_mutex_t</span> mutex<span class="token punctuation">;</span><span class="token keyword">int</span> condition <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span><span class="token keyword">void</span> <span class="token operator">*</span><span class="token function">f1</span><span class="token punctuation">(</span><span class="token keyword">void</span> <span class="token operator">*</span>arg<span class="token punctuation">)</span><span class="token punctuation">{</span><span class="token function">pthread_mutex_lock</span><span class="token punctuation">(</span><span class="token operator">&amp;</span>mutex<span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token keyword">if</span> <span class="token punctuation">(</span>condition <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">)</span> <span class="token punctuation">{</span><span class="token function">pthread_cond_wait</span><span class="token punctuation">(</span><span class="token operator">&amp;</span>cond<span class="token punctuation">,</span> <span class="token operator">&amp;</span>mutex<span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token punctuation">}</span><span class="token function">pthread_mutex_unlock</span><span class="token punctuation">(</span><span class="token operator">&amp;</span>mutex<span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token function">printf</span><span class="token punctuation">(</span><span class="token string">"I am f1\n"</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token punctuation">}</span><span class="token keyword">void</span> <span class="token operator">*</span><span class="token function">f2</span><span class="token punctuation">(</span><span class="token keyword">void</span> <span class="token operator">*</span>arg<span class="token punctuation">)</span><span class="token punctuation">{</span><span class="token function">printf</span><span class="token punctuation">(</span><span class="token string">"I am f2\n"</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token function">pthread_mutex_lock</span><span class="token punctuation">(</span><span class="token operator">&amp;</span>mutex<span class="token punctuation">)</span><span class="token punctuation">;</span>condition <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">;</span><span class="token function">pthread_cond_signal</span><span class="token punctuation">(</span><span class="token operator">&amp;</span>cond<span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token function">pthread_mutex_unlock</span><span class="token punctuation">(</span><span class="token operator">&amp;</span>mutex<span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>由此可见即使在原本的实际中并不涉及共享内存（<code>1</code> 和 <code>2</code> 都只打印信息，并不访问共享内存），仅是处于同步的需求，条件变量也必须要和锁紧密配合。这就是在 POSIX 的条件变量的 API 中有锁的原因。</p><p>上述简单的例子已经结束了，但是条件变量依然还存在一个问题，也就是“虚假唤醒”。这个问题涉及到了条件变量的实现机制，线程在 <code>wait</code> 的时候，会将锁释放掉，当被其他线程 <code>signal</code> 的时候，它不是立刻执行，而是被放到了 OS 的待调度队列中，当调度到他的时候，他要再去拿锁然后执行，如果没有拿到锁，那么还会被重新插入到 OS 的待调度队列中等待（相当于隐式 <code>yield</code> 了）。</p><p>这种机制就存在一个问题了，就是在线程被 <code>signal</code> 唤醒后插入到待调度队列中，到真正拿到锁开始执行的这段时间内，有可能有其他线程修改了 <code>condition</code> 这样的条件，致使从语义上来说，线程应该继续 <code>wait</code>，而因为 <code>if</code> 的原因，使得线程逃离 <code>wait</code>，开始执行。所以我们最后要做的修改就是将 <code>if</code> 改成 <code>while</code>，如下所示：</p><pre class="line-numbers language-c" data-language="c"><code class="language-c"><span class="token keyword">void</span> <span class="token operator">*</span><span class="token function">f1</span><span class="token punctuation">(</span><span class="token keyword">void</span> <span class="token operator">*</span>arg<span class="token punctuation">)</span><span class="token punctuation">{</span><span class="token function">pthread_mutex_lock</span><span class="token punctuation">(</span><span class="token operator">&amp;</span>mutex<span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token keyword">while</span> <span class="token punctuation">(</span>condition <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">)</span> <span class="token punctuation">{</span><span class="token function">pthread_cond_wait</span><span class="token punctuation">(</span><span class="token operator">&amp;</span>cond<span class="token punctuation">,</span> <span class="token operator">&amp;</span>mutex<span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token punctuation">}</span><span class="token function">pthread_mutex_unlock</span><span class="token punctuation">(</span><span class="token operator">&amp;</span>mutex<span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token function">printf</span><span class="token punctuation">(</span><span class="token string">"I am f1\n"</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>从这个意义上来看，所谓的“signal 唤醒”，对于被唤醒的进程，并不能保证现在的唤醒符合“可执行”的条件了，而只是“可能可执行”，需要进一步的检查。</p><h3 id="3-2-信号量"><a href="#3-2-信号量" class="headerlink" title="3.2 信号量"></a>3.2 信号量</h3><p>不可否认，条件变量是丑陋的，他必须配合锁，而且还要搭配 <code>while</code> 才能使用。究其根本，是因为它具有“唤醒丢失”和“虚假唤醒”的问题。</p><p>“唤醒丢失”是因为条件变量本身不具有状态导致的，必须用一个共享变量来指导同步，如果我们将一个共享变量封装到其中呢？那我们是不是就不用显式的面对锁的问题了。而反正我们都将共享变量封装到其中了，与之相关的控制语句 <code>while</code> 也封装进去，也不是什么困难的事情了。于是我们就得到了信号量（Semaphore）。</p><p>信号量的本质是一个计数器 counter，它具有 <code>P</code> （<code>wait</code>）和 <code>V</code> （<code>post</code>）两种操作，<code>P</code> 会减少 counter 的值，如果 <code>counter == 0</code>，那么就会让发起 <code>P</code> 操作的线程进入“等待室”；<code>V</code> 会增加 counter 的值，如果 <code>counter &gt; 0</code>，那么就会唤醒等待室中的线程。</p><p>可以看到基本上信号量就是将原本的 <code>condition</code> 转换成了 <code>counter</code> 并封装进了自身内部。其实现如下：</p><pre class="line-numbers language-c" data-language="c"><code class="language-c"><span class="token function">sem_wait</span><span class="token punctuation">(</span>s<span class="token punctuation">)</span> <span class="token punctuation">{</span>        <span class="token keyword">while</span><span class="token punctuation">(</span><span class="token function">CompareAndSwap</span><span class="token punctuation">(</span>s<span class="token punctuation">.</span>flag<span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">==</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        s<span class="token punctuation">.</span>count<span class="token operator">--</span><span class="token punctuation">;</span>        <span class="token keyword">if</span><span class="token punctuation">(</span>s<span class="token punctuation">.</span>count <span class="token operator">&lt;</span> <span class="token number">0</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>                <span class="token comment">/* 该线程进入 s.queue 队列 */</span>                <span class="token comment">/* 阻塞该线程（还需将 s.flag 设置为 0，阻塞和赋值需要是一个原子操作） */</span>        <span class="token punctuation">}</span>        s<span class="token punctuation">.</span>flag <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span><span class="token punctuation">}</span><span class="token function">sem_post</span><span class="token punctuation">(</span>s<span class="token punctuation">)</span> <span class="token punctuation">{</span>        <span class="token keyword">while</span><span class="token punctuation">(</span><span class="token function">CompareAndSwap</span><span class="token punctuation">(</span>s<span class="token punctuation">.</span>flag<span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">==</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        s<span class="token punctuation">.</span>count<span class="token operator">++</span><span class="token punctuation">;</span>        <span class="token keyword">if</span><span class="token punctuation">(</span>s<span class="token punctuation">.</span>count <span class="token operator">&lt;=</span> <span class="token number">0</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>                <span class="token comment">/* 从s.queue 队列中移出线程 p */</span>                <span class="token comment">/* 线程 p 进入就绪队列 */</span>        <span class="token punctuation">}</span>        s<span class="token punctuation">.</span>flag <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>信号量是 System V 提出的机制，它足够强大，以至于仅凭这一个机制，就可以实现互斥和同步两种原语。</p><p>当信号量初始值为 <code>1</code> 的时候，他可以用作互斥，如下所示：</p><pre class="line-numbers language-c" data-language="c"><code class="language-c"><span class="token class-name">sem_t</span> m<span class="token punctuation">;</span><span class="token function">sem_init</span><span class="token punctuation">(</span><span class="token operator">&amp;</span>m<span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token function">sem_wait</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment">// 临界区</span><span class="token function">sem_post</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>而当信号量初始值为 <code>0</code> 时，可以用于同步，这是因为此时就必须先 <code>post</code> 后 <code>wait</code> 才可以避免阻塞：</p><pre class="line-numbers language-c" data-language="c"><code class="language-c"><span class="token keyword">void</span> <span class="token operator">*</span><span class="token function">f1</span><span class="token punctuation">(</span><span class="token keyword">void</span> <span class="token operator">*</span>arg<span class="token punctuation">)</span><span class="token punctuation">{</span><span class="token function">sem_wait</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token function">printf</span><span class="token punctuation">(</span><span class="token string">"I am f1\n"</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token punctuation">}</span><span class="token keyword">void</span> <span class="token operator">*</span><span class="token function">f2</span><span class="token punctuation">(</span><span class="token keyword">void</span> <span class="token operator">*</span>arg<span class="token punctuation">)</span><span class="token punctuation">{</span><span class="token function">printf</span><span class="token punctuation">(</span><span class="token string">"I am f2\n"</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token function">sem_post</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>可以看到信号量非常简洁美妙。</p><hr><h2 id="四、生产者消费者模型"><a href="#四、生产者消费者模型" class="headerlink" title="四、生产者消费者模型"></a>四、生产者消费者模型</h2><p>生产者消费者模型是非常经典的并行原语的应用。其中因为生产者和消费者会同时访问同一片共享区域，需要使用互斥机制；又因为当消费品为零或者满的时候，需要使消费者或者生产者 <code>wait</code> ，当条件满足时，又需要 <code>signal</code> 生产者和消费者，所以需要同步机制。</p><p>并不是所有的共享同一片内存，具有读写两方的模型都被叫作生产者消费者模型，生产者和消费者之间必须有同步机制来提高效率，这样才能叫作生产者消费者机制。同步机制是非常重要的，考虑生产者的效率是消费者的十倍，那么生产者必然很快就会填满缓冲区，随后生产者会重复拿锁进入缓冲区，并不干任何事情就离开，而消费者不容易拿到锁，机会被大量挤占，导致消费能力进一步降低。而有了同步机制，当产品填满缓冲区时，生产者就可以 <code>wait</code> 等待消费者唤醒了，这样更加高效。</p><p>生产者消费者模型有“阻塞队列”和“循环队列”两种形式，分别对应条件变量和信号量实现。循环队列的方式更优，因为阻塞队列是用一把锁保护整个共享区域，而实际上只要不是同时对于同一个商品读写，那么其实共享区域是允许同时存在一个生产者和一个消费者的，循环队列配合信号量可以很容易解决这个问题。</p><p>更加具体的描述和实现，可以在<a href="https://cloud.tencent.com/developer/article/2352249">这里</a>找到。</p>]]></content>
    
    
    <summary type="html">&lt;h2 id=&quot;一、总论&quot;&gt;&lt;a href=&quot;#一、总论&quot; class=&quot;headerlink&quot; title=&quot;一、总论&quot;&gt;&lt;/a&gt;一、总论&lt;/h2&gt;&lt;p&gt;在并行编程中，除了“互斥”这个原语外（一般是采用“锁”来实现），还存在“同步（synchronous）”这个原语，这个原语指的是“各个事件按照特定顺序执行”的需求。比如说在生产者消费者模型中，必须要让生产者先生产，消费者才可以进行消费，这就是一种同步行为，是没有办法仅仅依靠锁来实现的。&lt;/p&gt;
&lt;p&gt;当涉及互斥时，涉及到的术语是 &lt;code&gt;lock, unlock, mutex&lt;/code&gt; ，而涉及到同步是术语是 &lt;code&gt;wait, signal, notify, barrier&lt;/code&gt; 等。之前我只重视了互斥的学习，而对于同步语义，则非常忽视。&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&quot;二、互斥&quot;&gt;&lt;a href=&quot;#二、互斥&quot; class=&quot;headerlink&quot; title=&quot;二、互斥&quot;&gt;&lt;/a&gt;二、互斥&lt;/h2&gt;</summary>
    
    
    
    <category term="并行计算" scheme="https://thysrael.github.io/categories/%E5%B9%B6%E8%A1%8C%E8%AE%A1%E7%AE%97/"/>
    
    
    <category term="直观理解" scheme="https://thysrael.github.io/tags/%E7%9B%B4%E8%A7%82%E7%90%86%E8%A7%A3/"/>
    
    <category term="S9课上" scheme="https://thysrael.github.io/tags/S9%E8%AF%BE%E4%B8%8A/"/>
    
    <category term="并行计算" scheme="https://thysrael.github.io/tags/%E5%B9%B6%E8%A1%8C%E8%AE%A1%E7%AE%97/"/>
    
  </entry>
  
  <entry>
    <title>海边拾贝-ExtMem</title>
    <link href="https://thysrael.github.io/posts/cbf91d56/"/>
    <id>https://thysrael.github.io/posts/cbf91d56/</id>
    <published>2024-08-26T12:31:23.000Z</published>
    <updated>2024-10-17T06:35:03.407Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>本文提出了一种用户态缺页异常处理框架，可以轻松适配不同的处理策略，适用于高并发环境。其亮点在于：</p><ul><li>框架的易用性：<ul><li>基于 Linux 的 Semi-Microkernel 设计</li><li>透明</li></ul></li><li>性能：<ul><li>采用了微内核和外核思想中的 upcall 设计</li><li>采用了先进的异步批处理 IO 后端 io_ring</li></ul></li></ul></blockquote><h2 id="一、背景"><a href="#一、背景" class="headerlink" title="一、背景"></a>一、背景</h2><h3 id="1-1-特化内存管理"><a href="#1-1-特化内存管理" class="headerlink" title="1.1 特化内存管理"></a>1.1 特化内存管理</h3><p>从软件层去看，目前内存密集型应用越来越多，如 TB 级的机器学习、大型图计算，内存数据库等。从硬件层去看，硬件新特性有很多，比如分离式内存、分层内存等。这些新的变化都对内存管理策略提出了新的挑战。</p><p>通用操作系统的内存管理策略并不适用于内存密集型应用，也不能针对性的利用硬件新特性。有研究表明最大的系统瓶颈是内存管理而不是设备带宽。</p><p>特化的内存管理策略（offload，prefetch，swap policy…）可以大大缓解这一现象。但是<strong>特化策略的普适性并不好</strong>。</p><h3 id="1-2-内核态内存管理"><a href="#1-2-内核态内存管理" class="headerlink" title="1.2 内核态内存管理"></a>1.2 内核态内存管理</h3><p>因为 Linux 内存管理模块十分基础、关键和复杂，所以在内核中开发、测试和部署一个新的内存管理策略开销非常大。大约 20 行代码即可描述的算法需要修改 20 个文件；测试开发需要 17 个月（和前面的不是同一个例子）；即使做出了，也很难被内核社区所接纳。</p><h3 id="1-3-用户内存管理框架"><a href="#1-3-用户内存管理框架" class="headerlink" title="1.3 用户内存管理框架"></a>1.3 用户内存管理框架</h3><p>“特化内存管理策略的有效性、不普适性和内核态内存策略的高昂开销”都在呼唤一个用户态的内存管理框架，也就是可以为多种内存管理策略提供支持的基础设施。</p><p>Linux 提供了 userfaultfd 机制来作为管理框架，用户基于此来实现用户态内存管理策略。框架的实现可以看作在进程中存在一个 manager thread，当一个 thread 发生 page fault 的时候，会通过基于 fd 的 IPC 方式（类似管道）给 manager thread 发信息报告自己缺失的地址等信息，manager thread 会根据相关信息进行处理。</p><p>本文认为这种方式并不适合高并发环境，采用 upcall 的方式和 ExoKernel 的理念去实现框架。</p><hr><h2 id="二、设计"><a href="#二、设计" class="headerlink" title="二、设计"></a>二、设计</h2><h3 id="2-1-upcall"><a href="#2-1-upcall" class="headerlink" title="2.1 upcall"></a>2.1 upcall</h3><p>Upcall 指的是从内核调用用户函数，可以看作是一种反向 syscall，常见于微内核系统，比如 chcore 中的 thread migration 机制。</p><p>传统的 userfaultfd 在高并发环境下存在延迟问题，这主要是由两方面原因组成：</p><p>一方面，线程的调度和切换开销很大，userfaultfd 下的 fault thread 和 MM thread 之间可能会插入多个其他无关线程（灰色虚线部分）：</p><p><img src="/posts/cbf91d56/userfaultsd.drawio.png" alt="userfaultsd.drawio"></p><p>而 upcall 可以由内核指定 MM thread 运行，并不需要调度：</p><p><img src="/posts/cbf91d56/extmem.drawio.png" alt="extmem.drawio"></p><p>另一方面，userfaultfd 的 MM thread 会串行处理 page fault，当多个线程都发生 page fault 的时候，会有排队现象：</p><p><img src="/posts/cbf91d56/userfaultfd1.drawio.png" alt="userfaultfd1.drawio"></p><p>但是利用 upcall 可以构造出 self-paging 机制，即 page fault handler 的本质是一个每个进程都有的库函数，发生 page fault 后内核会 upcall 进程自己的 handler 函数，这样多个 page fault handle 就可以并行了：</p><p><img src="/posts/cbf91d56/extmem2.drawio.png" alt="extmem2.drawio"></p><h3 id="2-2-io-uring"><a href="#2-2-io-uring" class="headerlink" title="2.2 io_uring"></a>2.2 io_uring</h3><p>内存管理可以分成前后端：前端负责处理 page fault 请求，分配页面完成映射；后端负责设备 I/O。</p><p>ExtMem 对于后端只要求 Direct I/O（也就是绕过 Linux 系统的 page cache），并没有对后端的同步和异步做出限制，ExtMem 自己使用了最为先进的 io_uring 机制。</p><p>之所以要强调这一点，是因为在后面的测试中，采用相同策略的 Linux 内核和 ExtMem 相对比，ExtMem 更占优势，它给出的解释是 ExtMem 在 evict 的代码更少，但是我觉得可能 io_uring 也发挥了一定的作用。</p><p>总得来说，io_uring 是 Linux 提供的一个先进的，异步的，非常适合批处理的 IO 接口：</p><p><img src="/posts/cbf91d56/io_uring.png" alt="img"></p><p>Linux 内部的 IO 使用的是中断驱动模式（应该是，不保真），而 io_uring 可以使用轮询模式。在高性能设备上，IO 的开销是小于上下文切换的开销的，所以轮询模式更优。</p><p><img src="/posts/cbf91d56/benchmark-1-1724747043453-9.png" alt="img"></p><hr><h2 id="三、实现"><a href="#三、实现" class="headerlink" title="三、实现"></a>三、实现</h2><h3 id="3-1-三层设计"><a href="#3-1-三层设计" class="headerlink" title="3.1 三层设计"></a>3.1 三层设计</h3><p>在设计上，该框架分为 3 层：</p><ul><li>core：和内核交互，实现监视虚拟地址，完成映射，IO 等基础功能</li><li>observability：提供对内存“冷热”等属性的信息</li><li>policy：提供实现具体策略所需要的 API。</li></ul><h3 id="3-2-链接与拦截"><a href="#3-2-链接与拦截" class="headerlink" title="3.2 链接与拦截"></a>3.2 链接与拦截</h3><p>为了用户的透明性（只 <code>mmap()</code> 等内存管理函数不需要修改），ExtMem 通过改变链接器的 <code>LD_PRELOAD</code> 变量实现了对于原有库函数的覆盖，通过使用 Intel libsyscall_intercept 技术实现了对于系统调用的覆盖。</p><h3 id="3-3-改写-UserFaultFD，SIGBUS"><a href="#3-3-改写-UserFaultFD，SIGBUS" class="headerlink" title="3.3 改写 UserFaultFD，SIGBUS"></a>3.3 改写 UserFaultFD，SIGBUS</h3><p>upcall 并不是 Linux 的原生机制，所以需要修改 Linux 内核支持 upcall：</p><p>一方面，ExtMem 复用了 Linux 信号机制中的 SIGBUS 信号，因为信号机制可以看作内核调用用户 handler，和 upcall 的语义近似。但是信号对于 handler 可重入性和线程安全的要求较高，为了功能的正常高效运行，ExtMem 削弱了一些原本的约束。</p><p>一方面，ExtMem 修改了 userfaultfd，使其不再通过基于 fd  的 IPC 通信，而是通过信号通信。</p><hr><h2 id="四、评估"><a href="#四、评估" class="headerlink" title="四、评估"></a>四、评估</h2><h3 id="4-1-评估环境"><a href="#4-1-评估环境" class="headerlink" title="4.1 评估环境"></a>4.1 评估环境</h3><p>如表所示：</p><div class="table-container"><table><thead><tr><th>条目</th><th>数据</th></tr></thead><tbody><tr><td>CPU</td><td>2.30GHz 的 Intel Xeon 5218 处理器</td></tr><tr><td>核心</td><td>16 个核心，每个核心 32 个硬件线程</td></tr><tr><td>内存</td><td>198GB 的 DDR4 内存</td></tr><tr><td>外存</td><td>读取速率为 2700 MB/s 的 NVMe SSD</td></tr><tr><td>操作系统</td><td>Linux 5.15</td></tr></tbody></table></div><h3 id="4-2-单次延迟"><a href="#4-2-单次延迟" class="headerlink" title="4.2 单次延迟"></a>4.2 单次延迟</h3><p>处理单个 page fault 的延迟如下：</p><p><img src="/posts/cbf91d56/image-20240827164626572.png" alt="image-20240827164626572"></p><p>其中 Upcall 指的是进行过性能优化的 SIGBUS 方法。</p><p>可以看到 UFFD 的方式在高并发环境下表现不良。而 ExtMem 则更好。</p><h3 id="4-3-相同策略吞吐"><a href="#4-3-相同策略吞吐" class="headerlink" title="4.3 相同策略吞吐"></a>4.3 相同策略吞吐</h3><p>他们在 ExtMem 上实现了和 Linux 相同的 2Q-LRU 逐出策略并进行测试。</p><p>使用 <code>mmap</code>  microbenchmark 去测试吞吐量，将 RAM 限制到 8G 来触发 page fault。</p><p>它测试了随机访存和顺序访存两种 pattern 下的吞吐</p><p><img src="/posts/cbf91d56/image-20240827165459110.png" alt="image-20240827165459110"></p><p>可以看到 ExtMem 都是优于 Linux，它论文中解释原因为 evict 的代码更简洁：</p><blockquote><p>The EXTMEM implementation evicts pages more quickly than Linux does, because its eviction code path is simpler, thereby explaining its performance advantage</p></blockquote><h3 id="4-4-预取"><a href="#4-4-预取" class="headerlink" title="4.4 预取"></a>4.4 预取</h3><p>在使用了预取策略后，我们评估 ExtMem 保留工作集的能力：</p><p><img src="/posts/cbf91d56/image-20240827170114740.png" alt="image-20240827170114740"></p><h3 id="4-5-CSR"><a href="#4-5-CSR" class="headerlink" title="4.5 CSR"></a>4.5 CSR</h3><p>压缩稀疏行（Compressed Sparse Row，CSR）是一种广泛用于内存图分析的数据结构。为使用 CSR 的应用开发一种新的内存管理策略：”将关键数据尽可能保存在内存中，并且利用一个滑动窗口的思想来指导数据的读入和逐出“，被称为 ”PR“。</p><p>运行 Twitter dataset using GAP benchmark suite 效果对比如下：</p><p><img src="/posts/cbf91d56/image-20240827170458158.png" alt="image-20240827170458158"></p><hr><h2 id="五、总结"><a href="#五、总结" class="headerlink" title="五、总结"></a>五、总结</h2><p>本文设计了一个用户态的内存管理策略框架，采用 upcall 机制来优化其在高并发环境下的表现，并且使用了一些工程技术来使得这个框架的易用性很好。</p>]]></content>
    
    
    <summary type="html">&lt;blockquote&gt;
&lt;p&gt;本文提出了一种用户态缺页异常处理框架，可以轻松适配不同的处理策略，适用于高并发环境。其亮点在于：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;框架的易用性：&lt;ul&gt;
&lt;li&gt;基于 Linux 的 Semi-Microkernel 设计&lt;/li&gt;
&lt;li&gt;透明&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;性能：&lt;ul&gt;
&lt;li&gt;采用了微内核和外核思想中的 upcall 设计&lt;/li&gt;
&lt;li&gt;采用了先进的异步批处理 IO 后端 io_ring&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;
&lt;h2 id=&quot;一、背景&quot;&gt;&lt;a href=&quot;#一、背景&quot; class=&quot;headerlink&quot; title=&quot;一、背景&quot;&gt;&lt;/a&gt;一、背景&lt;/h2&gt;&lt;h3 id=&quot;1-1-特化内存管理&quot;&gt;&lt;a href=&quot;#1-1-特化内存管理&quot; class=&quot;headerlink&quot; title=&quot;1.1 特化内存管理&quot;&gt;&lt;/a&gt;1.1 特化内存管理&lt;/h3&gt;&lt;p&gt;从软件层去看，目前内存密集型应用越来越多，如 TB 级的机器学习、大型图计算，内存数据库等。从硬件层去看，硬件新特性有很多，比如分离式内存、分层内存等。这些新的变化都对内存管理策略提出了新的挑战。&lt;/p&gt;
&lt;p&gt;通用操作系统的内存管理策略并不适用于内存密集型应用，也不能针对性的利用硬件新特性。有研究表明最大的系统瓶颈是内存管理而不是设备带宽。&lt;/p&gt;</summary>
    
    
    
    <category term="海边拾贝" scheme="https://thysrael.github.io/categories/%E6%B5%B7%E8%BE%B9%E6%8B%BE%E8%B4%9D/"/>
    
    
    <category term="知识总结" scheme="https://thysrael.github.io/tags/%E7%9F%A5%E8%AF%86%E6%80%BB%E7%BB%93/"/>
    
    <category term="S8假期" scheme="https://thysrael.github.io/tags/S8%E5%81%87%E6%9C%9F/"/>
    
    <category term="海边拾贝" scheme="https://thysrael.github.io/tags/%E6%B5%B7%E8%BE%B9%E6%8B%BE%E8%B4%9D/"/>
    
  </entry>
  
  <entry>
    <title>面向对象-设计模式</title>
    <link href="https://thysrael.github.io/posts/94e7864c/"/>
    <id>https://thysrael.github.io/posts/94e7864c/</id>
    <published>2024-08-22T06:29:00.000Z</published>
    <updated>2024-10-17T06:35:03.683Z</updated>
    
    <content type="html"><![CDATA[<h2 id="一、总论"><a href="#一、总论" class="headerlink" title="一、总论"></a>一、总论</h2><p>设计模式是一个工程问题，它不能为某个问题提供具体的答案，它只能让答案写得好看一些。</p><p>更进一步地说，设计模式是用于解决代码复杂度高（不是算法复杂度）的问题，这会引发难以阅读，难以维护等伴生问题。当代码量小，复杂度低，没有什么维护需求的时候（比如说科研代码），其实是没有必要采用规范的设计模式的。</p><p>我个人学习设计模式，并不是为了写代码（因为我写的代码就是科研代码），而是为了更好的阅读代码，因为大型工程代码都会或多或少遵循设计模式的思路。</p><p>很多设计模式解决的复杂度问题，是客观存在的，认识这些问题有助于设计出更加简洁健壮的架构；但是有些问题可能只是类似 Java 等语言表述能力不够所导致的，不用太较真。</p><hr><h2 id="二、设计原则"><a href="#二、设计原则" class="headerlink" title="二、设计原则"></a>二、设计原则</h2><p>设计原则的目的同样是降低代码的复杂度。它可以看作是设计模式的“基本原理”，每个设计模式都或多或少贯彻了这些原则。</p><p>我们会介绍一些这些原则的具体内容，并简单描述一下这些原则是如何发挥作用的。总的来说，它们都是在描述“一个好的抽象”或者说“一个好的接口”，应该具有哪些性质（简洁、稳定、精妙、短小）。</p><h3 id="2-1-单一职责原则"><a href="#2-1-单一职责原则" class="headerlink" title="2.1 单一职责原则"></a>2.1 单一职责原则</h3><p>单一职责原则（Single Responsibility Principle）指的是每一个类仅负责一项职责，当然如果更普适一些的表述，是每一个代码模块（OOP 中的类，某个函数，某个库）只负责一项职责。</p><p>这是因为当代码模块以“功能”为单位划分的时候，就符合了“高内聚，低耦合”的思想，每个模块其实以一个抽象职责的实现。代码开发者通过付出“冥思苦想提炼抽象”的代价，获得了“模块化”的优势。</p><p>当我们说“六大原则”的时候，其实是将单一职责原则剔除的，是因为这个原则在语义表述上，一点也不“单一职责”，它的思想</p><h3 id="2-2-开闭原则"><a href="#2-2-开闭原则" class="headerlink" title="2.2 开闭原则"></a>2.2 开闭原则</h3><p>开闭原则（Open Close Principle）指的是代码需要保证对于拓展开发，而对于修改关闭。说白了，就是只能增加功能，不能删除和修改功能。</p><p>代码开发者通过付出“维护一个可能更大且更冗余的代码量”的代价，获得了“向后兼容性”的优势。如何尽量规避这种代价呢？那就需要在设计之初，就尽可能避免设计出一些稳定性不强、可发展性不强的接口，避免日后为了维持这个接口而付出过大的代价。</p><h3 id="2-3-里氏代换原则"><a href="#2-3-里氏代换原则" class="headerlink" title="2.3 里氏代换原则"></a>2.3 里氏代换原则</h3><p>里氏代换原则（Liskov Substitution Principle, LSP）指的是任何基类可以出现的地方，子类一定可以出现。也就是说，基类和子类是“接口-实现”的关系。</p><p>里氏规则明确了接口和实现的分离关系，这样无论实现怎么变化（多种接口），接口都可以保持稳定。</p><p>里氏规则要求写出来的代码遵循这样的一种原则“如果鸟（基类）是会飞的，鸵鸟是一种鸟，那么鸵鸟就应该会飞”。而不幸的是，鸵鸟真的不会飞。所以基类（其实就是接口）的实际人员，就要避免给接口设计出像“飞”这样的非普适功能，或者避免将“鸵鸟”加入“鸟类”。</p><h3 id="2-4-依赖倒置原则"><a href="#2-4-依赖倒置原则" class="headerlink" title="2.4 依赖倒置原则"></a>2.4 依赖倒置原则</h3><p>所谓的依赖倒置，就是一个代码模块，是它的接口决定了它如何实现，而不是它的实现决定了它的接口。实现依赖接口，而非反过来。</p><p>这是因为实现细节具有多变性，而接口需要相对稳定。</p><h3 id="2-5-接口隔离原则"><a href="#2-5-接口隔离原则" class="headerlink" title="2.5 接口隔离原则"></a>2.5 接口隔离原则</h3><p>接口隔离原则（Interface Segregation Principle）指的是接口之间的功能都要彼此隔离而不是耦合在一起（其实也是单一职责原则的一种体现）。这是因为耦合对于维护是不利的，耦合会让依赖增多。</p><h3 id="2-6-最小知道原则"><a href="#2-6-最小知道原则" class="headerlink" title="2.6 最小知道原则"></a>2.6 最小知道原则</h3><p>最小知道原则（Demeter Principle）指的是一个接口应该与尽量少的其他接口发生相互作用。也是减少依赖的方式。</p><h3 id="2-7-合成复用原则"><a href="#2-7-合成复用原则" class="headerlink" title="2.7 合成复用原则"></a>2.7 合成复用原则</h3><p>合成复用原则（Composite Reuse Principle）指的是要尽量使用组合的方式来拓展功能，而不是采用继承的方式拓展功能。因为继承方式在某种意义上，是将基类形成了一种接口，而有些基类并没有经过良好的设计（它实现的时候是别人的子类），这种继承会引入性质不优良的接口。</p><p>而组合只是拓展了功能，并没有引入新的抽象。</p><hr><h2 id="三、设计模式"><a href="#三、设计模式" class="headerlink" title="三、设计模式"></a>三、设计模式</h2><p>正如前所述，设计模式是针对特定场景来优化代码复杂度的方案，也就是哪里复杂了，哪里才需要设计模式。设计模式可以分成“创建型，结构型，行为型”三类，分别对应一个模块在创建时、静态结构上、动态运行逻辑上产生复杂度时的应对方案。</p><h3 id="3-1-创建型模式"><a href="#3-1-创建型模式" class="headerlink" title="3.1 创建型模式"></a>3.1 创建型模式</h3><h4 id="3-1-1-工厂方法"><a href="#3-1-1-工厂方法" class="headerlink" title="3.1.1 工厂方法"></a>3.1.1 工厂方法</h4><p>工厂方法解决的问题是，对于一个普通的对象创建，我们一般直接调用构造器方法，而这种方式有时的表达能力是不够强的。</p><p>比如说对于很多常量，我们并不需要每次都创建一个新的对象，我们可以共享对象，反正没人可以修改这些共享对象。但是只要一调用构造器，那么就会产生一个新的对象。再比如，我们希望采用批处理的形式构造对象，那么使用构造器就没有办法做到。</p><p>为了实现这些更多的语义，一个比较自然的想法就是在创建对象的上下文中加上一些代码，但是因为对象的创建可能弥散在各个地方，这些代码也会被复制很多份，就很复杂。所以更好的方法就是定义一个“工厂方法”，将这些语义集成进去，就更好维护了。</p><p>我觉得工厂方法是唯一值得介绍的创建型方法，因为只有它在将复杂的构造代码提炼出一个新的抽象。其他模式都可以看作是在工厂方法上做出的改进。</p><h4 id="3-1-2-抽象工厂"><a href="#3-1-2-抽象工厂" class="headerlink" title="3.1.2 抽象工厂"></a>3.1.2 抽象工厂</h4><p>也就是存在多个工厂，这些工厂有一个共同的父类“抽象工厂”，这样我们就可以用不同的工厂（相当于具体的实现）来实现不同的构造策略。</p><h4 id="3-1-3-生成器"><a href="#3-1-3-生成器" class="headerlink" title="3.1.3 生成器"></a>3.1.3 生成器</h4><p>它指的是将构造过程拆分成多个步骤，每个步骤使用一个工厂方法。这种方法的好处除了可以让代码模块更加小以外，也更加灵活了。我们可以通过组合不同的工厂，来满足比较复杂的构造需求。</p><p>比如说对于“两轮车，三轮车，四轮车”的生产，我们可以简单的构造“两轮车工厂，三轮车工厂，四轮车工厂”。当然我们也可以只维护“车壳工厂”和“车轮工厂”两个工厂来满足这种复杂的构造需求。</p><p>生成器本质是对于构造功能的解耦和自由组合。</p><h4 id="3-1-4-原型"><a href="#3-1-4-原型" class="headerlink" title="3.1.4 原型"></a>3.1.4 原型</h4><p>当我们存在复制一个对象的需求的时候，其实是有两种思路的，方案 1 ：</p><pre class="line-numbers language-cpp" data-language="cpp"><code class="language-cpp"><span class="token keyword">class</span> <span class="token class-name">A</span> <span class="token punctuation">{</span>    <span class="token keyword">int</span> x<span class="token punctuation">;</span>    <span class="token keyword">int</span> y<span class="token punctuation">;</span><span class="token punctuation">}</span><span class="token punctuation">;</span>A a<span class="token punctuation">,</span> b<span class="token punctuation">;</span><span class="token comment">// copy a to b</span>b<span class="token punctuation">.</span>x <span class="token operator">=</span> a<span class="token punctuation">.</span>x<span class="token punctuation">;</span>b<span class="token punctuation">.</span>y <span class="token operator">=</span> a<span class="token punctuation">.</span>y<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>这种方案是有复制需求的一方在完成复制过程。</p><p>方案 2 :</p><pre class="line-numbers language-cpp" data-language="cpp"><code class="language-cpp"><span class="token keyword">class</span> <span class="token class-name">A</span> <span class="token punctuation">{</span>    <span class="token keyword">int</span> x<span class="token punctuation">;</span>    <span class="token keyword">int</span> y<span class="token punctuation">;</span>    <span class="token keyword">class</span> <span class="token class-name">A</span> <span class="token function">clone</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>        A b<span class="token punctuation">;</span>        b<span class="token punctuation">.</span>x <span class="token operator">=</span> <span class="token keyword">this</span><span class="token operator">-&gt;</span>x<span class="token punctuation">;</span>        b<span class="token punctuation">.</span>y <span class="token operator">=</span> <span class="token keyword">this</span><span class="token operator">-&gt;</span>y<span class="token punctuation">;</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span><span class="token punctuation">;</span>A a<span class="token punctuation">;</span>A b <span class="token operator">=</span> a<span class="token punctuation">.</span><span class="token function">clone</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>这种方案是有复制需求的一方只是调用 <code>clone</code> 方法，具体的方式是交给原型来做的。</p><p>当这种复制操作比较多的时候，显然第二种方式就比较好了；此外，当被复制的一方有私有数据时，也是第二种方式比较好。</p><h4 id="3-1-5-单例"><a href="#3-1-5-单例" class="headerlink" title="3.1.5 单例"></a>3.1.5 单例</h4><p>就是全局只有一个对象的情况，其实是和 Java 具体的语法联系比较紧密了，没有什么设计上的借鉴价值。</p><h3 id="3-2-结构型模式"><a href="#3-2-结构型模式" class="headerlink" title="3.2 结构型模式"></a>3.2 结构型模式</h3><h4 id="3-2-1-适配器"><a href="#3-2-1-适配器" class="headerlink" title="3.2.1 适配器"></a>3.2.1 适配器</h4><p>适配器模式是 Adapter，也称 Wrapper，是指如果一个接口需要 B 接口，但是待传入的对象却是 A 接口，怎么办？</p><p>那么就在 A 外面套一层满足 B 接口的适配器就可以了。</p><h4 id="3-2-2-桥接"><a href="#3-2-2-桥接" class="headerlink" title="3.2.2 桥接"></a>3.2.2 桥接</h4><p>其实这个模式很简单，它就是我们理解的“组合”，也就是每个部分只负责一些小的互相独立的功能，利用多个独立功能来组合完成复杂功能。</p><p>但是我很喜欢 Bridge 的概念，桥似乎在计算机术语中，描述的就是一种将多个功能模块组合在一起的概念，比如说芯片中的南桥和北桥芯片，网络中的桥接模式。</p><p><img src="/posts/94e7864c/bridge.png" alt="桥接设计模式"></p><p>它更像是一种“中间人”或者“平台”的概念，与汉语中的“连接和沟通两地”的概念有些出入。</p><h4 id="3-2-3-组合"><a href="#3-2-3-组合" class="headerlink" title="3.2.3 组合"></a>3.2.3 组合</h4><p>这里说的组合并不是和“继承”有对立关系的那个“组合”，而是一种树形结构，并且采用了递归处理：</p><pre class="line-numbers language-java" data-language="java"><code class="language-java"><span class="token keyword">public</span> <span class="token keyword">interface</span> <span class="token class-name">Node</span> <span class="token punctuation">{</span>    <span class="token keyword">private</span> <span class="token class-name">String</span> name<span class="token punctuation">;</span>    <span class="token keyword">private</span> <span class="token class-name">List</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">Node</span><span class="token punctuation">&gt;</span></span> list <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">ArrayList</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token punctuation">&gt;</span></span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token keyword">public</span> <span class="token class-name">String</span> <span class="token function">toXml</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>        <span class="token class-name">String</span> start <span class="token operator">=</span> <span class="token string">"&lt;"</span> <span class="token operator">+</span> name <span class="token operator">+</span> <span class="token string">"&gt;\n"</span><span class="token punctuation">;</span>        <span class="token class-name">String</span> end <span class="token operator">=</span> <span class="token string">"&lt;/"</span> <span class="token operator">+</span> name <span class="token operator">+</span> <span class="token string">"&gt;\n"</span><span class="token punctuation">;</span>        <span class="token class-name">StringJoiner</span> sj <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">StringJoiner</span><span class="token punctuation">(</span><span class="token string">""</span><span class="token punctuation">,</span> start<span class="token punctuation">,</span> end<span class="token punctuation">)</span><span class="token punctuation">;</span>        list<span class="token punctuation">.</span><span class="token function">forEach</span><span class="token punctuation">(</span>node <span class="token operator">-&gt;</span> <span class="token punctuation">{</span>            sj<span class="token punctuation">.</span><span class="token function">add</span><span class="token punctuation">(</span>node<span class="token punctuation">.</span><span class="token function">toXml</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token string">"\n"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token keyword">return</span> sj<span class="token punctuation">.</span><span class="token function">toString</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>总的来说就是树形结构的那些优点呗，局部的，递归的。</p><h4 id="3-2-4-装饰器"><a href="#3-2-4-装饰器" class="headerlink" title="3.2.4 装饰器"></a>3.2.4 装饰器</h4><p>装饰器（Decorator）模式，是一种在运行期动态给某个对象的实例增加功能的方法。</p><p>从实践角度来说，一些功能可能并不适合集成到类内部。比如说对某个类的“机械打印方法”，就是打印这个类的所有数据域（用于 debug）。这种方法显然不适合在类内部实现，不然每个类都要有这样的一个愚蠢的方法了。</p><p>所以我们可以将这个打印功能单独抽离出来，然后加到（装饰）所需要的类上，至于加的方法是基类、元编程还是什么其他手段，这就因实现而定了。</p><h4 id="3-2-5-外观"><a href="#3-2-5-外观" class="headerlink" title="3.2.5 外观"></a>3.2.5 外观</h4><p>外观模式，即 Facade ，它指的是：如果客户端要跟许多子系统打交道，那么客户端需要了解各个子系统的接口，比较麻烦。如果有一个统一的“中介”，让客户端只跟中介打交道，中介再去跟各个子系统打交道，对客户端来说就比较简单。</p><h4 id="3-2-6-享员"><a href="#3-2-6-享员" class="headerlink" title="3.2.6 享员"></a>3.2.6 享员</h4><p>享元（Flyweight）的核心思想很简单：如果一个对象实例一经创建就不可变，那么反复创建相同的实例就没有必要，直接向调用方返回一个共享的实例就行，这样即节省内存，又可以减少创建对象的过程，提高运行速度。</p><h4 id="3-2-7-代理"><a href="#3-2-7-代理" class="headerlink" title="3.2.7 代理"></a>3.2.7 代理</h4><p>代理模式，即 Proxy 。它和 Adapter 模式很类似，它们都是在原有类上在封装一层。</p><p>我个人觉得区别是，Adapter 是为了让功能可以正常使用，而 Proxy 视为了拓展功能的使用。比如说工厂方法就可以看作是构造方法的一种代理。</p><hr><h3 id="3-3-行为型模式"><a href="#3-3-行为型模式" class="headerlink" title="3.3 行为型模式"></a>3.3 行为型模式</h3><h4 id="3-3-1-责任链"><a href="#3-3-1-责任链" class="headerlink" title="3.3.1 责任链"></a>3.3.1 责任链</h4><p>行为型模式都是为了解决复杂的业务流而提出的。责任链的概念有些类似于流水线，每个人只负责处理一小部分业务逻辑。我个人感觉其实它更像是一堆筛网的集合，液体从中流过，滤出去了不同的东西。</p><p>这种模式下，增添一个筛网或者调整筛网的顺序，都是非常容易的，我甚至品出了流处理的精神。</p><h4 id="3-3-2-命令模式"><a href="#3-3-2-命令模式" class="headerlink" title="3.3.2 命令模式"></a>3.3.2 命令模式</h4><p>这说的是，对于每个操作，我们都让他们继承自一个叫做 <code>Command</code> 的基类，这样我们就可以对于这些操作进行统一的管理，比如我们可以 <code>undo, redo</code> 这些操作，至于我们为什么要对于这些操作进行统一的管理，可能这就是具体的情景要求了（比如一个编辑器中这种操作很常见）。</p><p>我个人觉得这种思想其实有些类似于“事务”或者“函数式”的思想了，将一段可执行代码当成一个类来操作。</p><h4 id="3-3-3-解释器"><a href="#3-3-3-解释器" class="headerlink" title="3.3.3 解释器"></a>3.3.3 解释器</h4><p>其实就是对于一些特定的问题，通用的编程语言会存在冗余繁复等问题，所以可以开发 DSL 来描述业务。解释器说的就是 DSL 的方法。</p><p>那么 DSL 的解释器的开发和维护难度呢？我觉得肯定是比不开发要难的，那我们为什么还需要 DSL 呢？我觉得是因为业务逻辑本身十分复杂且有规律，所以我们将原本的“业务逻辑复杂度”拆分成了“DSL 代码复杂度 + DSL 解释器复杂度”两个部分，或许这种拆分要比之前的复杂度要低。</p><h4 id="3-3-4-迭代器"><a href="#3-3-4-迭代器" class="headerlink" title="3.3.4 迭代器"></a>3.3.4 迭代器</h4><p>迭代器在 C++ Primer 中已经讨论滥了，它忽略了不同数据结构之间的差异，让我们可以以统一的方式遍历不同数据结构中的元素。也就是说，这是一种对于“迭代”这个操作的统一抽象。</p><h4 id="3-3-5-中介"><a href="#3-3-5-中介" class="headerlink" title="3.3.5 中介"></a>3.3.5 中介</h4><p>中介模式（Mediator）是通过引入一个中介对象，把多边关系变成多个双边关系，从而简化系统组件的交互耦合度。</p><p>说穿了，中介就是一个全局看板。</p><h4 id="3-3-6-备忘录"><a href="#3-3-6-备忘录" class="headerlink" title="3.3.6 备忘录"></a>3.3.6 备忘录</h4><p>备忘录模式（Memento），主要用于捕获一个对象的内部状态，以便在将来的某个时候恢复此状态。</p><p>我是觉得它和“原型”差不多。</p><h4 id="3-3-7-观察者"><a href="#3-3-7-观察者" class="headerlink" title="3.3.7 观察者"></a>3.3.7 观察者</h4><p>我觉得就是发布-订阅模式，是一种一对多的通知机制，使得双方无需关心对方，只关心通知本身。</p><h4 id="3-3-8-状态"><a href="#3-3-8-状态" class="headerlink" title="3.3.8 状态"></a>3.3.8 状态</h4><p>状态模式类似于状态机的理念，也就是根据状态产生不同的行为。</p><p>在具体的代码实现中，有一个 <code>State</code> 基类，它定义了一个 <code>process()</code> 纯虚方法，不同的状态继承这个基类并覆盖了 <code>process</code> 方法。</p><h4 id="3-3-9-策略"><a href="#3-3-9-策略" class="headerlink" title="3.3.9 策略"></a>3.3.9 策略</h4><p>策略模式：Strategy，是指，定义一组算法，并把其封装到一个对象中。然后在运行时，可以灵活的使用其中的一个算法。</p><h4 id="3-3-10-模板方法"><a href="#3-3-10-模板方法" class="headerlink" title="3.3.10 模板方法"></a>3.3.10 模板方法</h4><p>模板方法（Template Method）是一个比较简单的模式。它的主要思想是，定义一个操作的一系列步骤，对于某些暂时确定不下来的步骤，就留给子类去实现好了，这样不同的子类就可以定义出不同的步骤。</p><p>因此，模板方法的核心在于定义一个“骨架”。</p><h4 id="3-3-11-访问者"><a href="#3-3-11-访问者" class="headerlink" title="3.3.11 访问者"></a>3.3.11 访问者</h4><p>访问者模式（Visitor）是一种操作一组对象的操作，它的目的是不改变对象的定义，但允许新增不同的访问者，来定义新的操作。</p><p>有一说一非常复杂，我看懂了，但是我觉得没有什么特殊的。</p>]]></content>
    
    
    <summary type="html">&lt;h2 id=&quot;一、总论&quot;&gt;&lt;a href=&quot;#一、总论&quot; class=&quot;headerlink&quot; title=&quot;一、总论&quot;&gt;&lt;/a&gt;一、总论&lt;/h2&gt;&lt;p&gt;设计模式是一个工程问题，它不能为某个问题提供具体的答案，它只能让答案写得好看一些。&lt;/p&gt;
&lt;p&gt;更进一步地说，设计模式是用于解决代码复杂度高（不是算法复杂度）的问题，这会引发难以阅读，难以维护等伴生问题。当代码量小，复杂度低，没有什么维护需求的时候（比如说科研代码），其实是没有必要采用规范的设计模式的。&lt;/p&gt;
&lt;p&gt;我个人学习设计模式，并不是为了写代码（因为我写的代码就是科研代码），而是为了更好的阅读代码，因为大型工程代码都会或多或少遵循设计模式的思路。&lt;/p&gt;
&lt;p&gt;很多设计模式解决的复杂度问题，是客观存在的，认识这些问题有助于设计出更加简洁健壮的架构；但是有些问题可能只是类似 Java 等语言表述能力不够所导致的，不用太较真。&lt;/p&gt;</summary>
    
    
    
    <category term="面向对象" scheme="https://thysrael.github.io/categories/%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1/"/>
    
    
    <category term="直观理解" scheme="https://thysrael.github.io/tags/%E7%9B%B4%E8%A7%82%E7%90%86%E8%A7%A3/"/>
    
    <category term="面向对象" scheme="https://thysrael.github.io/tags/%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1/"/>
    
    <category term="S8 假期" scheme="https://thysrael.github.io/tags/S8-%E5%81%87%E6%9C%9F/"/>
    
  </entry>
  
  <entry>
    <title>计算机组成-乱序</title>
    <link href="https://thysrael.github.io/posts/af364ce6/"/>
    <id>https://thysrael.github.io/posts/af364ce6/</id>
    <published>2024-08-10T11:50:16.000Z</published>
    <updated>2024-10-17T06:35:03.567Z</updated>
    
    <content type="html"><![CDATA[<h2 id="一、总论"><a href="#一、总论" class="headerlink" title="一、总论"></a>一、总论</h2><p>乱序指的是指令并不按照顺序执行，所以这个概念比较接近软件编程中的“异步”概念（强调对于顺序时序的破坏）。而我之前似乎一直把它和“并行”挂钩（强调对于共享资源的争用）。这种认识倒也不算是错误，目前学了一圈下来，感觉其实和两个概念都有关系。</p><p>在顺序模型下，指令是一条条阻塞执行的，必须前一条指令执行完，才能执行后一条指令。那么如果前一条指令非常花时间，那么后一条指令就只能阻塞等待。这个问题是用流水线解决不了的。流水线中的指令也需要顺序执行。而乱序执行就打破了这种顺序执行的阻塞性，使得前序和后序指令可以并行执行。</p><hr><h2 id="二、冒险（hazard）"><a href="#二、冒险（hazard）" class="headerlink" title="二、冒险（hazard）"></a>二、冒险（hazard）</h2><p>我们希望 CPU 按照理想情况运行，那么什么是理想情况？对于单个处理器核心，当：</p><script type="math/tex; mode=display">指令执行速度 = 时钟频率 \times 流水线深度 \times 数据通路条目</script><p>时就是理想情况了。而在现实生活中，常常因为多种现实因素使得指令的执行速度减慢，这些现实因素被称为“冲突（hazard）”。具体有 3  种：</p><ul><li>结构冲突（structure）：指的是对于功能单元的竞争情况，比如两个指令都需要 ALU，而只有一个 ALU，那么这两条指令就只能串行。</li><li>分支冲突（branch）：指的是因为分支而导致的指令流中断，比如突然发现正在执行的指令属于不会被执行的分支，那么这些指令都需要撤销。</li><li>数据冲突（data）：指令需要的数据还没有被前一条指令计算出来，那么就会导致阻塞。</li></ul><p>CPU 种有很多功能单元（也可以看作计算资源），我们希望让他们都运转起来，不要闲置或者做无用功。但是每条指令并不会“同时”使用这些资源，比如对于一条指令的执行，只要取出指令后，就不需要再从 I-Cache 中读值了，当这条指令让 ALU 进行运算的时候，Fetch，Decode，Write Back 这些单元是闲置的。所以我们发明了流水线技术，将功能单元划分到不同的流水级，每个流水级都运行一条指令，这样就可以并行利用不同的资源。但是这样还不够，因为可能一个阶段里还有很多个功能单元，比如说 Execute Stage 里就有整数计算单元，浮点数计算单元，访存单元等，这些单元想要满载运转，就不能再采用流水线技术了，因为这些资源并不是每条指令都会用到，如果我们将 Execute Stage 拆分成 Calculate Stage 和 Memory Stage ，那么 Memory Stage 的资源就会在执行计算指令时被闲置，而 Calculate Stage 的资源则会在执行访存指令时被闲置，所以我们可以采用乱序的方式，让一个流水级中包含多条指令，比如 Execute Stage 就可以同时包含一条计算指令和一条访存指令，这样资源就可以得到更充分的利用。</p><p>总得来说，我们可以利用流水线技术和乱序技术对 CPU 内的资源进行不同维度的并行操作：</p><p><img src="/posts/af364ce6/cpu.png" alt="cpu"></p><p>从这个角度看，流水线深度并不是越深越好，因为被时序分割的资源，并不会在每条指令上得到充分利用，反而是乱序的方式，更能充分利用资源。</p><p>总得来说，我们对于明显有依赖关系的资源，会采用流水线的方式来并行，比如说取指单元和译码单元的流水线处理；而对于没有依赖关系的资源，我们会采用乱序的方式并行，比如访存单元和计算单元的乱序。更进一步辩证地看，在同一级流水线中，一定存在没有依赖关系的资源，那么就是可以乱序的；在</p><hr><h2 id="三、算法"><a href="#三、算法" class="headerlink" title="三、算法"></a>三、算法</h2><p>我觉得我自己之所以谈到更加高级的 CPU 特性，比如说乱序、分支预测谈虎色变，是因为我在心里认为在硬件上是没有办法实现过于复杂的算法的。但是这种观点是很不精确的，硬件和算法的复杂程度没有必然联系，不过确实在硬件上实现的算法会有一些硬件特征。</p><p>首先是在 CPU 中是没有内存的，所以也就没有地址。这里很容易产生一个误导，就是同样没有指针。这是不对的，算法需要的并不是一个具体的指针，它只需要一个“指向某个数据的变量”即可，所以没有指针，也可以用整型索引代替。这有点像算法竞赛在实现链表，树之类的数据结构的时候，都不会使用指针，而是提前开一个大数组，然后用索引来指向其中的元素的思想。</p><p>然后是在 CPU 中没有像高级语言的“无限”概念的，任何资源都是有数量限制的。不仅是资源的数量有限制，资源的规模也有限制，比如说一个整数寄存器，就是 32 位，如果希望表达一个更大的数，那么就没有办法了。不过这种限制其实很好解决，只需要阻塞 CPU 直到相关资源富裕就可以了，常见的问题有空闲物理寄存器数目不够，指令编号溢出，队列溢出等。</p><p>还有一种解决资源有限的方法，是将资源的状态都保存到内存中，不过这种方法在微体系结构中用得不多（时间开销太大），但是在编译器开发中很常见。</p><p>最后是 CPU 上的算法的局部性很强，而且是只有一遍的，我们只能看到 CPU 上运行的这几条指令，或者还有一些 buffer 指令，而且只能看见一次。这就导致很多全局算法我们是没有办法直观实现的，但是我们可以采用一种像“流”或者是“滑动窗口”的思想去从局部推断全局。</p><p>总得来说，CPU 的性质使得它在描述算法或者数据结构的时候，会呈现一种朴素的，有限的、狭隘的特征，但是基本上没有算法是用 CPU 无法表示的（复杂的森林和图都是可以的），所以当我们去看 CPU 上的特征时，应当从它笨拙的表达中，看出其背后的精妙算法。</p><hr><h2 id="四、假冒险"><a href="#四、假冒险" class="headerlink" title="四、假冒险"></a>四、假冒险</h2><p>这里讨论的真假冒险都是数据冒险的一种，其实就是对于数据依赖关系的讨论。出现数据冒险问题，是优于前序指令（一个装逼的说法，就是在汇编中位置靠前的指令）晚于后序指令提交造成。</p><p>所谓的真冒险，就是“写后读”（Read After Write，RAW），吐槽一句，可以发现在中文这个词是先写后读，而在英文中变成了下先 R 后 W，刚好是反过来的，后面我只用英文。至于为什么它是真冒险，是因为只有前序指令写入了这个数据，后序指令才能读入新的值。</p><pre class="line-numbers language-asm" data-language="asm"><code class="language-asm">write r0read r0 # commit first, error<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>与之相对的，有 WAR 和 WAW 两种假冒险。对于 WAR 而言，先序指令读，后序指令写，我们担心的是，后序指令先提交的情况，但是如果后序指令没有提交到原本的寄存器中呢，那么就不存在问题了，换句话说，如果有无限个寄存器（类似于无限个变量），那么谁还为了省一些寄存器，而去覆盖一个可能还会被读的寄存器。</p><pre class="line-numbers language-asm" data-language="asm"><code class="language-asm">read r0write r0 # commit first, error### good ###read r0write r1 # commit first, correct<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>至于如何让寄存器变成无限个，那其实就又很多种办法了，大不了阻塞 CPU 嘛。当然在实际应用中，我们会通过重命名的手段，在内存中维护一个从逻辑寄存器到实际寄存器的映射关系，来使得不会发生依赖现象，这就是寄存器重命名。</p><p>而寄存器重命名算法，在原理上和编译器的寄存器分配算法的需求是一样的，唯一的区别在于编译器的逻辑寄存器不够了，那么就会往栈上存，而 CPU 的物理寄存器不够了，就会阻塞 CPU。当然了，像图着色或者线性扫描这种方法是没法用到 CPU 上，CPU 一般就是维护一个空闲寄存器队列就够了。</p><hr><h2 id="五、计分板"><a href="#五、计分板" class="headerlink" title="五、计分板"></a>五、计分板</h2><blockquote><p>从任何意义上说，寄存器就是内存的一个过客。</p></blockquote><p>如果我们拨开 ISA 的复杂性的迷雾，就会发现 CPU 的核心在于“读入内存，计算，写入内存”的图灵机模式，其中的计算步骤，其实就是构建一个计算的 DAG 图（有向无环图），其结构如下：</p><p><img src="/posts/af364ce6/dag.drawio.png" alt="dag.drawio"></p><p>寄存器的作用就是存储这些 DAG 图的中间节点。这里面的 <code>(1), (2), (3)</code> 可能就分别对应某个寄存器。</p><p>所谓的计分板，就是描述这幅图的数据结构，他的每个条目就是图上的一个点</p><div class="table-container"><table><thead><tr><th>ID</th><th>ready</th><th>child</th></tr></thead><tbody><tr><td>(1)</td><td>false</td><td>a, b</td></tr><tr><td>(2)</td><td>false</td><td>(1), a</td></tr><tr><td>(3)</td><td>true</td><td>b, d</td></tr></tbody></table></div><p>那么为什么要保留这样的一个结构，因为这个结构非常方便查看是否允许并行并处理相关的数据依赖。</p><p>比如在计分板上，我们就知道 <code>(2)</code> 这条指令还没有办法进行计算，因为 <code>(1)</code> 还没有算完，但是 <code>(3)</code> 已经可以算了，也就是 <code>(1), (3)</code> 可以并行计算，而 <code>(2)</code> 不可以。我们还可以看出 <code>(1), (3)</code> 都依赖 <code>b</code> 这个节点。而且这里的 ID 可以理解成一种逻辑寄存器，我们可以将其分配给物理寄存器。</p><p>总之计分板就是这样的一个全局看板结构，基于 DAG 图的方式来协调乱序并行。</p>]]></content>
    
    
    <summary type="html">&lt;h2 id=&quot;一、总论&quot;&gt;&lt;a href=&quot;#一、总论&quot; class=&quot;headerlink&quot; title=&quot;一、总论&quot;&gt;&lt;/a&gt;一、总论&lt;/h2&gt;&lt;p&gt;乱序指的是指令并不按照顺序执行，所以这个概念比较接近软件编程中的“异步”概念（强调对于顺序时序的破坏）。而我之前似乎一直把它和“并行”挂钩（强调对于共享资源的争用）。这种认识倒也不算是错误，目前学了一圈下来，感觉其实和两个概念都有关系。&lt;/p&gt;
&lt;p&gt;在顺序模型下，指令是一条条阻塞执行的，必须前一条指令执行完，才能执行后一条指令。那么如果前一条指令非常花时间，那么后一条指令就只能阻塞等待。这个问题是用流水线解决不了的。流水线中的指令也需要顺序执行。而乱序执行就打破了这种顺序执行的阻塞性，使得前序和后序指令可以并行执行。&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&quot;二、冒险（hazard）&quot;&gt;&lt;a href=&quot;#二、冒险（hazard）&quot; class=&quot;headerlink&quot; title=&quot;二、冒险（hazard）&quot;&gt;&lt;/a&gt;二、冒险（hazard）&lt;/h2&gt;</summary>
    
    
    
    <category term="计算机组成" scheme="https://thysrael.github.io/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90/"/>
    
    
    <category term="直观理解" scheme="https://thysrael.github.io/tags/%E7%9B%B4%E8%A7%82%E7%90%86%E8%A7%A3/"/>
    
    <category term="S8假期" scheme="https://thysrael.github.io/tags/S8%E5%81%87%E6%9C%9F/"/>
    
    <category term="计算机组成" scheme="https://thysrael.github.io/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90/"/>
    
  </entry>
  
  <entry>
    <title>海边拾贝-VeriSMo</title>
    <link href="https://thysrael.github.io/posts/71c079c7/"/>
    <id>https://thysrael.github.io/posts/71c079c7/</id>
    <published>2024-07-29T01:25:40.000Z</published>
    <updated>2024-10-17T06:35:03.423Z</updated>
    
    <content type="html"><![CDATA[<p><img src="/posts/71c079c7/1600x900_1591431860952_2048x1152_logo.jpg" alt="A RaiPlay learning il Verismo e i suoi autori - RAI Ufficio Stampa"></p><p>VeriSMo 的可信基只包括硬件和它自己（VM），剔除了对于 Hypervisor 的信任。传统的 VM 的安全服务是由 Hypervisor 负责的，如果认为 Hypervisor 是不可信的，那么就不能由它来提供安全服务。AMD 提供了新的安全架构 SEV-SNP，它为在 VM 中独立实现安全服务提供了支持，VeriSMO 就利用了这个硬件特性。</p><p>除了利用新的硬件安全特性外，VeriSMo 在开发时完成了形式化验证来确保安全性。VeriSMo 的开发语言是 Rust，已经确保了部分的内存安全性（也就是 Rust Checker 承担了部分形式化验证的任务），距离完全的形式化验证还有两个挑战：</p><ol><li>因为 Hypervisor 不可信任，所以 Hypervisor 可以打断 VM 的执行并修改硬件状态，这种并行无法简单验证。</li><li>开发 VeriSMo 需要使用 Unsafe Rust，Rust Checker 无法验证这种情况。</li></ol><p>为了解决挑战 1，VeriSMo 将验证拆分成了 2 层，上层为机器模型层（Machine Model），用 model verify 专门约束 Hypervisor 的行为，下层为实现层（Implement），用于解决排除了 Hypervisor 干扰后的 VeriSMo 本身的验证问题。</p><p>为了解决挑战 2，VeriSMo 引入并拓展了 Verus 来对 Unsafe 的情况进行验证，Verus 是 Rust 的一个库，可以看作它强化了原本的 Checker 功能；</p><h2 id="一、技术背景"><a href="#一、技术背景" class="headerlink" title="一、技术背景"></a>一、技术背景</h2><p>这个项目使用了大量的第三方技术和理论（多到和我用技术背景水字数的毕设差不多比例了）。</p><h3 id="1-1-理论"><a href="#1-1-理论" class="headerlink" title="1.1 理论"></a>1.1 理论</h3><p>reference：</p><p><a href="https://blog.lucode.net/theory/PV-HoareLogic.html">程序验证技术——霍尔逻辑 - 撸代码 - LuCode.net</a></p><h4 id="1-1-1-验证逻辑"><a href="#1-1-1-验证逻辑" class="headerlink" title="1.1.1 验证逻辑"></a>1.1.1 验证逻辑</h4><p>在验证逻辑方面并没有“显式”使用，只需要明确它们都涉及了 Rust Borrower Checker 和 Verus 的基础理论。其中尤其是线性逻辑，是可以支持并行程序内部的验证的，所以 VeriSMo 作为一个并行程序，形式化验证并没有理论上的难度，只是在实现上存在难度。</p><h4 id="1-1-2-验证等级"><a href="#1-1-2-验证等级" class="headerlink" title="1.1.2 验证等级"></a>1.1.2 验证等级</h4><p>形式化验证有两个等级：模型（Model）级别和实现（Implement）级别。其中实现级别的验证就是直观的对于具体的代码的形式化验证。而模型级别的验证是验证抽象模型，而不是具体的代码实现。这些模型通常通过状态机、流程图或其他形式化描述来表示。</p><p>在本项目中，验证分为两层，其中对于机器层的验证，就是模型级的，对于 VeriSMo 本身的验证，是实现级的。</p><h3 id="1-2-硬件"><a href="#1-2-硬件" class="headerlink" title="1.2 硬件"></a>1.2 硬件</h3><p>reference：</p><p><a href="https://dl.acm.org/doi/fullHtml/10.1145/3623392">Hardware VM Isolation in the Cloud</a></p><p><a href="https://blog.csdn.net/qq_43543209/article/details/135652011">【TEE】【AMD SEV内存加密】 白皮书-CSDN博客</a></p><p>硬件特性有很多，其核心在于将原本由 Hypervisor 负责的安全功能全部提供给 VM 。</p><h4 id="1-2-1-加密内存"><a href="#1-2-1-加密内存" class="headerlink" title="1.2.1 加密内存"></a>1.2.1 加密内存</h4><p>SME（Secure Memory Encrypted）：写入内存时利用硬件生成的 VM-specific key 对数据加密，读取内存是对数据解密。VM 可以通过 PTE 中的 <code>C-bit</code> 对物理页进行选择性加密。</p><p><img src="/posts/71c079c7/pic1.PNG" alt="pic1"></p><p>SEV-SNP 引入了反向映射表（RMP，Reverse Map Table）。之所以称之为反向映射表，是因为在传统的 VM 地址翻译中，映射方向是：</p><blockquote><p>gVA =&gt; gPA（guest 物理地址） =&gt; sPA（系统物理地址）</p></blockquote><p>而 RMP 中记录的是：</p><blockquote><p>sPA =&gt; {gPA, valid_bit, ASID}</p></blockquote><p>与传统方向相反。</p><p>RMP 的设计主要是为了使得物理内存真的分配给了特定的 VM，恶意的 Hypervisor 无法欺骗 VM 。当 Hypervisor 给 VM 分配内存时，需要使用特定的 <code>rmpupdate</code> 指令，VM 需要使用 <code>rmpvalid</code> 指令确认此次分配符合自己的要求。一旦分配完成后，Hypervisor 就无法再写入该内存页面了。后续 VM 可以使用 <code>rmpupdate</code> 来调整权限或者映射关系。</p><p>采用反向映射的方式，在地址翻译的时候增添一次映射来核对 GPA （GPA 是否真的对应特定的 SPA）和 ASID （VM 是否真的是特定的 VM）来确保“恶意 Hypervisor 无法尝试将页面映射到 Guest 地址空间中的错误位置”。</p><p><img src="/posts/71c079c7/pic2.png" alt="pic2"></p><h4 id="1-2-2-上下文加密"><a href="#1-2-2-上下文加密" class="headerlink" title="1.2.2 上下文加密"></a>1.2.2 上下文加密</h4><p>ES（Encrypted state）：在 VM 内陷到 Hypervisor 的时候，CPU 的状态会被加密保存到 VM Saving Area (VMSA) 。</p><h4 id="1-2-3-安全中断"><a href="#1-2-3-安全中断" class="headerlink" title="1.2.3 安全中断"></a>1.2.3 安全中断</h4><p>当限制中断（restricted）被启用时，Hypervisor 只能注入一种叫作 #HV 的中断，当 #HV 中断到达某个 VMPL 时，该 VMPL 的 VM 代码可以参考 #HV 门铃页来检查中断类型，而不是直接跳转到任意的中断处理程序。</p><p>共享门铃页（Shared Doorbell Page）是一个内存页面，被 Hypervisor 和 VM 的不同权限级别共享，用于传递中断和事件通知的信息。当 Hypervisor 发生注入某个特定类型的中断的时候，可以先修改门铃页来记录要触发的中断类型，然后给 VM 注入 #HV 中断，VM 收到 #HV 中断后会查看门铃页里的中断类型，进而做出相应处理。而不是直接被 Hypervisor 改变程序流。</p><p>VeriSMo 启用了 restricted-mode，减少了 Hypervisor 中断注入攻击的攻击面。</p><h4 id="1-2-4-虚拟机特权等级"><a href="#1-2-4-虚拟机特权等级" class="headerlink" title="1.2.4 虚拟机特权等级"></a>1.2.4 虚拟机特权等级</h4><p>在经历了内存加密和寄存器加密后，其实特权等级模型已经发生了变换。传统的特权等级模型下，高特权级可以随意访问低特权级的资源，随意影响低特权级软件的程序流（中断）；但是在 AMD SEV 中，即使是高特权级也无法访问一些低特权级的资源。</p><p><img src="/posts/71c079c7/pic3.png" alt="pic3"></p><p>更进一步，SEV-SNP 提供了 VMPL（虚拟机特权级别）的功能。该功能允许进行额外的安全控制，以保护 guest 内部的内存免受同一 guest 中其他代码的影响。每个 guest 最多可以有四个 VMPL，其中 VMPL0 权限最高，VMPL3 权限最低。分配给 guest 的每个内存页面可能具有基于 VMPL 的不同权限。 VMPL0 始终具有对 guest 地址空间中每个页面的完全访问权限，但它可能会将某些页面配置为不可在 VMPL1 上访问，或者可能允许只读访问。</p><p>VeriSMo 就是一个运行在 VMPL0 上的软件，而 Guest OS 运行在 VMPL3（只要不是 VMPL0 就行）上，这样可以避免不受信任的 Guest OS 的攻击。VMPL0 除了可以管理</p><h3 id="1-3-软件"><a href="#1-3-软件" class="headerlink" title="1.3 软件"></a>1.3 软件</h3><p>reference：</p><p><a href="https://verus-lang.github.io/verus/guide/">Verus Tutorial and Reference</a></p><h4 id="1-3-1-Rust-Checker"><a href="#1-3-1-Rust-Checker" class="headerlink" title="1.3.1 Rust Checker"></a>1.3.1 Rust Checker</h4><p>Rust 的所有权系统和类型系统确保了一定的安全性，但是 Unsafe Rust 可能会导致 bug 或者安全性问题。</p><h4 id="1-3-2-Verus"><a href="#1-3-2-Verus" class="headerlink" title="1.3.2 Verus"></a>1.3.2 Verus</h4><p>Verus 是一个为 Rust 设计的形式化验证工具，它看上去就像一个被拓展了语法的 Rust。</p><pre class="line-numbers language-Rust" data-language="Rust"><code class="language-Rust">verus! {fn octuple(x1: i8) -&gt; (x8: i8)    requires        -16 &lt;= x1 &lt; 16,    ensures        x8 == 8 * x1,{    let x2 = x1 + x1;    let x4 = x2 + x2;    x4 + x4}fn main() {    let n = octuple(10);    assert(n == 80);}} // verus!<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>可以注意到相比于普通的 Rust，多加了 <code>requires, ensures, invarient</code> 等关键词，这些是形式化验证的“方法”。本项目不仅实现了一个经过验证的模块，还将验证方法都用 rust 或者说 verus 实现了。</p><hr><h2 id="二、设计"><a href="#二、设计" class="headerlink" title="二、设计"></a>二、设计</h2><h3 id="2-1-威胁模型"><a href="#2-1-威胁模型" class="headerlink" title="2.1 威胁模型"></a>2.1 威胁模型</h3><p>VeriSMo 的可信基只包括硬件和它自己（运行在 VMPL0 上的 VeriSMo），它既不信任 Hypervisor，也不信任运行在 VMPL3 的 Guest OS。</p><p><img src="/posts/71c079c7/pic4.png" alt="pic4"></p><p>VeriSMo 在这样的模型下，要完成唤醒 CPU，管理 Guest 内存，确保 Guest OS 的完整性，运行时测量等功能。</p><p><img src="/posts/71c079c7/pic5.png" alt=""></p><h3 id="2-2-验证目标"><a href="#2-2-验证目标" class="headerlink" title="2.2 验证目标"></a>2.2 验证目标</h3><p>我们希望用形式化验证的方式确定 3 个属性：</p><ul><li>功能正确性：VeriSMo 可以无 bug 地满足安全服务所需要的功能。</li><li>信息流安全：程序在任何情况下都不应通过内存操作或低安全级别变量的值泄露与高安全级别变量相关的信息。</li><li>VM 的机密性和可信性：Hypervisor 和 VMPL3 都不可以读取 VMPL0 的私有内存。Hypervisor 不可以读取 VM 的私有内存（应该是包括 VMPL0 和 VMPL3 的私有内存）。</li></ul><p>总的来说有两个目标，一个是内存安全，一个是信息流安全。文章比较大的篇幅集中于内存安全，而信息流安全的验证则和其他部分比较孤立，最后单独形成一个章节介绍。</p><h3 id="2-3-验证思路"><a href="#2-3-验证思路" class="headerlink" title="2.3 验证思路"></a>2.3 验证思路</h3><p>Hypervisor 会打断 VM 对资源形成并发操作，然而因为不信任 Hypervisor 的原因，我们无法直接验证 Hypervisor ，所以我们将验证分成了两层。第一层是 Machine Model Layer，采用建立一个硬件抽象机的方式进行模型级的验证，确保在给定 Hypervisor 约束后，它不会影响 VM 的机密性和完整性。第二层是 VeriSMo 内部实现的验证。</p><p><img src="/posts/71c079c7/1722216940888-14.png" alt="img"></p><p>我个人感觉形式化验证是可以验证并发程序的，此项目分成两层进行验证，有可能不是因为 Hypervisor 的并发很难验证，而是因为 Hypervisor 不在信任基内，导致我们没法直接验证，所以我们才采用了建模的方式进行抽象验证。</p><p>我个人感觉其实是将验证分为了两步：</p><ul><li>Machine-Model Layer：验证 AMD SEV-SNP 这套硬件机制没有问题</li><li>Implement Layer：验证 VeriSMo 对 AMD SEV-SNP 的使用没有问题</li></ul><hr><h2 id="三、内存安全验证"><a href="#三、内存安全验证" class="headerlink" title="三、内存安全验证"></a>三、内存安全验证</h2><h3 id="3-1-Machine-Model-层"><a href="#3-1-Machine-Model-层" class="headerlink" title="3.1 Machine-Model 层"></a>3.1 Machine-Model 层</h3><p>Machine Model 具有两个目标：</p><ul><li>Hypervisor 和 VMPL3 都不可以读取 VMPL0 的私有内存。</li><li>Hypervisor 不可以读取 VM 的私有内存（应该是包括 VMPL0 和 VMPL3 的私有内存）。</li></ul><p>更进一步地说，我们希望验证这个图片所展示的事实，即 HV 和 VM 具有一定的独立性：</p><p><img src="/posts/71c079c7/1722216970526-17.png" alt="img"></p><p>VERISMO 并没有一个 guest OS 那么庞大，所以 VERISMO 只对关键的内存和 cache 操作进行建模。</p><p>其更加具体地说，它的主线逻辑是这样的，它定义了 4 个对象：</p><ul><li>系统状态（Ψ）：整个系统</li><li>实体（e）：可能是 Hypervisor、VeriSMo，Guest OS </li><li>操作（op）：关键的内存和 cache 操作，比如更新页表之类的。</li><li>攻击模型（attack model）：Ψ 按照一定顺序经过多个 e 的多个 op 的一个序列</li></ul><p>如果 Ψ 初始化是正确的，所有的 op 都满足各自的前置条件和后置条件，验证 Ψ 经过 op 后依然安全（保证一定的不变式），那么按照类似数学归纳法的思想，经过多次 op 后 Ψ 依然安全。</p><p>那么检验的核心就在于 op 的约束条件（前置和后置）能否满足上述要求。这就需要结合硬件特性来推导出一些比较强的引理来。</p><p>关于 VM-Private 的内存，我们有：</p><ul><li>Ψ 下 CVM 私有内存 M 包含数据 D，经由 HV 操作后， Ψ’ 下 CVM 读取 M 得到数据 D 或读取失败。</li></ul><p>这是因为 RMP 规定如果该 M 不是 valid 的，那么 HV 是可以读取的，而如果是 valid 的，那么就不可以读取。</p><ul><li>Ψ 下 CVM 私有内存 M 包含机密 S，经由 HV 操作后， Ψ’ 下 HV 读取 M 得到 S 的密文。</li></ul><p>如果经过加密，那么读取到的一定是密文。</p><p>关于 VMPL0-Private 的内存，我们有：</p><ul><li>Ψ 下 VMPL0 私有内存 M 包含数据 D，经由 hypervisor 或 VMPL3 操作后， Ψ’ 下 VMPL0 读取 M 得到数据 D 或读取失败，VMPL3 不能读取 M。</li></ul><p>由引理 1，2 可以 HV 不可读取，又因为 RMP 中记录了每个 VMPL 的访问权限，VMPL3 没有访问权限。</p><p>关于地址翻译，我们有：</p><ul><li>Ψ 下 VMPL0 访问 gVA 翻译到 sPA，经由 HV 或 VMPL3 操作后，Ψ’ 下 VMPL0 访问 gVA 翻译到 sPA 或翻译失败。</li></ul><p>只有使用 VMPL0 的特殊指令才能更改页表，任何其他更改页表的行为都会导致报错。</p><ul><li>任何 Ψ 下，CVM 的 gVA 到 sPA 的映射是双射。</li></ul><p>因为 gPA 到 sPA 的映射是双射，只需要证明 gVA 到 gPA 是双射。具体的证明方法类似于“一开始是双射，而且每次操作都必须保证是双射的，所以最后是双射”的数学归纳法。</p><p>在有了这五条引理后，就可以交给形式化证明机来完成证明了。</p><h3 id="3-2-Implement-层"><a href="#3-2-Implement-层" class="headerlink" title="3.2 Implement 层"></a>3.2 Implement 层</h3><p>在实现层，验证上主要采用如下技术来实现形式化验证：</p><p><img src="/posts/71c079c7/1722216970526-18.png" alt="img"></p><p>其中 Rust 负责基础的所有权和读写检查，SNP Pointer 是一个用于验证的胖指针，里面对 SEV-SNP 机制进行了建模，胖指针的样子是这样的</p><pre class="line-numbers language-Rust" data-language="Rust"><code class="language-Rust">pub ghost struct SnpMemAttr{ rmp: RmpEntry, pte: PTAttr, is_pt: bool}pub ghost struct SnpPointsToData&lt;T&gt; {    addr: int, value: Option&lt;T&gt;,    swattr: SnpMemAttr, hwattr: SnpMemAttr,}pub tracked struct SnpPointsTo&lt;V&gt;{ _p: marker::PhantomData&lt;V&gt;, _ncopy: NoCopy }impl&lt;T&gt; SnpPointsTo&lt;T&gt;{ pub spec fn view(&amp;self) -&gt; SnpPointsToData&lt;T&gt;; }<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>检验者可以根据胖指针内 <code>RmpEntry, addr</code> 等元素进行验证。如下所示：</p><pre class="line-numbers language-Rust" data-language="Rust"><code class="language-Rust">fn access_private(Tracked(mperm): Tracked&lt;&amp;SnpPointsTo&lt; u64&gt;&gt;)    requires      mperm@.wf_not_null_at(0x1000),      mperm@.is_vmpl0_private(){    let val1 = *borrow(0x1000, Tracked(mperm));    let val2 = *borrow(0x1000, Tracked(mperm));    assert(val2 == val1);    replace(0x1000, 0x1234, Tracked(mperm)); // Rust : change the unmutable val!    let _val3 = *borrow(0x2000, Tracked(mperm)); // Verus: borrow wrong addr!}<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>对于 unsafe rust 操作，我们用 verus 来限制并验证其使用，比如 <code>rmpadjust</code> 指令，就有复杂的前置和后置条件（见 <a href="https://verus-lang.github.io/verus/guide/memory-safety.html">19.2. Memory safety is conditional on verification</a>）：</p><pre class="line-numbers language-Rust" data-language="Rust"><code class="language-Rust">pub fn rmpadjust(    vaddr: u64,    psize: u64,    attr: RmpAttr,    Tracked(mycore): Tracked&lt;&amp;SnpCore&gt;,    Tracked(newcore): Tracked&lt;Option&lt;CoreIdPerm&gt;&gt;,    Tracked(perm): Tracked&lt;&amp;mut SnpPointsToRaw&gt;,) -&gt; (ret: u64)    requires        old(perm)@.snp().requires_rmpadjust(vaddr as int, psize as int, attr@, newcore, old(perm)@),        mycore.coreid@.vmpl == 0,        attr.spec_vmpl() &gt; mycore.coreid@.vmpl,    ensures        old(perm)@.snp.rmpadjust_ret(perm@.snp, ret, vaddr as int, psize as int, attr@),        old(perm)@.range() === perm@.range(),        old(perm)@.snp_bytes === perm@.snp_bytes,{    let ret: u64;    unsafe {        asm!(".byte 0xf3,0x0f,0x01,0xfe",                in("rax") vaddr, in("rcx") psize, in("rdx") attr.value,                lateout("rax") ret,                options(nostack));    }    ret}<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><blockquote><p>PS: <code>@</code> 是 <code>.view()</code> 的缩写，见 <a href="https://verus-lang.github.io/verus/guide/reference-at-sign.html">4.1. Recursive spec functions, decreases, fuel</a></p></blockquote><p>其中 SNP Pointer 和与之配套的验证约束合称 Memory Permisson，因为这种 Permission 有时是需要共享的（因为内存需要共享），所以又引入了 Lock Permisson 来确保并发程序的正确性。</p><p><img src="/posts/71c079c7/1722216970526-19.png" alt="img"></p><p>VeriSMo 内存并发安全模型为：</p><ol><li>上锁的 VMPL0 私有内存（可信内存）可以任意访问；</li><li>如果其他实体（VMPL3 或者 HV）想共享给 VMPL0，要么上锁后拷贝给 VMPL0，要么修改映射关系后重新写入；</li><li>如果 VMPL0 需要共享给其他实体，可以上锁后直接修改映射关系。</li></ol><hr><h2 id="四、信息流安全验证"><a href="#四、信息流安全验证" class="headerlink" title="四、信息流安全验证"></a>四、信息流安全验证</h2><p>左图中，机密变量 high 被通过数据流泄露到公开变量 low。右图中，机密变量 high 通过控制流侧信道被泄露。</p><p><img src="/posts/71c079c7/1722216998108-26.png" alt="img"></p><p>具体的，本工作记录 VeriSMo 中每个变量的猜测空间（guess space, valset），猜测空间为全集的变量为机密变量，猜测空间为单元素集合的变量为公开变量，猜测空间随着计算操作传播。</p><p><img src="/posts/71c079c7/1722216998109-27.png" alt="img"></p><p>验证器确保：</p><ol><li>只有机密变量能用作密钥，</li><li>机密变量保存在 VMPL0 私有内存中</li><li>机密变量不能用于控制流判断、内存地址等可能导致侧信道泄露的用途。</li></ol><hr><h2 id="五、实现与评估"><a href="#五、实现与评估" class="headerlink" title="五、实现与评估"></a>五、实现与评估</h2><p>从实现层面来说，似乎锁设计比较新颖，锁的数目比较少，验证难度也比较低。</p><p>从实现性能看，与 Hecate 这种提供安全服务的 HV 相比，性能提高了 40%，因为不需要频繁内陷到 HV 中，这应该是所有的 Secure Module 都具有的性能优势。</p><p>而与其他的 Secure Module 相比（用 C 实现的 SMo 或者修改后 Linux 作为一个 SMo），在性能开销方面差别不大（Index 越高性能越好）</p><p><img src="/posts/71c079c7/1722217009985-32.png" alt="img"></p><p>从验证层面看，验证速度很快，大约 6 分钟就可以验证完两层模型。</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;&lt;img src=&quot;/posts/71c079c7/1600x900_1591431860952_2048x1152_logo.jpg&quot; alt=&quot;A RaiPlay learning il Verismo e i suoi autori - RAI Ufficio Stampa&quot;&gt;&lt;/p&gt;
&lt;p&gt;VeriSMo 的可信基只包括硬件和它自己（VM），剔除了对于 Hypervisor 的信任。传统的 VM 的安全服务是由 Hypervisor 负责的，如果认为 Hypervisor 是不可信的，那么就不能由它来提供安全服务。AMD 提供了新的安全架构 SEV-SNP，它为在 VM 中独立实现安全服务提供了支持，VeriSMO 就利用了这个硬件特性。&lt;/p&gt;
&lt;p&gt;除了利用新的硬件安全特性外，VeriSMo 在开发时完成了形式化验证来确保安全性。VeriSMo 的开发语言是 Rust，已经确保了部分的内存安全性（也就是 Rust Checker 承担了部分形式化验证的任务），距离完全的形式化验证还有两个挑战：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;因为 Hypervisor 不可信任，所以 Hypervisor 可以打断 VM 的执行并修改硬件状态，这种并行无法简单验证。&lt;/li&gt;
&lt;li&gt;开发 VeriSMo 需要使用 Unsafe Rust，Rust Checker 无法验证这种情况。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;为了解决挑战 1，VeriSMo 将验证拆分成了 2 层，上层为机器模型层（Machine Model），用 model verify 专门约束 Hypervisor 的行为，下层为实现层（Implement），用于解决排除了 Hypervisor 干扰后的 VeriSMo 本身的验证问题。&lt;/p&gt;</summary>
    
    
    
    <category term="海边拾贝" scheme="https://thysrael.github.io/categories/%E6%B5%B7%E8%BE%B9%E6%8B%BE%E8%B4%9D/"/>
    
    
    <category term="知识总结" scheme="https://thysrael.github.io/tags/%E7%9F%A5%E8%AF%86%E6%80%BB%E7%BB%93/"/>
    
    <category term="S8假期" scheme="https://thysrael.github.io/tags/S8%E5%81%87%E6%9C%9F/"/>
    
    <category term="海边拾贝" scheme="https://thysrael.github.io/tags/%E6%B5%B7%E8%BE%B9%E6%8B%BE%E8%B4%9D/"/>
    
  </entry>
  
  <entry>
    <title>信息安全-基本概念</title>
    <link href="https://thysrael.github.io/posts/7efac32a/"/>
    <id>https://thysrael.github.io/posts/7efac32a/</id>
    <published>2024-07-10T12:51:28.000Z</published>
    <updated>2024-10-17T06:35:01.753Z</updated>
    
    <content type="html"><![CDATA[<h2 id="一、安全目标"><a href="#一、安全目标" class="headerlink" title="一、安全目标"></a>一、安全目标</h2><h3 id="1-1-总论"><a href="#1-1-总论" class="headerlink" title="1.1 总论"></a>1.1 总论</h3><p>系统安全有 3 个目标：</p><ul><li><strong>机密性（Confidentiality）</strong>：又称隐私性（Privacy），是指数据不能被未授权的主体窃取（即恶意读操作）。</li><li><strong>完整性（Integrity）</strong>：是指数据不能被未授权的主体篡改（即恶意写操作）。</li><li><strong>可用性（Availability）</strong>：是指数据能够被授权主体正常访问。</li></ul><p>合称 CIA 。</p><h3 id="1-2-机密性-Confidentiality"><a href="#1-2-机密性-Confidentiality" class="headerlink" title="1.2 机密性 (Confidentiality)"></a>1.2 机密性 (Confidentiality)</h3><h4 id="1-2-1-含义"><a href="#1-2-1-含义" class="headerlink" title="1.2.1 含义"></a>1.2.1 含义</h4><p>完整性是指保护数据不被未授权的主体篡改，确保数据的准确性、一致性和信任度。</p><h4 id="1-2-2-实现手段"><a href="#1-2-2-实现手段" class="headerlink" title="1.2.2 实现手段"></a>1.2.2 实现手段</h4><ul><li><strong>加密</strong>：对数据进行加密，只有持有正确解密密钥的主体才能读取数据。</li><li><strong>访问控制</strong>：通过访问控制列表（ACL）和权限设置来限制数据的访问。</li><li><strong>身份验证</strong>：确保数据只能由经过身份验证的用户或系统访问。</li></ul><h4 id="1-2-3-示例"><a href="#1-2-3-示例" class="headerlink" title="1.2.3 示例"></a>1.2.3 示例</h4><ul><li><strong>加密通信</strong>：使用 HTTPS 协议对网络通信进行加密，防止第三方窃取传输中的数据。</li><li><strong>数据加密存储</strong>：在文件系统或数据库中对敏感信息进行加密存储。</li><li><strong>访问控制</strong>：设定文件或数据库记录的访问权限，只允许具备相应权限的用户访问。</li></ul><h3 id="1-3-完整性-Integrity"><a href="#1-3-完整性-Integrity" class="headerlink" title="1.3 完整性 (Integrity)"></a>1.3 完整性 (Integrity)</h3><h4 id="1-3-1-含义"><a href="#1-3-1-含义" class="headerlink" title="1.3.1 含义"></a>1.3.1 含义</h4><p>完整性是指保护数据不被未授权的主体篡改，确保数据的准确性、一致性和信任度。</p><h4 id="1-3-2-实现手段"><a href="#1-3-2-实现手段" class="headerlink" title="1.3.2 实现手段"></a>1.3.2 实现手段</h4><ul><li><strong>校验和和哈希</strong>：使用校验和或哈希函数来生成数据的唯一摘要，接收方可以通过比较摘要来验证数据是否被篡改。</li><li><strong>数字签名</strong>：使用数字签名对数据进行签名，以确保数据在传输中的完整性和来源的可靠性。</li><li><strong>版本控制</strong>：使用版本控制系统记录数据的变更历史，防止未经授权的修改。</li></ul><h4 id="1-3-3-示例"><a href="#1-3-3-示例" class="headerlink" title="1.3.3 示例"></a>1.3.3 示例</h4><ul><li><strong>哈希校验</strong>：下载文件后检查文件的哈希值，确认其未被篡改。</li><li><strong>数字签名</strong>：邮件或文档使用数字签名，收件人可以验证其来源和内容的完整性。</li><li><strong>文件权限</strong>：设置敏感文件为只读，防止未经授权的用户进行修改。</li></ul><h3 id="1-4-可用性-Availability"><a href="#1-4-可用性-Availability" class="headerlink" title="1.4 可用性 (Availability)"></a>1.4 可用性 (Availability)</h3><h4 id="1-4-1-含义"><a href="#1-4-1-含义" class="headerlink" title="1.4.1 含义"></a>1.4.1 含义</h4><p>可用性是指确保数据和系统在需要时能够被授权的主体正常访问和使用。</p><h4 id="1-4-2-实现手段"><a href="#1-4-2-实现手段" class="headerlink" title="1.4.2 实现手段"></a>1.4.2 实现手段</h4><ul><li><strong>冗余和备份</strong>：通过数据冗余和定期备份来确保数据在特殊情况下（如硬件故障）仍然可用。</li><li><strong>容错和高可用架构</strong>：设计容错和高可用系统架构，使用负载均衡、多路径等技术，确保系统在故障情况下仍然能够提供服务。</li><li><strong>DoS/DDoS 保护</strong>：通过防火墙、入侵检测系统（IDS）和流量管理等手段防止拒绝服务（DoS）或分布式拒绝服务（DDoS）攻击。</li></ul><h4 id="1-4-3-示例"><a href="#1-4-3-示例" class="headerlink" title="1.4.3 示例"></a>1.4.3 示例</h4><ul><li><strong>云备份</strong>：定期将数据备份到云存储，确保在本地数据损坏时可以恢复。</li><li><strong>高可用性集群</strong>：使用高可用性集群和负载均衡器分配流量，确保一个节点出现故障时，其他节点可以继续提供服务。</li><li><strong>流量管理</strong>：部署防火墙和负载均衡器，防止由于流量异常导致的服务中断。</li></ul><h3 id="1-5-三者的区别"><a href="#1-5-三者的区别" class="headerlink" title="1.5 三者的区别"></a>1.5 三者的区别</h3><ul><li><strong>机密性 vs. 完整性</strong>：机密性关注的是防止数据被窃取，而完整性关注的是数据未经授权被篡改。机密性主要解决“谁能看到”的问题，而完整性解决的是“它是否被改变”的问题。</li><li><strong>完整性 vs. 可用性</strong>：完整性确保数据的准确和一致性，而可用性确保数据和系统在需要时是可访问的。完整性保证数据未受未经授权的修改，可用性保证在正确时间提供正确的服务。</li><li><strong>机密性 vs. 可用性</strong>：在某些情况下，机密性和可用性可能需要权衡。例如，高度加密的数据可能需要更多的计算资源解密，从而影响系统的可用性。机密性和可用性关注的是不同的方面，前者注重安全访问，后者注重无障碍访问。</li></ul><hr><h2 id="二、访问控制"><a href="#二、访问控制" class="headerlink" title="二、访问控制"></a>二、访问控制</h2><h3 id="2-1-总论"><a href="#2-1-总论" class="headerlink" title="2.1 总论"></a>2.1 总论</h3><p>访问控制（Access Control）是按照访问主体的身份（Identity）来限制其访问对象的一种方法。它由两个基本过程组成，即：</p><ul><li>认证（Authentication）：验证某个发起访问请求的主体的身份。</li><li>授权（Authorization）：授予某个身份一定的权限以访问特定的对象。</li></ul><p>访问控制是这样的一件事，资源的请求方被称为主体，认证干的事情是确定你真的是这个主题，而不是一个人化妆了伪造出来的人，换句话说，认证干的是“主体 =&gt; 身份”的工作；授权则干得是“身份 =&gt; 权限”的工作，需要强调，授权并不只局限于“赋予”某个身份一定的权限，他还包括这个权限的正确执行，违法权限的行为的发现。</p><p><img src="/posts/7efac32a/image-20240711145910684.png" alt="image-20240711145910684"></p><p>打给比方，认证就是“火眼金睛”，而“授权”则是天条和天兵。</p><h3 id="2-2-认证"><a href="#2-2-认证" class="headerlink" title="2.2 认证"></a>2.2 认证</h3><p>认证过程旨在建立发起请求的主体与系统中某个 ID 之间的绑定关系。例如，用户登录操作系统时，首先要选择用户名（即 ID），然后输入密码或口令完成登录过程。</p><p>认证过程中,判断某一个主体身份的方法主要有三种：</p><ul><li>你知道什么（Something you know）：例如密码/口令（password）、手势密码、某个问题的答案等。</li><li>你有什么（Something you have）：例如 USB-key、密码器等实物；电子令牌（token）</li><li>你是什么（Something you are）：例如指纹、虹膜、步态、键盘输入习惯等，属于人的一部分。</li></ul><p>总的来说，由上到下主体和身份（ID）的相关性在增强，进而安全性就在增强。主体知道的东西很容易被窃取，比如一个用生日做的密码，即使不是主体，也很容猜到。而主体的指纹，就没那么容易搞到了。</p><p>Token 和 Password 都用于身份验证但用途和特性不同。Password 是用户在登录时输入的静态字符组合，用于初次验证身份。而 Token 则是在用户通过密码验证后，由服务器生成并发给客户端的动态凭证，用于在后续请求中证明身份。与 Password 不同，Token 通常有时效性，可以减少频繁传递 Password 的安全风险，并且适合分布式系统中的认证场景。</p><h3 id="2-3-授权"><a href="#2-3-授权" class="headerlink" title="2.3 授权"></a>2.3 授权</h3><p>授权，是判断某个主体是否有权限访问某个对象的过程。授权机制主要考虑以下三个问题：</p><ol><li><p><strong>用何种数据结构来表达主体与对象之间的权限关系</strong>：</p><p>确定如何存储和表示主体与对象之间的权限关系，如使用访问控制列表（ACL）、角色权限矩阵或权限表等。</p></li><li><p><strong>如何设置和修改这种权限关系</strong>：</p><p>确定权限的分配和调整机制，例如通过管理员手动配置、角色分配系统或自动化策略等。</p></li><li><p><strong>如何强制保证这种权限关系</strong>：</p><p>确保系统能够正确执行权限检查和访问控制，防止未经授权的访问。可以通过身份验证、访问控制检查和安全审计等手段来实现。</p></li></ol>]]></content>
    
    
    <summary type="html">&lt;h2 id=&quot;一、安全目标&quot;&gt;&lt;a href=&quot;#一、安全目标&quot; class=&quot;headerlink&quot; title=&quot;一、安全目标&quot;&gt;&lt;/a&gt;一、安全目标&lt;/h2&gt;&lt;h3 id=&quot;1-1-总论&quot;&gt;&lt;a href=&quot;#1-1-总论&quot; class=&quot;headerlink&quot; title=&quot;1.1 总论&quot;&gt;&lt;/a&gt;1.1 总论&lt;/h3&gt;&lt;p&gt;系统安全有 3 个目标：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;机密性（Confidentiality）&lt;/strong&gt;：又称隐私性（Privacy），是指数据不能被未授权的主体窃取（即恶意读操作）。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;完整性（Integrity）&lt;/strong&gt;：是指数据不能被未授权的主体篡改（即恶意写操作）。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;可用性（Availability）&lt;/strong&gt;：是指数据能够被授权主体正常访问。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;合称 CIA 。&lt;/p&gt;</summary>
    
    
    
    <category term="信息安全" scheme="https://thysrael.github.io/categories/%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8/"/>
    
    
    <category term="直观理解" scheme="https://thysrael.github.io/tags/%E7%9B%B4%E8%A7%82%E7%90%86%E8%A7%A3/"/>
    
    <category term="信息安全" scheme="https://thysrael.github.io/tags/%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8/"/>
    
    <category term="S8假期" scheme="https://thysrael.github.io/tags/S8%E5%81%87%E6%9C%9F/"/>
    
  </entry>
  
  <entry>
    <title>沟通交流-旋氏语法</title>
    <link href="https://thysrael.github.io/posts/a039c29c/"/>
    <id>https://thysrael.github.io/posts/a039c29c/</id>
    <published>2024-06-24T01:58:10.000Z</published>
    <updated>2024-10-17T06:35:03.407Z</updated>
    
    <content type="html"><![CDATA[<h2 id="一、总论"><a href="#一、总论" class="headerlink" title="一、总论"></a>一、总论</h2><p>这篇文章是对于<a href="https://llwslc.github.io/grammar-club/">旋元佑语法俱乐部</a>的一个注释总结。行文思路基本上和这本电子书的章节保持一致。</p><p>语法是对于语言的规律总结，这类似于物理是对于客观世界的规律总结。不过应当注意到，即使掌握了语法，也并不能短时间内提高英语水平，因为在语法的指导下使用语言，同样是一个需要习惯和精进的过程。这就像掌握了物理定律和物理满分之间依然存在很大差距一样。</p><p>旋老师的语法和我中学学过的语法并不一样，旋老师倾向于建立一种“大一统”的理论来解释所有的语言现象，而中学语法则更加繁杂和缺少一致性。在加上我这次学习语法已经是大四，在逻辑思维上相比于中学已经有了很大的进步。所以总的来说，语法更加“讲理”了。</p><p>但是旋氏语法的缺点我个人感觉有两个，一个是因为过于“统一”，导致需要引入一堆与中学语法似是而非的概念，这些概念类似于物理学上的“波粒二象性”一样，对中学语法是一种挑战；并且因为旋老师是台湾人的缘故，所以在表达习惯和方式上也与大陆存在一定的差异（也就是他写的中文有点难看懂）。另一个是旋老师在建立了“统一”的理论后，并没有充分利用这些规律推导出中学语法甚至是其他中学语法难以推导的其他语言现象。</p><p>所以这篇文章会对原本的电子书进行一定的解释和应用。</p><hr><h2 id="二、简单句"><a href="#二、简单句" class="headerlink" title="二、简单句"></a>二、简单句</h2><h3 id="2-1-基本句型"><a href="#2-1-基本句型" class="headerlink" title="2.1 基本句型"></a>2.1 基本句型</h3><p>英语语法的研究单位是句子，而简单句（可以看作比较本源的一种句子）一共有  5 种句型，如下所示：</p><div class="table-container"><table><thead><tr><th>简记</th><th>解释</th><th>动词性质</th><th>举例</th></tr></thead><tbody><tr><td>S + V</td><td>主语 + 动词</td><td>不及物动词</td><td>die, smile</td></tr><tr><td>S + V + O</td><td>主语 + 动词 + 宾语</td><td>单宾语及物动词</td><td>kill, love, like</td></tr><tr><td>S + V + C</td><td>主语 + 动词 + 主语补语</td><td>系动词/连缀动词</td><td>be, seem, sound, feel, prove</td></tr><tr><td>S + V + O + O</td><td>主语 + 动词 + 直接宾语 + 间接宾语</td><td>双宾语及物动词</td><td>give, call,tell</td></tr><tr><td>S + V + O + C</td><td>主语 + 动词 + 宾语 + 宾语补语</td><td>宾语补语及物动词</td><td>find, consider, find</td></tr></tbody></table></div><p>其中简记符号是这样的：</p><div class="table-container"><table><thead><tr><th>符号</th><th>英文</th><th>全称</th></tr></thead><tbody><tr><td>S</td><td>Subject</td><td>主语</td></tr><tr><td>V</td><td>Verb</td><td>动词</td></tr><tr><td>O</td><td>Object</td><td>宾语</td></tr><tr><td>C</td><td>Complement</td><td>补语</td></tr></tbody></table></div><p>在这种分类下（其实这只是旋老师自己的分类，有些语法的分类要更加复杂），有许多有趣的特征：</p><p>可以看到这种对句子成分的分类法，取消了常见的“谓语，状语，表语”的语法成分。其中谓语的取消，应该是因为谓语的定义过于宏大。谓语的英文是 Predicate，也就是断言，所以我个人理解，断言加上断言的目标，也就是主语，那么就可以构成一个命题了，而命题基本上是句子存在的意义。我们说的每一句话，都是一个命题。如果认为句子中存在谓语，那么基本上其他的语法成分都会被囊括其中，其实是不利于细致探究的。而状语之所以没有，是因为它并不是句子的主干，而是句子的点缀，所以就没有细说。而传统意义上的表语，则大部分被划分到了补语范畴内，旋老师这么做是为了某种“简洁性”。</p><p>一个句子对应一个动词。也就是说，如果一个字符串里没有动词，那么就一定不是一个简单句，同理，如果一个字符串中有了两个动词，那么就一定不是一个简单句，而有可能是一个从句，或者简化从句，这是很有意思的一点，比如说例句：</p><blockquote><p>I hate programming.</p></blockquote><p>其中有 hate 和 program 两个动词，所以它并不是一个简单句，而是一个简化从句：</p><blockquote><p>I hate that I program.</p></blockquote><p>意识到句子与动词的一一对应关系，可以理解复杂的句子，因为动词很好数出来。</p><p>动词的性质决定了不同的句型。上文列出了五种句型，并不是可以随意搭配动词使用的。动词性质决定了句型，比如不及物动词，它的句型只能是“S + V”，不能是“S + V + C”。所以积累动词的性质，可以有助于我们识别句子的结构，当遇到一个不及物动词的时候，就不用去后文找补语或者宾语了。</p><h3 id="2-2-限定"><a href="#2-2-限定" class="headerlink" title="2.2 限定"></a>2.2 限定</h3><p>在介绍其他语法之前我想介绍一下限定（Finite），它指的是词语的一种属性。对于动词而言，简单句里的动词都是限定动词，这样的动词需要受到人称、时态、语态、助词（情态动词等）、语气的限制（Determiner），也就是承担了更多的句子表达更多信息的任务。我们可以从限定动词中获得更多的信息，在使用限定动词的时候，也需要注意更多限制。而非限定动词则不需要考虑那么多，一般只有 Ving，to V，Ven 这几种形式。非限定动词可以看作是从句简化后的结果。</p><p>基于“限定”的概念，引申出来“不定式”的概念，它特指“to V”结构。旋老师将不定时描述成了情态动词的退化，将在后面详述。</p><p>除了动词以外，名词也有限定词的说法，它指的是复数变化和冠词等内容。</p><h3 id="2-3-时态"><a href="#2-3-时态" class="headerlink" title="2.3 时态"></a>2.3 时态</h3><h4 id="2-3-1-分词"><a href="#2-3-1-分词" class="headerlink" title="2.3.1 分词"></a>2.3.1 分词</h4><p>在传统语法中，时态是非常复杂的，有如此多项：</p><ul><li>时间：过去，现在，未来</li><li>状态：简单，进行，完成</li><li>语态：主动，被动</li></ul><p>一般都是这三种内容的自由组合，比如说“过去完成时被动语态”。旋老师主张将进行时和被动语态看作一种“形容词”，这样</p><blockquote><p>I am reading.</p></blockquote><p>就变成了一种“S + V + C”的结构。这样的话，其实就取消了“主被动”的问题，并且减少了“状态”中的进行时。这种简化我觉得并不是很有意义，只是在形式上简化了语法，但是“进行”或者“被动”本身的含义并没有被化简掉。</p><p>这种思想其实并不是牵强附会，它可以看作是“分词 Participle”思想的延伸，分词既有动词的特性，也有形容词的特性，所以说它”分享”了两种词类的特点。分词有现在分词（Present Participle）和过去分词（Past Participle）两种，其实就是 Ving 和 Ved 这两种。它们原本是动词，分词化处理后具有了形容词词性，所以可以担任补语的职责。</p><h4 id="2-3-2-状态"><a href="#2-3-2-状态" class="headerlink" title="2.3.2 状态"></a>2.3.2 状态</h4><p>其中时间和语态的区分是比较容易的，难点还是状态的区分上。我感觉最好还是同时区分“简单、进行、完成”三种语态。其实从语义上来说，三者的区别是很明显的，其中普通式指的是“这句话只是为了说这句话”，也就是这句话就是一个纯粹的<strong>命题</strong>。其他两种状态都有一种“这句话是别的话的铺垫”的感觉，这是我觉得这三种状态最核心的区别，如下所示：</p><blockquote><p>I read this book. （我读这本书，平平淡淡的陈述句）</p><p>I am reading this book （我正在读这本书，强调“正在”要超过“读”，可能表明现在很忙）</p><p>I have read this book （我读过这本书了，强调“读过”要超过“读”，可能表明我了解这本书的知识了）</p></blockquote><p>当然在搞明白这点以后，其实并不足够。我个人感觉是因为状态的描述不仅需要依靠现在分词或者 have 这样的助动词来帮助，它们往往和时间概念联系在一起。这并不奇怪，因为当我们在说一个不是纯粹命题的句子（也就是普通式）的时候，我们往往还要说些其他的信息，而将不纯粹命题和其他信息联系在一起的媒介，就是时间。比如说：</p><blockquote><p>I was reading this book when he knocked my door. （他的敲门打扰了我“正读书”的行为）</p><p>I have read this book so that I will pass the exam easily. （因为我“读过”书了，所以通过考试对我轻轻松松） </p></blockquote><p>这些蕴藏在状态中的时间概念，如下图所示：</p><p><img src="/posts/a039c29c/time.png" alt=""></p><p>对于普通式来说，其时间观念的核心在于一个“<strong>有始有终的准确时间范围</strong>”，这是因为任何命题的成立都需要一个时间范围。比如：</p><blockquote><p>I read this book last week.</p></blockquote><p>这句话如果去掉了“last week”也不是不行，但是这只是一种“省略”，但是读书一定会发生在过去的一个准确的时间段。这种时间段有两个有趣的特性。一个就是前面提到的省略，确实可以省略，但是意思并不会变，与之形成对比就是其他两种状态，往往更需要显式的时间成分。另一个就是时间段的开始和结束时间可以到无限远，此时命题就变成了真理。</p><p>当时间段缩短到一个点的时候，就得到了进行时，这个很好理解。</p><p>而完成时更容易和普通式弄混，如前所述，完成时强调的不再是命题本身，而是命题之外的信息。所以命题发生的时间并不重要，命题产生影响的时间更重要。所以它在示意图中是一个单向箭头，箭头的起点是受到命题影响的时间，而不是命题发生的时间。比如：</p><blockquote><p>I have read this book.</p></blockquote><p>即使这句话使用了“现在”完成时，但是主人公并不是在现在读的书，而是在过去的某个时间节点读的书，只是“现在”要用上这本书的知识了。所以完成时和普通时的一个更加形而下的差别，就是完成时不能确定命题的开始时间和结束时间。</p><p>上面细化了状态的时间概念，但是是从一个比较抽象的、感性的层次去描述的，而实际上，抽象的时间概念依然会落实到具体的单词或者句子上，这些具体的单词或者句子，其实都很有标示性，这就像汉语中很难跳过“正在”或者“过”来描述进行时和完成时一样。故总结如下：</p><div class="table-container"><table><thead><tr><th>状态</th><th>短语</th></tr></thead><tbody><tr><td>普通式</td><td>in + 时间点，this/next month</td></tr><tr><td>进行式</td><td>whole + 时间段，when 从句，then</td></tr><tr><td>完成式</td><td>for + 时间段，since 从句，before 从句，by the time 从句</td></tr></tbody></table></div><h3 id="2-4-语气"><a href="#2-4-语气" class="headerlink" title="2.4 语气"></a>2.4 语气</h3><h4 id="2-4-1-助动词"><a href="#2-4-1-助动词" class="headerlink" title="2.4.1 助动词"></a>2.4.1 助动词</h4><p>在介绍语气前还需要介绍一下助动词（Auxiliary Verb），他们是一种类似于“名词，动词，副词”这样的独立词性。正如前面“限定”所介绍的，限定动词需要承担描述许多信息的职责，当 Ving，Ved 无法满足表达需要的时候，助动词就会出现来辅助限定动词的表达。助动词有如下几类：</p><ul><li>be</li><li>have</li><li>do</li><li>情态动词（modal）</li></ul><h4 id="2-4-2-真假"><a href="#2-4-2-真假" class="headerlink" title="2.4.2 真假"></a>2.4.2 真假</h4><p>语气其实也应该合在“时态”章节里介绍，他们都属于某种“限定”，只是我之前一直忽视，就单独拿出来讲了。语气解决的问题是不再让句子称为一个只是布尔值的情况，他让命题的真值更加连续：</p><blockquote><p>You may be right.</p></blockquote><p>这句话并不能说明”你是对的“，而只能说是可能正确。这种限定句子”真假“的语气，一共有 3 种：</p><ul><li>推测：表示对于命题的不确定（可能学名不叫这个，但是我觉得这个恰当）</li><li>虚拟：表示一种不可能的情况，用说反话的方式来表达意思</li><li>祈使：表示希望能成真，但尚未实现</li></ul><h4 id="2-4-3-推测"><a href="#2-4-3-推测" class="headerlink" title="2.4.3 推测"></a>2.4.3 推测</h4><p>推测语句表示的是一种”不确定“的语气，它需要加上情态动词（must、should、will/would、can/could、may/might 等）来完成。</p><blockquote><p>You are right. （你是对的。）</p><p>You may be right. （你可能是对的。）</p></blockquote><p>需要注意的是，would，could，might 虽然是 will，can，may 的过去时，但是我们并不能用它们表示”过去推测“，他们只是表示一种相对于现在时更加不确定的语气：</p><blockquote><p>The doctor thinks it <strong>can be</strong> AIDS. （医生认为可能是艾滋病。）</p><p>It <strong>could be</strong> anything—AIDS or a common cold. （还看不出来是什么病——可能是艾滋病，也可能是感冒。）</p></blockquote><p>这种现象导致按照过去的逻辑，推测语气是只有现在时的，没有时态变化的。因为在过去时所需要的 would/could/might 都被当成了一种“更小概率”的语义，而将来时所需要的 will，也被当成了一种“概率”的语义。</p><p>但是显然推测语气是需要和时态组合的，它们拓展了原本的规则，总结如下：</p><div class="table-container"><table><thead><tr><th>时态</th><th>用法</th><th>例子</th></tr></thead><tbody><tr><td>过去时</td><td>情态动词 + have + Ved</td><td>It <strong>may have rained</strong> a little last night.</td></tr><tr><td>现在时</td><td>情态动词 + V</td><td>It <strong>may rain</strong> any minute now.</td></tr><tr><td>将来时</td><td>情态动词 + V</td><td>It <strong>may rain</strong> tomorrow.</td></tr></tbody></table></div><p>总的来说就是用完成式表达过去时，而用普通式表达现在和将来。</p><h4 id="2-4-4-虚拟"><a href="#2-4-4-虚拟" class="headerlink" title="2.4.4 虚拟"></a>2.4.4 虚拟</h4><p>虚拟语气在描述一种“假如”语义，是一种复句语义，即“假如……，那么就……”。首先声明，这里说的“假如”，并不是全部的“条件句”，而是条件句的一类。有些条件句真的是在描述一种命题推导关系，比如说</p><blockquote><p>If you let go, the apple will fall.</p></blockquote><p>这是一个地球上的客观事实，只要你松手（条件），苹果就会掉落（结果），没有人限制你是否松手。但是还有一种条件句，它是一种“假如”的语气，也就是“假如，我说得是假如啊”，这是一个不可能发生的条件：</p><blockquote><p> If I were you, I wouldn’t do it. </p></blockquote><p>显然“我不是你”，所以条件并不成立。这是在说反话。还有一种翻译是“万一”：</p><blockquote><p>If an asteroid <strong>should hit</strong> the earth, man <strong>could die</strong> out.</p></blockquote><p>将其翻译成“万一小行星撞击地球了，那么人们可能就灭绝了”也是非常得体的。</p><p>在介绍具体的虚拟语气语法现象之前，我想先理清一下条件句的结构，其实只有两个部分，一个是条件句，一个是结论句。以此句举例：</p><blockquote><p> If I were you, I wouldn’t do it. </p></blockquote><p>其中“如果我是你”这是条件句，而“我不会做这件事”是结论句。那么为了达成这种“虚拟语气”，是条件句需要调整，还是结论句需要调整？答案是基本上都需要调整，或者严谨的说：<strong>无论条件句还是结论句是涉及了“虚拟，假如”的语义，那么就都需要变化，而条件句和结论句的变化方式是不同的</strong>。变化方式总结如下：</p><div class="table-container"><table><thead><tr><th>时态</th><th>条件句（从句）</th><th>结论句（主句）</th></tr></thead><tbody><tr><td>过去时</td><td>had + Ved</td><td>would/could /might + have + Ved</td></tr><tr><td>现在时</td><td>Ved（其中如果是 be 要变成 were）</td><td>would/could /might + V</td></tr><tr><td>将来时</td><td>should/were to + V</td><td>would/could /might + V</td></tr></tbody></table></div><p>在传统语法中，会归纳出“时态回退”现象，也就是“过去时变成过去完成时，现在时变成过去时，将来时情态动词变成 should”，可以看到这种规律即使用在条件句上，也会显得牵强，而用在结论句上，则是完全不符合。所以我主张直接记忆这个表格。</p><p>需要注意，在实际使用中，存在“时态错综”现象，也就是说，可以存在一个句子，具有过去时的条件句，而具有现在时的结论句，如下所示：</p><blockquote><p>If I <strong>had studied</strong> harder <strong>in school</strong>（过去）, I <strong>could qualify</strong> for the job <strong>now</strong>（现在）.</p></blockquote><p>此外，甚至“真假”也可以错综，也就是一个真实的条件句搭配一个虚拟语气的结论句，比如说：</p><blockquote><p>I <strong>could have contributed</strong> to the fund drive then（虚拟，我本来想捐钱但是并没有捐）, only that I <strong>didn’t have</strong> any money with me（真实，我真的没有带钱）.</p></blockquote><p>最后补充一下真实条件句的时态变化，其实只有一点，就是真实条件句一般都是“主将从现”的。这是因为如果条件发生在过去，那么结论一般已经发生了，那么就不构成这种“条件推导”关系了（硬币落下后再猜正反没有意义了，坍缩了）。而条件如果发生在将来，那么也没啥意义，因为对将来一无所知，我们能做的是就是根据现在的条件，判断未来发生的事情。</p><h4 id="2-4-5-祈使"><a href="#2-4-5-祈使" class="headerlink" title="2.4.5 祈使"></a>2.4.5 祈使</h4><p>祈使语气最简单了，就是直接用动词原型，然后省略主语。</p><p>还有一种间接祈使句，就是祈使句的命令方并非听着，而是第三者，这样就会呈现这样的例子：</p><blockquote><p>The court demands that the witness <strong>leave</strong> the courtroom. </p><p>There is a strong expectation among the public that someone <strong>take</strong> responsibility for the disaster.</p></blockquote><p>我很想积累这些固定用法，但是时间有些紧张。按照旋老师的说法，固定用法有很多，最重要的是看重祈使语气所强调的“望能成真，但尚未实现”。</p><h3 id="3-冠词"><a href="#3-冠词" class="headerlink" title="3. 冠词"></a>3. 冠词</h3><p>冠词 a(n) 可以视为 one 的弱化（reduction）结果。也就是说，a(n) 就代表 one 的意思，只是语气比较弱。</p><p>the 可视为 that 或 those 的弱化形式。而 that 或 those 是指示形容词，有明确的指示功能。所以定冠词 the 也可以用同样的角度来了解：凡是上下文中有明指或暗示时，也就是有“那个”的指示功能时，便要用定冠词 the。</p><hr><h2 id="三、复合句及其化简"><a href="#三、复合句及其化简" class="headerlink" title="三、复合句及其化简"></a>三、复合句及其化简</h2><p>TODO</p>]]></content>
    
    
    <summary type="html">&lt;h2 id=&quot;一、总论&quot;&gt;&lt;a href=&quot;#一、总论&quot; class=&quot;headerlink&quot; title=&quot;一、总论&quot;&gt;&lt;/a&gt;一、总论&lt;/h2&gt;&lt;p&gt;这篇文章是对于&lt;a href=&quot;https://llwslc.github.io/grammar-club/&quot;&gt;旋元佑语法俱乐部&lt;/a&gt;的一个注释总结。行文思路基本上和这本电子书的章节保持一致。&lt;/p&gt;
&lt;p&gt;语法是对于语言的规律总结，这类似于物理是对于客观世界的规律总结。不过应当注意到，即使掌握了语法，也并不能短时间内提高英语水平，因为在语法的指导下使用语言，同样是一个需要习惯和精进的过程。这就像掌握了物理定律和物理满分之间依然存在很大差距一样。&lt;/p&gt;
&lt;p&gt;旋老师的语法和我中学学过的语法并不一样，旋老师倾向于建立一种“大一统”的理论来解释所有的语言现象，而中学语法则更加繁杂和缺少一致性。在加上我这次学习语法已经是大四，在逻辑思维上相比于中学已经有了很大的进步。所以总的来说，语法更加“讲理”了。&lt;/p&gt;
&lt;p&gt;但是旋氏语法的缺点我个人感觉有两个，一个是因为过于“统一”，导致需要引入一堆与中学语法似是而非的概念，这些概念类似于物理学上的“波粒二象性”一样，对中学语法是一种挑战；并且因为旋老师是台湾人的缘故，所以在表达习惯和方式上也与大陆存在一定的差异（也就是他写的中文有点难看懂）。另一个是旋老师在建立了“统一”的理论后，并没有充分利用这些规律推导出中学语法甚至是其他中学语法难以推导的其他语言现象。&lt;/p&gt;</summary>
    
    
    
    <category term="沟通交流" scheme="https://thysrael.github.io/categories/%E6%B2%9F%E9%80%9A%E4%BA%A4%E6%B5%81/"/>
    
    
    <category term="知识总结" scheme="https://thysrael.github.io/tags/%E7%9F%A5%E8%AF%86%E6%80%BB%E7%BB%93/"/>
    
    <category term="S8课上" scheme="https://thysrael.github.io/tags/S8%E8%AF%BE%E4%B8%8A/"/>
    
    <category term="沟通交流" scheme="https://thysrael.github.io/tags/%E6%B2%9F%E9%80%9A%E4%BA%A4%E6%B5%81/"/>
    
  </entry>
  
  <entry>
    <title>吃喝玩乐-流浪天津</title>
    <link href="https://thysrael.github.io/posts/cb9fcc81/"/>
    <id>https://thysrael.github.io/posts/cb9fcc81/</id>
    <published>2024-06-20T12:11:21.000Z</published>
    <updated>2024-10-17T06:35:02.120Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>对于“死猪不怕开水烫”这句话，似乎每个人的理解是不同的：</p><p>有的人是“小太爷告诉你，咱得是猪，可不是那鸡鸭的便宜玩意儿”；</p><p>有的人是“跟嫩么说，别听前面的猪渍歪，介玩意儿就没带怕的”；</p><p>还有的人是“俺得用开水，不是开水可不瞻”。</p><p>但是很少有人想过”为什么我是死猪，为什么要用开水烫我“。</p></blockquote><h2 id="一、观感"><a href="#一、观感" class="headerlink" title="一、观感"></a>一、观感</h2><p>天津真的很像十年前的石家庄。我指的不是发展程度，而是市容市貌。在街上随处可见将背心挽到胸口的大爷，拿着火钳子捅咕炉子，炭火上是一两只烤鸡翅或者烤虾。旁边的饭店有踩着趿拉板儿的姐姐拎着水管往街上滋着黑水。一个个脸上都是泥渍和晒疮的小孩子，将砖头揉碎了倒到书包里，两三个人拥着一辆比人都高的华丽的变速自行车，向着挤满三轮的岔路口奔去。而石家庄，可能是因为我不常回家的缘故，早已昏沉沉地睡去。</p><p>这是西北角的景象，而在五大道，我见过了最新奇的建筑群，洋房子里长出了商户，丝毫没有嫁接或者“捏到一起”的感觉。秃头或者蓬蓬头的胖大妈从一个漂亮的西式木头窗后探出头，这如果不是发生在天津，又能发生在哪里？</p><p>来到天津以后，我才感觉到，似乎我的一部分是在天津的。这个地方没有小红书上说得那么俏皮或者幽默，而更像是我小时候读到的《神鞭》一样，这里的人为了某种传统的生活方式，而憋着一口气，他们迫不及待地向别人证明，更向自己证明，我们这么活没有错。</p><p>在华北平原上，人们惧怕没有“活儿”，因为没活儿才意味着真正的死去。</p><hr><h2 id="二、地理"><a href="#二、地理" class="headerlink" title="二、地理"></a>二、地理</h2><p>天津地理变化似乎有些剧烈，很多地区都在反复地划入河北，或者从河北划出（甚至建国后天津还成为过河北省的省会，甚至反复省会和直辖反复横跳）。关于天津建国后地理范围的具体变化，可以参考<a href="https://www.douyin.com/zhuanti/7283922349697697850">这里</a>。</p><p><img src="/posts/cb9fcc81/image-20240702110021985.png" alt="image-20240702110021985"></p><p>从历史角度分析，其实天津可以被分为两个“源”，一个是沿海的塘沽，另一个是不沿海，而是在海河三岔口附近的天津城。也就是上图东侧的部分和西侧的部分。这两个部分其实是承担了不同的城市职责。塘沽非常好理解，他临近渤海湾，是天然的海运港口。不好理解的是天津城，因为它不沿海，为什么要在内陆发展出这样的一个城市。</p><p><img src="/posts/cb9fcc81/v2-52a77dce617dbf748a04beba72673f2a_720w.webp" alt="img"></p><p>这有两个原因：自然原因和经济原因。自然原因是黄河改道与渤海海侵。现在的黄河是从山东入海，但是黄河泛滥的时候，会导致决堤更改河道，有的时候是会从天津入海的。黄河从天津入海携带的大量泥沙让天津形成了沿海的冲积平原，也就是塘沽地区，但是这片地区过于低洼，土质松软，很容易被渤海淹没，所以不适合建立大城市。而稍微靠近内陆的天津城。则没有这种担忧。</p><p><img src="/posts/cb9fcc81/703.png" alt="img"></p><p>经济原因是除了海运，天津城还承担了河运的职责。天津城位于海河、滹沱河和潞河的三岔口处，同时还有京杭大运河的的永济渠也在此处交汇，在这个位置围绕直沽修建天津城就很合理了。</p><p>到了近代，天津的行政规划不断扩大，原本的塘沽变成了滨海新区，而天津城逐渐成了一个卷心菜中菜心的部分，别周围的郊县包围，形成了“市内六区，四郊五县”的格局，其中：</p><ul><li>市内六区： 河北，南开，河东，红桥，河西，和平</li><li>四郊： 津南，北辰，东里，西青</li><li>五县： 蓟县，武清，宝坻，宁和，静海</li></ul><p>最后放一张现在天津的行政规划：</p><p><img src="/posts/cb9fcc81/18963.jpg" alt="天津市地图简图"></p><p>或者这张更形象一些：</p><p><img src="/posts/cb9fcc81/v2-b7476ae920318e6cae7159f9f314cf59_720w.webp" alt=""></p><p>而从旅游角度来说，天津的景点集中于市内六区（如果不去海边玩的话），其实是很小的一片地方，我在知乎找到这样一个评论形容市内六区，大概可以概括一下天津的风土人情：</p><blockquote><p>因为每个区人的来源不同，河东区是本土漕运人，南开区是城里人，红桥区是回族人，和平区是外地人，河西是庄家人，河北是铁路人。然后各个区领地意识很强，你也听说过天津媳妇不外嫁，跨区算外嫁吧。</p><p>市内六区打的不可开交，在他们眼里，郊区不配拥有姓名。“出了和平都是郊区”，别说四郊五县了，就连市内其他五区都看不上。</p><p>市里居民对于四郊五县人排斥 ，本质上是城市文明市民文化对于传统农业文明的一种排斥。</p><p>市里的和四郊五县本来就不是一个祖宗，市里的是江淮浙闽晋这五省移民后裔，主要从事工商业，是比较完整的市民社会模式。而四郊五县则是冀鲁民系后裔，主要从事农业，是传统的农业社会模式。</p><p>市区因为骨子里面是移民后代，家庭结构更加原子化，日常生活中更加遵守规则，而四郊五县是冀鲁农民后代，家庭关系更加紧密，更喜欢走人际关系。市区刀子嘴但是内心很包容，四郊五县看似嘴不如市区厉害，但是骨子里面更加排外。</p><p>像武清宝坻宁河汉沽蓟县四县一区是上世纪六七十年代划给天津的，这些地方之前一直是跟着北京或者唐山混的，对于天津没有什么认同感，反而对天津认同度高的沧州划给了河北省，德州归了山东省。</p></blockquote><p>这次旅行因为被学校 push 得太紧了，所以并没有好好逛天津的旅游景点，只是将想吃的天津美食吃了吃，所以下文只有关于美食的介绍，没有太多关于景点的介绍。</p><hr><h2 id="三、美食"><a href="#三、美食" class="headerlink" title="三、美食"></a>三、美食</h2><h3 id="3-1-昱德来"><a href="#3-1-昱德来" class="headerlink" title="3.1 昱德来"></a>3.1 昱德来</h3><p>昱德来并不是小红书或者知乎等攻略里推荐的天津传统菜馆，那些传统菜馆都在市内的东北侧，而我住在了鼓楼（也就是市中心），所以就找了宾馆附近的昱德来，发现味道还不错。这可能是因为天津菜非常传统，并没有很多的外地特色，不同的菜馆之间不会有明显差异导致的。</p><p>我最爱吃的是鸭卷，这可以说是我吃过最好吃的鸭子的烹饪方式。鸭子肉被撕成细丝，在保留肥美汁水的同时又避免了鸭肉柴硬的口感。鸭肉被鸡蛋皮和豆皮裹着下锅炸，要比北京烤鸭用荷叶饼或者面皮的方式融合得更好，更能保留鸭香。</p><p><img src="/posts/cb9fcc81/IMG20240616114751.jpg" alt=""></p><p>鲜虾茄盒是酸甜口的，做得中规中矩，并没有非常惊艳我。其实我一开始真的最想吃的就是这个，因为它有非常闪亮光泽的芡，看着就很下饭。实际吃上去吧，有点糊嗓子。</p><p><img src="/posts/cb9fcc81/IMG20240616114337.jpg" alt=""></p><p>我还吃了老爆三（也就是传统爆三样），确实处理得不错，没有什么脏器味儿或者腥膻味儿，但是依然不好吃。</p><h3 id="3-2-利德顺小老饭店"><a href="#3-2-利德顺小老饭店" class="headerlink" title="3.2 利德顺小老饭店"></a>3.2 利德顺小老饭店</h3><p>这家是我在西北角逛街时遇到的，是传统回民馆子，人非常火爆。我听旁边一个食客大哥说是天津非常好吃的一家传统菜馆，但是因为从不上美团或者大众点评，所以曝光率不是很高。</p><p>我个人感觉确实我吃到的菜品堪称惊艳！无论是从好吃的角度，还是从特色的角度来看。但是服务员真的好凶啊，我进了饭店也不领我去饭桌（人是真的多），好不容易坐下来也没人点菜，我去找前台就说让我等着。点菜的时候来了一个说着很重天津话的牛眼睛大爷，看我点了一个面筋，然后扯着嗓子嘟嘟囔囔（真的是这样，又大声又小声的）说太多油了，我吃不惯。把我吓得差点都直接不吃了。</p><p>虾仁独面筋真的超级好吃，面筋被完全浸泡在一个超绝的油里，那个油最少有白花椒油，菜籽油和椒麻油三种口感。面筋浸入在里面，又香又有嚼劲，而且油似乎有隔热的作用，当你将面筋吃进去的时候。面筋里被油阻隔的温度会在口腔里炸开，类似于在口腔里进行油泼面的淋油操作，那种蛋白质瞬间变性的口感，真的是绝了！这道菜就是我心中天津最好吃的菜！</p><p><img src="/posts/cb9fcc81/IMG20240616192134.jpg" alt=""></p><p>我去的时候就只有自己一个人，怕吃不完就点了这一份菜，但是白嘴吃似乎有些寡淡，就要了一个主食，一个服务员给我推荐了回头，我一看好贵啊，独面筋 40，这个东西也 40，但是我怕那个牛眼睛大爷又来，所以就点了：</p><p><img src="/posts/cb9fcc81/IMG20240616195952.jpg" alt=""></p><p>结果等了一个小时才上，这个东西其实要我说，非常有特色，而且不难吃，它类似于牛肉馅饼或者牛肉火烧，不同的是他的面没有刷的油更少，面皮更薄，烤制的时间更长。吃起来的口感更像是饼干而非饼，甚至让我有种吃比萨的错觉。</p><h3 id="3-3-西北角"><a href="#3-3-西北角" class="headerlink" title="3.3 西北角"></a>3.3 西北角</h3><p>西北角在旅游攻略上被传成了一个网红早餐街，我还以为会跟北京的南锣鼓巷一样，都是骗外地人的“塑料美食”呢。但是实际上这里确实非常生活化，东西也不贵，有很多居民区的大爷大妈都来这里吃。我来这里吃了两天，基本上把这面墙上的东西都吃了个遍：</p><p><img src="/posts/cb9fcc81/IMG20240617094212.jpg" alt=""></p><p>我早餐都是在利民餐厅吃的，主要是大夏天的，能有个能坐下吃饭还有空调的地方实在是太爽了：</p><p><img src="/posts/cb9fcc81/IMG20240617092951.jpg" alt=""></p><p>煎饼真的是太失望了，我听了那么久的天津相声，听了那么久天津人对于外地煎饼馃子的嘲弄，但是我自己吃的时候，真的味道是一样的，甚至天津的煎饼还更难以下咽。我小时候从书上看到过枣红色的油条，结果我转了很多的摊子，发现卖的都是黄色的油条，而且还很难吃（另外说一嘴，还是永和豆浆的油条最好吃，写得时候馋死我了），就像一个简单的面棍一样。</p><p><img src="/posts/cb9fcc81/IMG20240618091812.jpg" alt=""></p><p>嘎巴才倒是挺好吃的，嘎巴菜是面片片上面淋上麻酱腐乳和某种特制的黏糊糊的汤汁，是咸口的，我觉得挺香的，而且面片的口感哏啾啾的，不像煎饼那么浮囊。</p><p><img src="/posts/cb9fcc81/IMG20240617091139-17199124363434.jpg" alt=""></p><p>面茶跟嘎巴菜的味道差不多，真的像《俗世奇人》里描述的一样，先加半碗茶汤，再加一层芝麻，然后再加半碗茶汤，再撒一层芝麻。茶汤并不是固体，而更像是芝麻糊那样的固液交融的状态。我打算先攉拢攉拢再吃，但是旁边的天津大姨教给我不要搅和，而是要拿勺子溜着碗沿儿㧟着吃。</p><p><img src="/posts/cb9fcc81/IMG20240618092023.jpg" alt=""></p><p>卷圈的腐乳味、油渣味儿和豆芽菜的水汽味儿交织在一起，形成了一种神秘的味觉体验，这种味道甚至都有些刺鼻了（腐乳有点发酸）：</p><p><img src="/posts/cb9fcc81/IMG20240617102724.jpg" alt=""></p><p>在西北角还常见熟梨膏，但是其实和梨这种水果没啥关系，我查了查，据说是“熟哩”的音译。其做法上很类似陕西的镜糕，但是要更加难吃一些，酱料𫫇甜𫫇甜的，而糯米过于粉了，这可能是由于它并不是在一个像蒸锅一样的密闭容器，而是在一个小碗里制作的。</p><h3 id="3-4-起士林"><a href="#3-4-起士林" class="headerlink" title="3.4 起士林"></a>3.4 起士林</h3><p>非常有名的西餐馆，我觉得更难得是价格还算合理，而且服务员态度很好（感觉五大道这边市井气少一些，更加工业城市了一些）。可惜的是，这里的大列巴是要钱的（《师父》骗人！）：</p><p><img src="/posts/cb9fcc81/IMG20240618103345.jpg" alt=""></p><p>店内的装潢有一种中西混合的感觉，西式的主体和中式的繁复装饰：</p><p><img src="/posts/cb9fcc81/IMG20240618105955.jpg" alt=""></p><p>我在想耿良辰是不是原本比武赢了后就是要在这张楼梯口的大桌子上吃饭：</p><p><img src="/posts/cb9fcc81/IMG20240618110000.jpg" alt=""></p><p>这个吧台也很漂亮：</p><p><img src="/posts/cb9fcc81/IMG20240618110822.jpg" alt=""></p><p>坐下来窗外是一个外国风情的音乐厅：</p><p><img src="/posts/cb9fcc81/IMG20240618111449.jpg" alt=""></p><p>我看门口介绍说是德国餐厅，居然意外的好吃（什么刻板印象，我该死），红汤有很浓郁的酵香，而且还不酸𫫇：</p><p><img src="/posts/cb9fcc81/IMG20240618110549.jpg" alt=""></p><p>奶油芝士杂拌芝士量很足，拉丝很明显，各种肉类都很好吃：</p><p><img src="/posts/cb9fcc81/IMG20240618111729.jpg" alt=""></p><p>我平时并不喝酒，不知道是不是心理因素，我觉得这杯金汤力非常清冽，没有酸锈味儿：</p><p><img src="/posts/cb9fcc81/IMG20240618112918-17199229470811.jpg" style="zoom:25%;"></p>]]></content>
    
    
    <summary type="html">&lt;blockquote&gt;
&lt;p&gt;对于“死猪不怕开水烫”这句话，似乎每个人的理解是不同的：&lt;/p&gt;
&lt;p&gt;有的人是“小太爷告诉你，咱得是猪，可不是那鸡鸭的便宜玩意儿”；&lt;/p&gt;
&lt;p&gt;有的人是“跟嫩么说，别听前面的猪渍歪，介玩意儿就没带怕的”；&lt;/p&gt;
&lt;p&gt;还有的人是“俺得用开水，不是开水可不瞻”。&lt;/p&gt;
&lt;p&gt;但是很少有人想过”为什么我是死猪，为什么要用开水烫我“。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&quot;一、观感&quot;&gt;&lt;a href=&quot;#一、观感&quot; class=&quot;headerlink&quot; title=&quot;一、观感&quot;&gt;&lt;/a&gt;一、观感&lt;/h2&gt;&lt;p&gt;天津真的很像十年前的石家庄。我指的不是发展程度，而是市容市貌。在街上随处可见将背心挽到胸口的大爷，拿着火钳子捅咕炉子，炭火上是一两只烤鸡翅或者烤虾。旁边的饭店有踩着趿拉板儿的姐姐拎着水管往街上滋着黑水。一个个脸上都是泥渍和晒疮的小孩子，将砖头揉碎了倒到书包里，两三个人拥着一辆比人都高的华丽的变速自行车，向着挤满三轮的岔路口奔去。而石家庄，可能是因为我不常回家的缘故，早已昏沉沉地睡去。&lt;/p&gt;
&lt;p&gt;这是西北角的景象，而在五大道，我见过了最新奇的建筑群，洋房子里长出了商户，丝毫没有嫁接或者“捏到一起”的感觉。秃头或者蓬蓬头的胖大妈从一个漂亮的西式木头窗后探出头，这如果不是发生在天津，又能发生在哪里？&lt;/p&gt;
&lt;p&gt;来到天津以后，我才感觉到，似乎我的一部分是在天津的。这个地方没有小红书上说得那么俏皮或者幽默，而更像是我小时候读到的《神鞭》一样，这里的人为了某种传统的生活方式，而憋着一口气，他们迫不及待地向别人证明，更向自己证明，我们这么活没有错。&lt;/p&gt;</summary>
    
    
    
    <category term="吃喝玩乐" scheme="https://thysrael.github.io/categories/%E5%90%83%E5%96%9D%E7%8E%A9%E4%B9%90/"/>
    
    
    <category term="S8课上" scheme="https://thysrael.github.io/tags/S8%E8%AF%BE%E4%B8%8A/"/>
    
    <category term="吃喝玩乐" scheme="https://thysrael.github.io/tags/%E5%90%83%E5%96%9D%E7%8E%A9%E4%B9%90/"/>
    
    <category term="流浪天津" scheme="https://thysrael.github.io/tags/%E6%B5%81%E6%B5%AA%E5%A4%A9%E6%B4%A5/"/>
    
  </entry>
  
  <entry>
    <title>自由王国-字体</title>
    <link href="https://thysrael.github.io/posts/6a65902d/"/>
    <id>https://thysrael.github.io/posts/6a65902d/</id>
    <published>2024-06-10T08:08:50.000Z</published>
    <updated>2024-10-17T06:35:03.533Z</updated>
    
    <content type="html"><![CDATA[<h2 id="一、编码"><a href="#一、编码" class="headerlink" title="一、编码"></a>一、编码</h2><p>此章的目的是弄清楚 ASCII, GBK, Unicode, UTF-8 编码的区别，大部分知识都来源于<a href="https://www.ruanyifeng.com/blog/2007/10/ascii_unicode_and_utf-8.html">这里</a>。所以我只是简单转述一下：</p><p>ASCII 是最为古老的编码方式，它指的是用一个字节也就是 8 bit 完成编码，实际上只用了 7 bit ，最高位的值衡为 0 （这也成了其他编码方式兼容 ASCII 的一个重要抓手）。也就是说，ASCII 只能编码 2<sup>7</sup> = 128 个文字，这对英文这种只有 26 个字母的语言体系是足够的。</p><p>但是 ASCII 并不能满足很多类似英语的语言体系，比如说 <code>é, ג</code> 这种字符都是原有的 ASCII 所没有的，但是幸运的是，很多语言的字符数本来就不多，比如俄语是 33 个，而法语是基础的 26 个英文字母加音标。所以这些语言同样可以用一个字节进行编码，英语字符占据了 <code>0 ~ 127</code> ，它们就占据了 <code>128 ~ 255</code> 。这样的缺点就是不同国家的 <code>128 ~ 255</code> 表示不同的字母，彼此之间并不兼容。</p><p>但是像汉语这样的语言就没有那么轻松了，他们就算占据了 <code>128 ~ 255</code> 位，也最多增加 128 个字符，这对于有 10 万个字符的汉语来说是杯水车薪。所以中国就开发了 GB2312 编码系统，后来演变成了 GBK 系统。总的来说，就是采用两个 <code>128 ~ 255</code> 的字节来表示一个汉字（应该是差不多），这样的话大约可以表示 2 万多个汉字，但是这样其实有一些生僻一些的字也是无法表示的。</p><p>这些各个国家私自拓展 ASCII 编码的行为导致了各种语言的编码系统都不兼容，随着互联网的兴起，一套兼容的编码系统呼之欲出，也就是 Unicode ，它用 32bit 表示一个符号，那么就可以表示 2 亿多个符号，这足够容纳人类的所有语言，可以在<a href="https://symbl.cc/en/unicode-table/">这里</a>查询。Unicode 编码通常有一个 <code>U+</code> 的前缀。但是随着而来的问题是，原本需要用 8bit 表示的英文字母，现在需要用 32bit 了，这显然不是一个好事情。</p><p>为了权衡数据大小和兼容性，以 Unicode 为编码基础，人们提出了 UTF-8, UTF-16, UTF-32 等具体的编码方案。以 UTF-8 为例，它使用变长编码，压缩了原本 32bit 的字符。在 UTF-8 中，字符可能长度是 8, 16, 32bit ，这样兼顾了大小和兼容性。UTF-16 和 UTF-32 则都是定长编码，UTF-16 适用于需要处理大量双字节字符（如亚洲文字）的场景。UTF-32 则适用于需要处理所有 Unicode 字符，且对内存空间要求较高的情况。</p><p>UTF-8 看似兼顾了优势，但是不定长的特性使得解码效率降低，而且这使得像 C++ 这样的语言，字符数组的概念变得容易混淆，当我说 <code>s[3]</code> 时，很难确定它是一个特定的字符，还只是字符的某一部分。</p><hr><h2 id="二、渲染"><a href="#二、渲染" class="headerlink" title="二、渲染"></a>二、渲染</h2><h3 id="2-1-点阵字体"><a href="#2-1-点阵字体" class="headerlink" title="2.1 点阵字体"></a>2.1 点阵字体</h3><p>在最开始的时候，字体是用点阵（bitmap）的方式描述的，也就是这个字体记录了不同大小（字号）的字符的像素的排列方式，非常的朴素和直观。但是这种方式是的缺点在于，不同字号的字都分别需要记录一次像素的排列方式，所以如果恰好这个字号没有记录，就非常尴尬了（不可能每个字号都有），只能用用相邻的有记录的字号进行推算。而且这种方式的也不适合进行一些数学相关的处理（比如加粗、倾斜、缩放和旋转）。</p><h3 id="2-2-矢量字体"><a href="#2-2-矢量字体" class="headerlink" title="2.2 矢量字体"></a>2.2 矢量字体</h3><p>为了解决这个问题，人们提出了矢量字体，这种字体不再记录具体的像素排列方式，而是用数学上的贝塞尔曲线在一个虚拟的网格（类似于坐标系，但是并不连续）描述字体。这种方式解决了点阵字体的缺点，如下所示：</p><p><img src="/posts/6a65902d/clipboard-20240610T153703.png" alt=""></p><p>最开始的时候，是 Adobe 公司最先开发了 Type1 矢量字体格式（后缀名为 <code>pfb</code>），但是 Adobe 太贵了，所以 MS 和 Apple 联手开发新的矢量字体，但是只有 Apple 开发成功了，它的作品是 TrueType（后缀名为 <code>ttf</code>，也就是 true type format）。后来 MS 又和 Adobe 公司开发出了 OpenType（后缀名为 <code>otf</code>，也就是 open type format），这种字体也被称为 Type2。除此之外，还有为 web 而生的字体标准 <code>woff</code> 和 <code>woff2</code>，它们的优势在于压缩率高。我们还常见一种后缀名为 <code>ttc</code> 的文件，它的全称是 TrueType Collection，是在一单独文件结构中包含多种字体，以便更有效地共享轮廓数据，当多种字体共享同一笔画时，TTC 技术可有效地减小字体文件的大小。</p><p>总的来说，Type1 字体基本上已经不常见了，而 OTF 因为吸取了 TTF 的经验，所以更为先进，但是 TTF 具有先发优势，兼容性更好。不过两者的差别并不明显。</p><h3 id="2-3-屏幕"><a href="#2-3-屏幕" class="headerlink" title="2.3 屏幕"></a>2.3 屏幕</h3><p>这里插叙一段关于屏幕的介绍。我个人的理解，屏幕是一块布满像素点的网格板子，其核心在于<strong>分辨率</strong>，也就是屏幕的实际大小和其上的像素点的关系。我们在字体设置时常常有诸多单位，记录如下：</p><ul><li>pt：译作“磅”，这是一个物理单位，是 1/72 英寸的。直观来看，我个人常用 14pt 左右的字体写代码，这样的我 15 寸的电脑大约能容纳 40 行。这个字体对于写代码来说差不多，但是对于纸质阅读来说，是有一些大的。之所以我们需要用磅，是因为人眼睛直观感受到的是物理尺寸，无论屏幕的像素是多少，一个过小 pt 的字，总是不容易识别的。</li><li>px：译作“像素”，这是一个显示单位，也就是 1px 就指的是一个像素的宽度。当字体物理高度（也就是 pt 固定）固定的时候，像素越多，字体的边缘就会越圆润细腻。</li><li>ppi：pixel per inch，可以被视为“分辨率”，还有一个类似的单位叫作 dpi，dpi 用于衡量打印物上每英寸的点数密度，而 ppi 用于屏幕，含义上没有过大区别。其实严格上说，ppi 是决定屏幕是否细腻的核心。</li><li>em：这个就游离于上述三个概念之外了，它指的是一个字母 <code>e</code> 的宽度。</li></ul><p>我们有如下公式：</p><script type="math/tex; mode=display">1 px = \frac{72}{ppi} pt</script><p>考虑到 pt 是物理实际长度不可变，ppi 是屏幕特性不可变，所以基本上这个公式除了计算像素宽度外，似乎并没有作用。而实际上并不是这样的，因为屏幕上的软件其实是并不知道物理长度的，它们总不能从屏幕里伸出一只手来拿个尺子量一量字体高度是不是真的是 14pt。它们是根据 ppi 来计算字体高度的。也就是说 ppi 作为一个参数传入给了程序。</p><p>这种方式就衍生了一种新的调节字体高度的方式，除了传统的修改字体字号，现在还可以修改 ppi，将 ppi 改大，就会导致字体高度也变大。但是需要强调的是，此时的 ppi 已经不再是屏幕的一个物理参数了，而变成了一个程序渲染的参数，可以脱离实际意义。</p><p>那么为什么在可以直接调节字号的情况下，还修改 ppi 呢？这是因为屏幕上不只有文字，还有许多其他的 UI 组件，修改 PPI 可以统一将他们一起放大缩小。至于为啥要修改它们，这可能是因为人眼具有“近大远小”的机制，所以离人较远的显示器，是需要通过放大来保证落入眼睛里时是正常大小的。</p><h3 id="2-3-光栅化"><a href="#2-3-光栅化" class="headerlink" title="2.3 光栅化"></a>2.3 光栅化</h3><p>当然矢量字体也并非完全碾压点阵字体，点阵字体展示在屏幕上是非常直观的，基本上像素是怎么被记录的，就怎么显示到屏幕上就可以了（这个过程称之为渲染）。但是矢量字体想要映射到一个屏幕像素网格上，那么就会发生一个“从连续到离散”的过程了，这种渲染过程被称为光栅化，如图所示：</p><p><img src="/posts/6a65902d/fig3-2-1.png" alt="figure_3"></p><p>从上图就可以看出，光栅化如果不加优化，直接映射，是非常丑陋的。而点阵字体因为开发时面对的就是网格，反而设计师不会设计出粗糙丑陋的字体。那么光栅化具体有哪些优化呢？</p><p>为了解决渲染后的字体有一种机器渲染的粗糙和死板感的问题，比如说下面的 e 这个字符，顶部只有一个像素：</p><p><img src="/posts/6a65902d/IF3.png" alt="figure_4"></p><p>人们发明了<strong>字型微调（hinting）</strong>，它指的是通过稍微调整字形（一般是倾斜）的方式，来达到一种更加“拟人”的渲染方式，当然如果过度使用这种方法，也会导致字形发生严重的扭曲。</p><p><img src="/posts/6a65902d/IF4.png" alt="figure_5"></p><p><strong>抗锯齿（anti-aliasing）</strong>则是另一种优化手段，他指的是当像素过少的时候，很容易出现像素点之间的方块块，就会形成鳞次栉比的“锯齿”，这个时候就很丑陋，那么我们可以将边缘的像素点改成灰色（原本是黑色或者白色），然后就可以模糊了原本的锯齿。这种方法也称为<strong>灰度渲染（Grayscale rendering）</strong>。经过抗锯齿化的字体的缺点是边缘可能有些“模糊”。</p><p>还有一种类似的方法叫作<strong>亚像素渲染（Subpixel rendering）</strong>，它利用了现行的 RGB 显示屏的像素点其实是 3 个分别显示红绿蓝颜色的“亚像素”拼成的，所以可以只显示三分之一个像素或者三分之二个像素，这样分辨率相当于在横向上提高了 3 倍。但是除了边缘模糊的缺点外，这种方法还会造成某种“腻感”，这是因为边缘出现了颜色。</p><p>抗锯齿和亚像素渲染的概念如下图所示：</p><p><img src="/posts/6a65902d/aaaa.png" alt="figure_6"></p><hr><h2 id="三、字族"><a href="#三、字族" class="headerlink" title="三、字族"></a>三、字族</h2><h3 id="3-1-风格"><a href="#3-1-风格" class="headerlink" title="3.1 风格"></a>3.1 风格</h3><p>评价一个字体的风格，最为简单的有 3 个标准：</p><ol><li>有衬线还是无衬线：Serif or Sans-serif</li><li>等宽还是变宽：Monospace or Proportional</li><li>印刷体还是手写体：Gothic or Script</li></ol><p>在英文中的区别我就不细说了，主要讲这些概念的“中国化”。无衬线的字体一般用于标题等醒目的地方，所以对应汉字的“黑体”，而有衬线的字体更适合阅读，对应汉字的“宋体”。汉字是方块字，所以一般都是等宽的，这里说汉字等宽，往往是指汉字需要和两个英文字母等宽。上面说的黑体和宋体都很正式，是印刷体，而“仿宋”或者“楷体”则更加灵活，对应手写体。</p><h3 id="3-2-属性"><a href="#3-2-属性" class="headerlink" title="3.2 属性"></a>3.2 属性</h3><p>字体有很多属性，常用的有字族（family）、倾斜（slant）、字重（weight）。后两者合一起叫样式（style）。</p><p>字族就是字体的名字。</p><p>倾斜就是斜不斜，英文叫 Roman，Italic 或者 Oblique ，Italic 是专门的斜体写法（更接近手写样式）， Oblique 是把常规写法倾斜一下完事。</p><p>字重就更简单了，就是笔划的粗细。常见的有 Regular、Normal、Medium、Bold、Semibold、Black、Thin、Light、Extralight 等。</p><h3 id="3-3-汉字"><a href="#3-3-汉字" class="headerlink" title="3.3 汉字"></a>3.3 汉字</h3><p>Noto 系列字体是 Google 主导的，名字的含义是<strong>没有豆腐（no tofu）</strong>，因为缺字时显示的方框或者方框被叫作 tofu 。思源系列字体是 Adobe 主导的。其中汉字部分被称为思源黑体和思源宋体，是由这两家公司共同开发的，两个字体系列的汉字部分是一样的。</p>]]></content>
    
    
    <summary type="html">&lt;h2 id=&quot;一、编码&quot;&gt;&lt;a href=&quot;#一、编码&quot; class=&quot;headerlink&quot; title=&quot;一、编码&quot;&gt;&lt;/a&gt;一、编码&lt;/h2&gt;&lt;p&gt;此章的目的是弄清楚 ASCII, GBK, Unicode, UTF-8 编码的区别，大部分知识都来源于&lt;a href=&quot;https://www.ruanyifeng.com/blog/2007/10/ascii_unicode_and_utf-8.html&quot;&gt;这里&lt;/a&gt;。所以我只是简单转述一下：&lt;/p&gt;
&lt;p&gt;ASCII 是最为古老的编码方式，它指的是用一个字节也就是 8 bit 完成编码，实际上只用了 7 bit ，最高位的值衡为 0 （这也成了其他编码方式兼容 ASCII 的一个重要抓手）。也就是说，ASCII 只能编码 2&lt;sup&gt;7&lt;/sup&gt; = 128 个文字，这对英文这种只有 26 个字母的语言体系是足够的。&lt;/p&gt;
&lt;p&gt;但是 ASCII 并不能满足很多类似英语的语言体系，比如说 &lt;code&gt;é, ג&lt;/code&gt; 这种字符都是原有的 ASCII 所没有的，但是幸运的是，很多语言的字符数本来就不多，比如俄语是 33 个，而法语是基础的 26 个英文字母加音标。所以这些语言同样可以用一个字节进行编码，英语字符占据了 &lt;code&gt;0 ~ 127&lt;/code&gt; ，它们就占据了 &lt;code&gt;128 ~ 255&lt;/code&gt; 。这样的缺点就是不同国家的 &lt;code&gt;128 ~ 255&lt;/code&gt; 表示不同的字母，彼此之间并不兼容。&lt;/p&gt;
&lt;p&gt;但是像汉语这样的语言就没有那么轻松了，他们就算占据了 &lt;code&gt;128 ~ 255&lt;/code&gt; 位，也最多增加 128 个字符，这对于有 10 万个字符的汉语来说是杯水车薪。所以中国就开发了 GB2312 编码系统，后来演变成了 GBK 系统。总的来说，就是采用两个 &lt;code&gt;128 ~ 255&lt;/code&gt; 的字节来表示一个汉字（应该是差不多），这样的话大约可以表示 2 万多个汉字，但是这样其实有一些生僻一些的字也是无法表示的。&lt;/p&gt;</summary>
    
    
    
    <category term="自由王国" scheme="https://thysrael.github.io/categories/%E8%87%AA%E7%94%B1%E7%8E%8B%E5%9B%BD/"/>
    
    
    <category term="S8课上" scheme="https://thysrael.github.io/tags/S8%E8%AF%BE%E4%B8%8A/"/>
    
    <category term="自由王国" scheme="https://thysrael.github.io/tags/%E8%87%AA%E7%94%B1%E7%8E%8B%E5%9B%BD/"/>
    
    <category term="字体" scheme="https://thysrael.github.io/tags/%E5%AD%97%E4%BD%93/"/>
    
  </entry>
  
  <entry>
    <title>海边拾贝-TCCL</title>
    <link href="https://thysrael.github.io/posts/3e82a961/"/>
    <id>https://thysrael.github.io/posts/3e82a961/</id>
    <published>2024-06-03T03:11:57.000Z</published>
    <updated>2024-10-17T06:35:03.420Z</updated>
    
    <content type="html"><![CDATA[<h1 id="TCCL-为-PCIe-GPU-集群发现更好的通信路径"><a href="#TCCL-为-PCIe-GPU-集群发现更好的通信路径" class="headerlink" title="TCCL: 为 PCIe GPU 集群发现更好的通信路径"></a>TCCL: 为 PCIe GPU 集群发现更好的通信路径</h1><p>论文地址：<a href="https://dl.acm.org/doi/10.1145/3620666.3651362">https://dl.acm.org/doi/10.1145/3620666.3651362</a></p><p>项目地址：<a href="https://github.com/mcrl/tccl">https://github.com/mcrl/tccl</a></p><h2 id="一、背景"><a href="#一、背景" class="headerlink" title="一、背景"></a>一、背景</h2><h3 id="1-1-计算集群"><a href="#1-1-计算集群" class="headerlink" title="1.1 计算集群"></a>1.1 计算集群</h3><p>随着深度学习模型规模的增大，单一的 GPU 已经无法满足计算的需要了，人们使用计算集群（Computation Cluster），也就是一组相关的 CPU GPU 网卡和连接它们的数据通路组成。这样计算任务就可以被并行了，原本的计算也变成了”计算 + 传输”两个部分。</p><p>从并行方式上划分，可以分为数据并行（data parallism）和算法并行（pipeline parallism）。数据并行指的是将一个主任务分成多个相互独立的子任务。而算法并行指的是将主任务划分出不同的阶段，形成流水线，各个阶段依次依赖。数据并行通信的对带宽要求并不高；算法并行通信的主要操作是传递，对带宽较为敏感。似乎这种分类并没有统一标准，有许多类似的概念。</p><h3 id="1-2-集体通信"><a href="#1-2-集体通信" class="headerlink" title="1.2 集体通信"></a>1.2 集体通信</h3><p>集体通信（Collective Communication）是计算集群实现分布式并行计算的一个重要过程。代表操作有 <code>reduce, scatter, gather</code> 等。</p><p>其中成环算法（Ring algorithm）在集体通信的实现中非常重要：成环算法将 GPU 组成一个环，方便进行数据的分发和采集。如图所示：</p><p><img src="/posts/3e82a961/2024-06-02_14-20.png" alt=""></p><p>成环算法在深度学习中有着广泛的应用，比如说数据并行（data parallelism），张量并行（tensor parallelism），序列并行（sequence parallelism），专家并行（Expert parallelism）中有着广泛应用。</p><p>我个人感觉集体通信更服务于数据并行或者类似概念的并行，因为这些操作对数据并行的”将主任务环分为多个子任务，将子任务合并成主任务”的逻辑很像，而与算法并行所需要的传递通信关系并不大。</p><h3 id="1-3-分类"><a href="#1-3-分类" class="headerlink" title="1.3 分类"></a>1.3 分类</h3><p>本文将目前的计算集群分成了两类，高带宽系统（high-bandwidth systems）和依赖 PCIe 的系统（PCIe-dependent systems）。</p><p>高带宽系统如 NVIDIA DGX-1 是硬件厂商打造的”旗舰系统”，具有专有的高带宽通路，比如 NVLink ，高带宽的专用交换机，比如说 NVSwitch 和 PCIe Switch ，高效的通信机制，可以全功率无阻塞的传递数据。</p><p>而许多研究院、初创公司和云服务厂商并没有足够的资金去购买这种高带宽集群，他们使用的是依赖 PCIe 的系统。这种系统没有高速数据通路，只能将 CPU 的 PCIe host bridge 和 NUMA 架构下的 CPU socket 当作交换通道，常常因为 GPU 间不支持直接传输功能，而需要借助 CPU 内存间接传输。这些特征说明了依赖 PCIe 的系统的本质是低带宽系统，为了方便行文，后续都称之为低带宽系统。</p><p>两种系统的示意图如下：</p><p><img src="/posts/3e82a961/2024-06-02_15-05.png" alt=""></p><p>根据阿里巴巴的调查报告，大约 90.4% 的系统是低带宽系统。遗憾的是，现有的集体通信库在低带宽系统上表现远没有理论预估得好，出现了数据通路堵塞的现象，而在高带宽系统上则不存在这个问题。这是因为这些函数库都是针对高带宽系统设计的，忽略了低带宽系统的特殊性。</p><h3 id="1-4-集群内部架构"><a href="#1-4-集群内部架构" class="headerlink" title="1.4 集群内部架构"></a>1.4 集群内部架构</h3><h4 id="1-4-1-集群设备"><a href="#1-4-1-集群设备" class="headerlink" title="1.4.1 集群设备"></a>1.4.1 集群设备</h4><p>在计算集群中，除了 CPU 和 GPU 这样的计算设备外，还有内存等设备也为计算任务的完成贡献了力量。</p><div class="table-container"><table><thead><tr><th>设备</th><th>解释</th></tr></thead><tbody><tr><td>CPU</td><td>初始化数据传输、参与数据搬运，CPU 用 Bounce Buffer 表示</td></tr><tr><td>GPU</td><td>进行计算任务</td></tr><tr><td>NVSwitch</td><td>英伟达专用的交换机</td></tr><tr><td>PCIe Switch</td><td>PCIe 设备交换机</td></tr><tr><td>IB NIC</td><td>网卡，用于跨芯片通信</td></tr><tr><td>Bounce Buffer</td><td>CPU 内存中的临时缓冲区，用于在数据传输过程中存储中转数据</td></tr></tbody></table></div><h4 id="1-4-2-数据通路"><a href="#1-4-2-数据通路" class="headerlink" title="1.4.2 数据通路"></a>1.4.2 数据通路</h4><p>数据通路是连接集群设备的线路，他们有带宽的差别，种类如下（表中数据没有经过详细考证）：</p><div class="table-container"><table><thead><tr><th>通路</th><th>带宽（GB/s）</th><th>解释</th></tr></thead><tbody><tr><td>NVLink</td><td>300 ~ 1800</td><td>英伟达专用的通路</td></tr><tr><td>PCIe</td><td>30 ~ 120</td><td>PCIe 设备使用的通路</td></tr><tr><td>IB</td><td>2 ~ 30</td><td>IB NIC 使用的通路</td></tr><tr><td>QPI</td><td>8 ~ 20</td><td>NUMA 节点中 CPU 间的通路</td></tr></tbody></table></div><h4 id="1-4-3-NUMA"><a href="#1-4-3-NUMA" class="headerlink" title="1.4.3 NUMA"></a>1.4.3 NUMA</h4><p>NUMA（Non-Uniform Memory Access）架构在计算集群中指的是集群中的设备（CPU，内存，网卡，GPU）被组成成了多个节点（Node）。当 GPU、网卡和 CPU 主内存属于同一 NUMA 节点时，它们之间的通信速度会更快。相反，如果它们属于不同的 NUMA 节点，则可能会产生较高的访问延迟和较低的带宽。</p><p>抽象来看，一个计算集群可以被理解为一个具有多个子图的图，每个子图是一个 NUMA Node 。计算设备是图上的点，而数据通路是图上的边。</p><p>成环问题就是在这个图上找到一个带宽最大的环的问题。</p><hr><h2 id="二、设计"><a href="#二、设计" class="headerlink" title="二、设计"></a>二、设计</h2><h3 id="2-1-Overview"><a href="#2-1-Overview" class="headerlink" title="2.1 Overview"></a>2.1 Overview</h3><p>TCCL 基于 NCCL 库（这是英伟达开发的一款集体通信库）构建。分为 Profiler 和 PathFinder, Profiler 用于测试带宽，PathFinder 用于成环路径生成，结构如图所示：</p><p><img src="/posts/3e82a961/overview.png" alt=""></p><p>在初始化阶段，Profiler 会测试实际带宽，PathFinder 会根据测试结果生成节点内环和节点内链，在调用阶段，PathFinder 会根据 Communicator 的要求返回节点内环，如果发生跨节点通信，PathFinder 会将节点内链组合起来形成跨节点环。</p><h3 id="2-2-Profile"><a href="#2-2-Profile" class="headerlink" title="2.2 Profile"></a>2.2 Profile</h3><p>为了测试精准性，原有的 benchmark 需要运行多次，而每次的初始化时间不固定，所以最后测试出来的 transfer 开销也是不固定的，而且每次测试前都需要进行初始化，非常耗时。TCCL 改进了原有的测试实际带宽的形式，提供了一个进程池用于测量，只需要 spawn 和 init 一次即可，并且在测试前还需要进行同步，提高测试精读，如下所示：</p><p><img src="/posts/3e82a961/profile.png" alt=""></p><h3 id="2-3-PathFinder"><a href="#2-3-PathFinder" class="headerlink" title="2.3 PathFinder"></a>2.3 PathFinder</h3><p>路径可以分为节点内路径和跨节点路径。因为可能的路径太多了，所以没有办法枚举来获得最优解。所以 TCCL 先用一个类似 Dijkstra 的优先队列最短路径算法来求取节点内的最优路径，然后再用动态规划结合上一问的解来求解跨节点的最优路径。</p><p>求解节点内最优路径的伪代码如下：</p><p><img src="/posts/3e82a961/2024-06-01_10-46-28_screenshot.png" alt=""></p><p>这个算法从两个数据结构开始：一个是需要访问的 GPU 集合 <code>G</code> （相当于点集），另一个是一个最大优先队列 <code>Q</code>，其中带宽是 key，transfer set 是 value （相当于边集）。这个队列里会包括所有已经 profiled 过了（也就是知道带宽了）但是还可以进一步加入（append） transfer 的所有 transfer set 。这和 dijkstra 算法很像，这是因为 dijkstra 算法可以用优先队列来选择出下一步要 append 的边（也就是最短的边），而这里用最大优先队列来选择最大带宽的边。带宽和边长有一定的相似性。</p><p>和 dijkstra 原理类似，当 <code>T</code> 成环的时候，它一定是优先队列中带宽最大的，同时那些没有加入队列的路径，肯定不如 <code>T</code> 的带宽大。</p><p>而节点间的求解，因为节点过多，所以用 dijkstra 算法复杂度（ $O((V+E)logV)$ ）会提高，先找到节点内的短链（使用 dijkstra 算法），再将这些短链在节点间连成环。</p><hr><h2 id="三、实验"><a href="#三、实验" class="headerlink" title="三、实验"></a>三、实验</h2><h3 id="3-1-环境设置"><a href="#3-1-环境设置" class="headerlink" title="3.1 环境设置"></a>3.1 环境设置</h3><p>实验采用了 3 种低带宽的计算集群，分别是 AMD-V100, AMD-3090, Intel-V100 ，其具体配置如下：</p><p><img src="/posts/3e82a961/clusters.png" alt=""></p><p>实验与 NCCL 和 MSCCL 进行对比。NCCL 在初始化阶段就确定了路径，所以不需要运行时 profile 。MSCCL（Multiple Schedulers for Collective Communication Library）是建立在 NCCL 之上的运行时系统。它利用 TACCL 产生的通信调度，并结合任务的执行计划，实现高效的集合通信。</p><h3 id="3-2-拥塞模式"><a href="#3-2-拥塞模式" class="headerlink" title="3.2 拥塞模式"></a>3.2 拥塞模式</h3><p>TCCL 记录了当发生拥塞（也就是实际带宽与理想带宽出现严重不符）时的模式（congestion pattern），但是却没有详细分析这些拥塞的成因，也没有利用这些模式优化算法。</p><p>TCCL 记录了 3 种模式：</p><p><img src="/posts/3e82a961/30e2f3013d50eb93abae86066be46f39_4_Table_1_154416043.png" alt=""></p><p>1，2，3 号实验说明，当 GPU 一边写 CPU 内存，一边写其他 NUMA Node GPU 内存时，会出现堵塞。</p><p>从第 6 和第 9 组实验中可以看出，这里说得是如果不同 Node 间的 GPU 直接写内存，那么性能会出现不可解释地下降，所以不如改用 bounce buffer 。</p><p>从 10 和 11，12 和 13 的对比中可以看出，由于 CPU 内存带宽有限，当太多的传输集中在同一 NUMA 节点的 CPU 内存上时，性能可能会下降。所以要更换为不同的 CPU。</p><p>我个人觉得这里的意义只说说明了对于低带宽系统，会出现许多难以预料的拥塞，原本基于理论带宽构建的库并不适合低带宽系统。</p><h3 id="3-3-集体通信原语"><a href="#3-3-集体通信原语" class="headerlink" title="3.3 集体通信原语"></a>3.3 集体通信原语</h3><p>我们测试了 5 种集体通信元语在 3 种库上的对比，结果如图：</p><p><img src="/posts/3e82a961/compare1.png" alt=""></p><p>可以看到 TCCL 相较于 baseline 具有 1 ~ 2 倍的提速。这是因为 TCCL 在路径规划是避开了带宽较小（因为发生了堵塞）的通路（红色所示）。</p><p><img src="/posts/3e82a961/red.png" alt=""></p><h3 id="3-4-深度学习模型"><a href="#3-4-深度学习模型" class="headerlink" title="3.4 深度学习模型"></a>3.4 深度学习模型</h3><p>深度学习训练模型结果对比如图：</p><p><img src="/posts/3e82a961/compare2.png" alt=""></p><p>与 TCCL 在单个原语中实现的加速相比，这种加速相对较小，因为在纯数据并行化配置中，通信仅占总执行时间的约 15%。</p><p>DL 模型测试不乐观的原因是这些 DL 模型都是为高带宽集群设计的。如果希望低带宽集群和 TCCL 发挥作用，需要新的 DL 模型设计思路。</p><hr><h2 id="四、总结"><a href="#四、总结" class="headerlink" title="四、总结"></a>四、总结</h2><p>TCCL 在集体通信库上针对依赖 PCIe 的系统（低带宽系统）进行了优化。相较于原有的 NCCL 之类的库，有如下优势：</p><ol><li>考虑了不存在超高带宽（如 NVLink）的数据通路情况，超高带宽容易让算法开发难度降低。</li><li>考虑了 NUMA Node 内部设备较少的情况，也就是考虑了更多跨节点通信的情况。</li><li>考虑了包含 Bounce Buffer 或者 NIC 等设备的路径，这是因为低带宽系统中的 Direct Write 较弱。</li><li>考虑了实际发生的并行传输时的拥塞现象，不再用理论带宽作为算法依据。</li></ol><p>我个人觉得 TCCL 的优化并不是仅针对于低带宽集群的特异性，有些优化是 general 的：</p><ol><li>dijkstra 算法配合动态规划降低算法复杂度。</li><li>用拓扑双射优化 Cache 提高运行效率。</li><li>维护进程池方便准确测量实际带宽</li></ol><p>这些举措放到高带宽系统上依然也有优化作用。</p><p>此外，对于拥塞导致的带宽下降，本文只是在初始化阶段简单了规避了拥塞发生的通路。而拥塞控制如果是一个运行时动态调整的操作，我觉得可能会更好，实时检测各个数据通路的拥塞情况，并据此改变路径的选择。</p><hr>]]></content>
    
    
    <summary type="html">&lt;h1 id=&quot;TCCL-为-PCIe-GPU-集群发现更好的通信路径&quot;&gt;&lt;a href=&quot;#TCCL-为-PCIe-GPU-集群发现更好的通信路径&quot; class=&quot;headerlink&quot; title=&quot;TCCL: 为 PCIe GPU 集群发现更好的通信路径&quot;&gt;&lt;/a&gt;TCCL: 为 PCIe GPU 集群发现更好的通信路径&lt;/h1&gt;&lt;p&gt;论文地址：&lt;a href=&quot;https://dl.acm.org/doi/10.1145/3620666.3651362&quot;&gt;https://dl.acm.org/doi/10.1145/3620666.3651362&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;项目地址：&lt;a href=&quot;https://github.com/mcrl/tccl&quot;&gt;https://github.com/mcrl/tccl&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&quot;一、背景&quot;&gt;&lt;a href=&quot;#一、背景&quot; class=&quot;headerlink&quot; title=&quot;一、背景&quot;&gt;&lt;/a&gt;一、背景&lt;/h2&gt;&lt;h3 id=&quot;1-1-计算集群&quot;&gt;&lt;a href=&quot;#1-1-计算集群&quot; class=&quot;headerlink&quot; title=&quot;1.1 计算集群&quot;&gt;&lt;/a&gt;1.1 计算集群&lt;/h3&gt;</summary>
    
    
    
    <category term="海边拾贝" scheme="https://thysrael.github.io/categories/%E6%B5%B7%E8%BE%B9%E6%8B%BE%E8%B4%9D/"/>
    
    
    <category term="知识总结" scheme="https://thysrael.github.io/tags/%E7%9F%A5%E8%AF%86%E6%80%BB%E7%BB%93/"/>
    
    <category term="S8课上" scheme="https://thysrael.github.io/tags/S8%E8%AF%BE%E4%B8%8A/"/>
    
    <category term="海边拾贝" scheme="https://thysrael.github.io/tags/%E6%B5%B7%E8%BE%B9%E6%8B%BE%E8%B4%9D/"/>
    
  </entry>
  
  <entry>
    <title>硬件平台-外存</title>
    <link href="https://thysrael.github.io/posts/dcaf34a0/"/>
    <id>https://thysrael.github.io/posts/dcaf34a0/</id>
    <published>2024-05-04T07:47:22.000Z</published>
    <updated>2024-10-17T06:35:03.437Z</updated>
    
    <content type="html"><![CDATA[<h2 id="一、块设备"><a href="#一、块设备" class="headerlink" title="一、块设备"></a>一、块设备</h2><p>外存是一种块设备（block device），是指以固定大小的块（block）为单位进行读写访问的设备。这些设备以块为最小的访问单元，每个块都有一个唯一的地址。我个人理解，可以将一个块设备理解成以 block 为元素的线性数组。</p><p>其中 block 大小一般是 512 字节，也被叫作扇区 sector。其实这个大小对于现在的计算机有些太小了，所以往往这些 block 也会聚集成一个更大的单位，这里就会产生一些混乱，比如说这个更大的单位可以被叫作簇 cluster，也可以被叫作块 block。</p><p>块设备在 Linux 中显示为 <code>/dev/</code> 下的一个文件，他们命名往往是 <code>xxy</code> ，其中 <code>y</code> 是 <code>a, b, c, d</code> 这样的字母，用于表示相同设备的编号。而 <code>xx</code> 表示设备的种类：</p><ul><li><code>hd</code>：指的是采用 IDE 磁盘接口的磁盘</li><li><code>sd</code>：原本是 SCSI disk，SCSI 和 IDE 都是旧控制器协议，现在也只 SATA 接口的磁盘</li><li><code>vd</code>：虚拟硬件设备，在一些虚拟化平台（如 KVM、QEMU、Xen）中，虚拟化主机的磁盘设备会被命名为 <code>vda</code>、<code>vdb</code>、<code>xvdc</code> 等类似的形式。</li><li><code>nvme</code>：NVMe 是 non-volatile memory express，它是一个主机控制器接口和存储协议，用于加速企业和客户端系统以及固态驱动器（SSD）之间的数据传输。它通过电脑的高速 PCIe 总线工作。总结就是一个比 SATA 快的固态硬盘设备。</li></ul><p>当然我们提供了这些文件，主要是是为了使用他们，我门也不指望可以用 <code>cat</code> 查看他们内容了，但是可以用 <code>dd</code> 对它们进行复制，用 <code>fdisk</code> 对它们进行分区。</p><p>另外还有一种叫作<strong>磁盘镜像</strong>的文件，他们就是磁盘内容的完全复制，也就是说，所有能在 <code>/dev/sda</code> 上进行的操作，都可以在 <code>disk.img</code> 中进行，相当于是把一个磁盘内容作为文件放到了另一个磁盘上。</p><hr><h2 id="二、分区"><a href="#二、分区" class="headerlink" title="二、分区"></a>二、分区</h2><p>一般我们并不会在拿到一个块设备后就立刻使用，而是对它们进行分区，分区的效果就是让一块磁盘看上去像多块磁盘。</p><p>至于为什么要分区，从历史的角度看，分区可能是因为 OS 并不能很好处理容量较大的磁盘，通过分区可以让磁盘分成多个小磁盘，方便 OS 的处理。而当今来看，分区和文件系统密切联系，一个分区上只能有一个文件系统，一个文件系统只能在一个分区上。所以当我们有使用多文件系统的需求时，也就需要分区了。</p><p>而为什么需要多个文件系统，就有很多原因了，比如最为朴素的，希望不同的文件属于不同的文件系统，比如 Windows 就希望所有的软件都在 C 盘中安装。而比较高端的，就是因为不同的文件系统具有不同的性质，比如有些不易失，但是速率较慢，而有些速度块，却很易失，所以就需要用多个文件系统来达到权衡。</p><p>分区的实现依赖于分区表，目前有两种格式的分区表，分别是 MBR 分区表和 GPT 分区表，后者可以创建更多的分区，是一种先进的设计。</p><p>我们可以用 <code>fdisk</code> 或者 <code>gparted</code> 对磁盘进行分区，我截了张图，是 Windows 下的分区</p><p><img src="/posts/dcaf34a0/image-20240504174321947.png" alt="image-20240504174321947"></p><p>这张图基本上直观地反映了这篇博文的所有知识点。这个磁盘有 6 个分区，其中比较重要的 3 个分区分别是 C，D，E 盘。</p><p>有趣的是，分区和磁盘一样，同样会在 <code>/dev/</code> 文件夹下出现，他们的命名格式就是原本的磁盘名字加上数字编号（或者一些其他类似的后缀），当我们使用 <code>lsblk</code> 命令时，会清楚得发现这个关系，如下所示：</p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">$ lsblkNAME        MAJ:MIN RM   SIZE RO TYPE MOUNTPOINTSnvme1n1     <span class="token number">259</span>:0    <span class="token number">0</span> <span class="token number">476</span>.9G  <span class="token number">0</span> disk ├─nvme1n1p1 <span class="token number">259</span>:1    <span class="token number">0</span>   260M  <span class="token number">0</span> part ├─nvme1n1p2 <span class="token number">259</span>:2    <span class="token number">0</span>    16M  <span class="token number">0</span> part ├─nvme1n1p3 <span class="token number">259</span>:3    <span class="token number">0</span>   100G  <span class="token number">0</span> part ├─nvme1n1p4 <span class="token number">259</span>:4    <span class="token number">0</span> <span class="token number">187</span>.8G  <span class="token number">0</span> part /run/media/thysrael/D├─nvme1n1p5 <span class="token number">259</span>:5    <span class="token number">0</span> <span class="token number">187</span>.8G  <span class="token number">0</span> part /run/media/thysrael/E└─nvme1n1p6 <span class="token number">259</span>:6    <span class="token number">0</span>  1000M  <span class="token number">0</span> part nvme0n1     <span class="token number">259</span>:7    <span class="token number">0</span> <span class="token number">931</span>.5G  <span class="token number">0</span> disk ├─nvme0n1p1 <span class="token number">259</span>:8    <span class="token number">0</span>   300M  <span class="token number">0</span> part /boot/efi└─nvme0n1p2 <span class="token number">259</span>:9    <span class="token number">0</span> <span class="token number">931</span>.2G  <span class="token number">0</span> part /<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>（另外说一嘴，表头的 <code>MAJ:MIN</code> 指的是主设备号和次设备号）。</p><p>所有可以对磁盘文件使用的命令都可以对分区文件使用，而且分区文件还可以使用 <code>mount</code> 命令。这是因为只有分区因为有文件系统的存在，所以具有“可解释性”。而磁盘并没有这个特性。</p><hr><h2 id="三、文件系统"><a href="#三、文件系统" class="headerlink" title="三、文件系统"></a>三、文件系统</h2><p>分区之后依然没法使用，因为我们还需要对分区进行<strong>格式化</strong>，在 Linux 上我们可以使用命令 <code>mkfs</code> 来进行格式化。正如这个命令本身所暗示的一样，格式化的本质就是在分区上创建一个“文件系统”。</p><p>这里需要区分一下文件系统的概念。事实上，我们会接触到两个文件系统，一个文件系统是我从小就接触到的，它被组织成一棵树型结构，有文件夹，有文件，我可以创建，删除，编辑，在各个路径下导航，这个文件系统是操作系统维护并呈现给我的。还有一个文件系统是我之前很少接触的，他们指的是如何规划分区里面的 block ，在原本线性的 block 数组上，构建一个树形结构，每个节点还存储着一些元数据。此外，还应当考虑这个树形结构的检索、安全、可恢复性、大小等因素。这个文件系统有 FAT, EXT, NTFS 等例子。</p><p>我们格式化生成的就是第二种文件系统，而第一种文件系统更像是第二种文件系统的“<strong>前端</strong>”。这种文件系统由以下几个部分组成：</p><ul><li>file data: 即文件中的数据</li><li>meta data: 除了文件本身包含的数据，还有文件的访问权限、大小和创建时间等控制信息。这也被称为 inode</li><li>control data: 用于记录分区 block 的使用情况和归属情况，可以是位图</li><li>superblock: 包含了一个文件系统所有的控制信息，可以理解为文件系统的 meta data</li></ul><hr><h2 id="四、挂载"><a href="#四、挂载" class="headerlink" title="四、挂载"></a>四、挂载</h2><p>那么如何让一个外存上的文件系统转变成我们常见的<strong>前端文件系统</strong>呢？是通过挂载 mount 。</p><p>挂载指的是在原有的前端文件系统中找到一个目录（也被称为挂载点），然后让 OS 解析外存文件系统，并将其根节点放到挂载点上的过程。之后我们就可以通过访问挂载点下的文件树，来访问实际的文件系统了。</p><p>示意图如下：</p><p><img src="/posts/dcaf34a0/v2-1d745e32b36be641322ac90ea9812978_720w.webp" alt="img"></p><p>以 <code>/home</code> 为挂载点挂载 partition b，效果如图：</p><p><img src="/posts/dcaf34a0/v2-63bc5bc54fda33eef63e5d3102234756_720w.webp" alt="img"></p>]]></content>
    
    
    <summary type="html">&lt;h2 id=&quot;一、块设备&quot;&gt;&lt;a href=&quot;#一、块设备&quot; class=&quot;headerlink&quot; title=&quot;一、块设备&quot;&gt;&lt;/a&gt;一、块设备&lt;/h2&gt;&lt;p&gt;外存是一种块设备（block device），是指以固定大小的块（block）为单位进行读写访问的设备。这些设备以块为最小的访问单元，每个块都有一个唯一的地址。我个人理解，可以将一个块设备理解成以 block 为元素的线性数组。&lt;/p&gt;
&lt;p&gt;其中 block 大小一般是 512 字节，也被叫作扇区 sector。其实这个大小对于现在的计算机有些太小了，所以往往这些 block 也会聚集成一个更大的单位，这里就会产生一些混乱，比如说这个更大的单位可以被叫作簇 cluster，也可以被叫作块 block。&lt;/p&gt;
&lt;p&gt;块设备在 Linux 中显示为 &lt;code&gt;/dev/&lt;/code&gt; 下的一个文件，他们命名往往是 &lt;code&gt;xxy&lt;/code&gt; ，其中 &lt;code&gt;y&lt;/code&gt; 是 &lt;code&gt;a, b, c, d&lt;/code&gt; 这样的字母，用于表示相同设备的编号。而 &lt;code&gt;xx&lt;/code&gt; 表示设备的种类：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;hd&lt;/code&gt;：指的是采用 IDE 磁盘接口的磁盘&lt;/li&gt;
&lt;li&gt;&lt;code&gt;sd&lt;/code&gt;：原本是 SCSI disk，SCSI 和 IDE 都是旧控制器协议，现在也只 SATA 接口的磁盘&lt;/li&gt;
&lt;li&gt;&lt;code&gt;vd&lt;/code&gt;：虚拟硬件设备，在一些虚拟化平台（如 KVM、QEMU、Xen）中，虚拟化主机的磁盘设备会被命名为 &lt;code&gt;vda&lt;/code&gt;、&lt;code&gt;vdb&lt;/code&gt;、&lt;code&gt;xvdc&lt;/code&gt; 等类似的形式。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;nvme&lt;/code&gt;：NVMe 是 non-volatile memory express，它是一个主机控制器接口和存储协议，用于加速企业和客户端系统以及固态驱动器（SSD）之间的数据传输。它通过电脑的高速 PCIe 总线工作。总结就是一个比 SATA 快的固态硬盘设备。&lt;/li&gt;
&lt;/ul&gt;</summary>
    
    
    
    <category term="硬件平台" scheme="https://thysrael.github.io/categories/%E7%A1%AC%E4%BB%B6%E5%B9%B3%E5%8F%B0/"/>
    
    
    <category term="直观理解" scheme="https://thysrael.github.io/tags/%E7%9B%B4%E8%A7%82%E7%90%86%E8%A7%A3/"/>
    
    <category term="S8课上" scheme="https://thysrael.github.io/tags/S8%E8%AF%BE%E4%B8%8A/"/>
    
    <category term="硬件平台" scheme="https://thysrael.github.io/tags/%E7%A1%AC%E4%BB%B6%E5%B9%B3%E5%8F%B0/"/>
    
  </entry>
  
  <entry>
    <title>硬件平台-Cache</title>
    <link href="https://thysrael.github.io/posts/603a762d/"/>
    <id>https://thysrael.github.io/posts/603a762d/</id>
    <published>2024-05-03T13:21:29.000Z</published>
    <updated>2024-11-27T10:49:36.211Z</updated>
    
    <content type="html"><![CDATA[<h2 id="一、结构"><a href="#一、结构" class="headerlink" title="一、结构"></a>一、结构</h2><p>因为一直分不清 Cache 的结构名字，所以特地画了一个比较满意的图来标注各种结构。</p><p><img src="/posts/603a762d/cache.drawio.png" alt=""></p><p>这个示意图的参数在右上角。Cache 中的基本单位是 Cache Line，它又被叫作 Block，它是由多个 Word 组成的。多个 Cache Line 会组成一个 Cache Set，一个 Cache Set 内包含的 Cache Line 数量被成为 Way。比如图中就是 2-Way 的 Cache，那么每个 Cache Set 就有 2 个 Cache Line。相同 Cache Set 中的 Cache Line 的关系被称为 associative（相联），它们不能依靠 set index 进行区分，只能通过 tag 区分。 </p><p>根据 Set 个数和 Way 的不同（其本质是 Cache Line 的位置确定），可以对 Cache 进行分类：</p><ul><li>直接映射（direct-map）：即 Way = 1 的情况</li><li>组相连（set-associative）：即普通情况</li><li>全相连（fully-associative）：即只有一个 Set，所有的 Cache Line 都是 associative 的。</li></ul><p>他们的功能上的区别在 Cache 的检索和分配上均有体现。会在下面章节进行介绍。</p><hr><h2 id="二、查找"><a href="#二、查找" class="headerlink" title="二、查找"></a>二、查找</h2><h3 id="2-1-过程"><a href="#2-1-过程" class="headerlink" title="2.1 过程"></a>2.1 过程</h3><p>首先补充 Cache 和 CPU 还有内存沟通的数据大小：CPU 每次从 Cache 中取出一个 Word，而 Cache 每次从 Memory 中取出一个 Cache Line。</p><p>CPU 会给 Cache 发送一个地址，这个地址有可能是虚拟地址，也可能是物理地址，这取决于具体的架构实现方式。这个地址还有一个特点是<strong>按照 Word 对齐的</strong>。虽然这个示意图中 Word 只有一个字节，没有对齐的必要，但是在常见的 Word 为 4 个字节的 32 位架构中，这个地址的 <code>[1:0]</code> 一定是 <code>0</code> 。</p><p>交给 Cache 的地址会被分成 3 个部分，即上图的 Tag（蓝色），Index（绿色） 和 Offset（橙色）。检索 Word 的过程是一个“Index-Check-Index”的过程。</p><p>首先我们根据<strong>绿色部分 index</strong> 找到对应的 Cache Set（这是一个像随机地址访问的过程，称之为 Index），因为 Index 是 1，所以我们找到左下角的 Cache Set 1。然后就会发现里面有一堆的 Cache Line，对于这些 Cache Line，我们没有办法直接确定哪一个是我们要找到的 Cache Line，我们需要用地址上的<strong>蓝色部分 Tag</strong> 和 Cache 中的 Tag 进行比对，只有完全相同才是我们要找的 Cache Line，所以我们在此图中选择了第二个 Cache Line（这个过程需要比对所有的 Tag 的所有位，称之为 Check）。在选定 Cache Line 后，我们需要根据<strong>橙色部分 Offset </strong>选择 Cache Line 中具体的 Word，图中 Offset 是 2，所以我们选择第 2 个 Word 交给 CPU（这个过程和绿色部分一样，也是 Index）。</p><p>如果用伪代码描述，是如下过程：</p><pre class="line-numbers language-cpp" data-language="cpp"><code class="language-cpp"><span class="token keyword">using</span> Word <span class="token operator">=</span> <span class="token keyword">char</span><span class="token punctuation">;</span><span class="token keyword">using</span> CacheLine <span class="token operator">=</span> Word<span class="token punctuation">[</span><span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">;</span><span class="token keyword">using</span> CacheSet <span class="token operator">=</span> std<span class="token double-colon punctuation">::</span>set<span class="token operator">&lt;</span>Tag<span class="token punctuation">,</span> CacheLine<span class="token operator">&gt;</span><span class="token punctuation">;</span><span class="token keyword">using</span> Cache <span class="token operator">=</span> CacheSet<span class="token punctuation">[</span><span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">;</span>Word <span class="token function">find</span><span class="token punctuation">(</span>Tag tag<span class="token punctuation">,</span> Index index<span class="token punctuation">,</span> Offset offset<span class="token punctuation">)</span><span class="token punctuation">{</span>CacheSet set <span class="token operator">=</span> Cache<span class="token punctuation">[</span>index<span class="token punctuation">]</span><span class="token punctuation">;</span><span class="token keyword">for</span> <span class="token punctuation">(</span><span class="token keyword">auto</span> <span class="token operator">&amp;</span>entry <span class="token operator">:</span> set<span class="token punctuation">)</span><span class="token punctuation">{</span>CacheLine line <span class="token operator">=</span> entry<span class="token punctuation">.</span>second<span class="token punctuation">;</span><span class="token keyword">if</span> <span class="token punctuation">(</span>entry<span class="token punctuation">.</span>first <span class="token operator">==</span> tag<span class="token punctuation">)</span><span class="token punctuation">{</span><span class="token keyword">return</span> line<span class="token punctuation">[</span>offset<span class="token punctuation">]</span><span class="token punctuation">;</span><span class="token punctuation">}</span><span class="token punctuation">}</span><span class="token keyword">return</span> <span class="token keyword">nullptr</span><span class="token punctuation">;</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>上述过程基本上描述了“一个 Word 是怎样从 Cache 中根据地址被检索出来”的过程，省略的部分主要是对于 Cache Line valid 和 dirty 等属性的检验。</p><p>对于检索成功的情况，我们称之为 hit（命中），而对于检索失败的情况，我们称之为 miss（缺失）。</p><h3 id="2-2-矛盾"><a href="#2-2-矛盾" class="headerlink" title="2.2 矛盾"></a>2.2 矛盾</h3><p>在上述过程中，Index 具有随机访问的特征，所以会比较快，而 Check 需要对 Set 内的每个 Line 的 Tag 进行比对，所以比较慢。Check 和 Way 直接相关，因为 Way 就是 Set 里 Line 的数量，所以 Way 越大，Check 对硬件性能的要求越高（因为比较电路非常耗片上资源，而且存储 Tag 也需要额外的空间）。但是换一个角度思考，当 Way 变大时，我们命中 Cache 的可能性也会变大，因为此时会存在更多候选的 Line 。所以选择多少 Way 其实是需要权衡的。</p><p>当 Cache 的总容量一定（这个比较实际，因为 Cache 总容量跟 Cache 需要消耗的片上资源直接相关）的时候，Way 和 Set 数量是反比关系，所以我们应当考虑好这个矛盾，也就是高命中率（Way 多）和低硬件成本和复杂度（Set 多）。</p><h3 id="2-3-地址翻译"><a href="#2-3-地址翻译" class="headerlink" title="2.3 地址翻译"></a>2.3 地址翻译</h3><h4 id="2-3-1-地址策略"><a href="#2-3-1-地址策略" class="headerlink" title="2.3.1 地址策略"></a>2.3.1 地址策略</h4><p>在上面的介绍中，我们并没有强调我们查找 Cache 的时候的地址是物理地址还是虚拟地址，这是因为这是受到具体的硬件架构设计。具体的策略有 3 种：VIVT、PIPT、VIPT，这里的英文是都是缩写，分别对应 Virtual，Physical，Index，Tag 英文。</p><h4 id="2-3-2-VIVT"><a href="#2-3-2-VIVT" class="headerlink" title="2.3.2 VIVT"></a>2.3.2 VIVT</h4><p>VIVT 指的是完全使用 VA 进行 Cache 查找，这种方式的优势是，在查找前不需要经过 MMU 将 VA 翻译成 PA，命中只需要花费查找的时间，而缺失的时候再经过 MMU 翻译成 PA 进行访存，是非常高效的（因为 MMU 翻译也是很消耗时间的），</p><p>但是缺点有两个：歧义 (ambiguity) 和别名 (alias) 。这其实都是虚拟地址空间本身特性导致的问题。</p><p>歧义指的是<strong>相同的 VA 对应不同的 PA</strong>，这是由于相同的 VA 来自不同的进程地址空间，这就要求 OS 在进程切换的时候需要刷新 Cache，这就导致了切换后会有一个冷启动过程。</p><p>而别名指的是<strong>不同的 VA 对应了相同的 PA</strong>，这是由于虚拟地址可以让不同 VA 映射到相同的 PA 上，别名问题会导致一个 Cache 中可能存在多个物理内存的副本，而当我们更新这些副本的时候，有可能没有更新全部副本，导致操作。解决这个问题的方式就是将这种<strong>共享的 PA</strong> 设置成 nocache 的，即禁止他们使用 Cache。除此之外，似乎还可能用硬件措施解决多副本问题。</p><h4 id="2-3-3-PIPT"><a href="#2-3-3-PIPT" class="headerlink" title="2.3.3 PIPT"></a>2.3.3 PIPT</h4><p>PIPT 指的是完全使用 PA 进行 Cache 查找。因为物理地址具有唯一性，所以就不会存在 VIVT 所面临的歧义和别名问题，OS 的维护难度会直线下降，这部分的维护开销也会被取消。</p><p>但是其缺点就是每次 Cache 查找都需要经过 MMU 翻译，需要承担翻译的开销。但是因为现代的 MMU 有 TLB 加速，所以开销是可以接受的。现代的 Cache 往往采用 PIPT 的形式。</p><h4 id="2-3-4-VIPT"><a href="#2-3-4-VIPT" class="headerlink" title="2.3.4 VIPT"></a>2.3.4 VIPT</h4><p>当我们讨论使用 VA 的缺点时，本质其实在说用于查找的 Tag 和 Index 到底是 Virtual 的还是 Physical 的，如果是 Virtual 的，那么就会有歧义和别名问题，如果是 Physical 的，那么就不会有。</p><p>VIPT 指的是使用 Physical 的 Tag 和 Virtual 的 Index 。这样的好处在于，地址翻译过程和 Cache 查找过程可以并行，在地址翻译还没有结果的时候，我们就可以用 VI 来进行 Cache Set 的确定了。而且这种方式不再有歧义问题了，但是可能有别名问题。</p><p>对于歧义问题，此时的 PT 不再是 PA 的 Tag 部分，而变成了 PPN，PPN 具有唯一性，所以不再有歧义问题。</p><p>而对于别名问题，则要分类讨论，因为 Index 依然是虚拟的，那么使用 PPN 作为 Tag 能否矫正 VI 的影响呢？这要看 PPN 的宽度（反过来也可以说看 Index 的宽度），如下所示：</p><p><img src="/posts/603a762d/VIPT.drawio.png" alt=""></p><p>如果是第一种情况，VI 和 PI 存在差异，所以就会有别名现象，而第二种情况，VI 和 PI 不存在差异，就不会有别名现象。</p><p>总结就是 PPN 和 Index 不能有交集，就不会有问题。</p><hr><h2 id="三、分配与更新"><a href="#三、分配与更新" class="headerlink" title="三、分配与更新"></a>三、分配与更新</h2><h3 id="3-1-分配的情形"><a href="#3-1-分配的情形" class="headerlink" title="3.1 分配的情形"></a>3.1 分配的情形</h3><p>当我们考虑将一个 CacheLine 从 Memory 中填充到 Cache 中时，这个 CacheLine 一定会被确定地放到某个 CacheSet 中，但是具体是哪个 CacheLine Slot，那就不一定了，我们有 Way 种选择。</p><p>其实原本的 CacheSet 中的 CacheLine Slot 也有 3 种情况，第一种是这个 slot 是空的，那么 CacheLine 放到这里就好了。第二种是这个 slot 本来就放着 这个待插入的 CacheLine，那么什么都不用干就好了。最后一种是这个 Slot 本来就放着一个不同的 CacheLine，那么就需要把原本的 CacheLine 逐出（evictation）。至于选择 set 中的哪个 line 逐出，基本上我们采用 LRU 策略来决定。</p><p>从逐出角度考虑，当 Way 增大的时候，CacheLine 的选择会更加灵活，逐出会更少。</p><p>从宏观角度看，逐出的存在是因为 Cache 比 Memory 小。如果 Index 的宽度是地址宽度减去 Offset 宽度，那么就不存在逐出了，很可惜事实并不是这样。相同 Index 的 CacheLine 会被分配到同一个 set 中，而 Way 只是提供了一种逐出的“缓冲”。</p><h3 id="3-2-Index-Position-分析"><a href="#3-2-Index-Position-分析" class="headerlink" title="3.2 Index Position 分析"></a>3.2 Index Position 分析</h3><p>在示意图上展示的 Index 在低位，而 Tag 在高位。这样做的效果就是，一些地址相近的数据（也就是高位地址相同），会被分散到各个 Set 中，这无疑是好的。因为程序具有局部性，地址相近的数据大概率会被反复用到，如果将它们分配到同一个 Set 中，那么就会导致它们互相挤占（Evictation），导致命中率降低。</p><h3 id="3-3-分配策略"><a href="#3-3-分配策略" class="headerlink" title="3.3 分配策略"></a>3.3 分配策略</h3><p>cache 的分配策略（allocation policy）是指我们什么情况下应该为数据分配 cache line，也就是合适从内存中将数据取出来放到 cache 中。分为<strong>读分配策略和写分配策略</strong>。</p><p>读分配策略指的是当 CPU 读数据时，发生 cache 缺失，这种情况下都会分配一个 cache line 缓存从主存读取的数据。默认情况下，cache 都支持读分配。</p><p>当 CPU <strong>写数据</strong>发生 cache 缺失时，才会考虑写分配策略。当我们不支持写分配的情况下，写指令只会更新 Memory 数据，然后就结束了。当支持写分配的时候，我们首先从 Memory 中加载数据到 cache line 中（相当于先做个读分配动作），然后会更新 cache line 中的数据。</p><p>Cache 对读写的加速副作用是不一样的，Cache 加速写操作，如果采用写分配策略，那么就会有可能导致 Cache 和 Memory 中的数据存在差异（具体取决于更新策略）。</p><h3 id="3-4-更新策略"><a href="#3-4-更新策略" class="headerlink" title="3.4 更新策略"></a>3.4 更新策略</h3><p>更新策略（update policy）指的是，当<strong>写操作（Store）</strong>命中 Cache 时，Cache 应当如何更新其中的数据。有写直通（write through）和写回（write back）两种策略。</p><p>写直通指的是当 CPU 执行 store 指令并在 cache 命中时，我们更新 cache 中的数据并且更新 Memory 中的数据。<strong>cache和 Memory 的数据始终保持一致</strong>。</p><p>当 CPU 执行 store 指令并在 cache 命中时，我们只更新 cache 中的数据。并且每个 cache line 中会有一个 bit 位记录数据是否被修改过，称之为dirty bit。Memory 中的数据只会在 cache line 被逐出或者显式的 clean 操作时更新。因此，<strong>cache 和 Memory 的数据可能不一致</strong>。</p><hr>]]></content>
    
    
    <summary type="html">&lt;h2 id=&quot;一、结构&quot;&gt;&lt;a href=&quot;#一、结构&quot; class=&quot;headerlink&quot; title=&quot;一、结构&quot;&gt;&lt;/a&gt;一、结构&lt;/h2&gt;&lt;p&gt;因为一直分不清 Cache 的结构名字，所以特地画了一个比较满意的图来标注各种结构。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/posts/603a762d/cache.drawio.png&quot; alt&gt;&lt;/p&gt;
&lt;p&gt;这个示意图的参数在右上角。Cache 中的基本单位是 Cache Line，它又被叫作 Block，它是由多个 Word 组成的。多个 Cache Line 会组成一个 Cache Set，一个 Cache Set 内包含的 Cache Line 数量被成为 Way。比如图中就是 2-Way 的 Cache，那么每个 Cache Set 就有 2 个 Cache Line。相同 Cache Set 中的 Cache Line 的关系被称为 associative（相联），它们不能依靠 set index 进行区分，只能通过 tag 区分。 &lt;/p&gt;
&lt;p&gt;根据 Set 个数和 Way 的不同（其本质是 Cache Line 的位置确定），可以对 Cache 进行分类：&lt;/p&gt;</summary>
    
    
    
    <category term="硬件平台" scheme="https://thysrael.github.io/categories/%E7%A1%AC%E4%BB%B6%E5%B9%B3%E5%8F%B0/"/>
    
    
    <category term="直观理解" scheme="https://thysrael.github.io/tags/%E7%9B%B4%E8%A7%82%E7%90%86%E8%A7%A3/"/>
    
    <category term="S8课上" scheme="https://thysrael.github.io/tags/S8%E8%AF%BE%E4%B8%8A/"/>
    
    <category term="硬件平台" scheme="https://thysrael.github.io/tags/%E7%A1%AC%E4%BB%B6%E5%B9%B3%E5%8F%B0/"/>
    
  </entry>
  
</feed>
